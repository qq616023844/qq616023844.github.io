<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[简记20191123]]></title>
    <url>%2F2019%2F11%2F23%2F%E7%AE%80%E8%AE%B020191123%2F</url>
    <content type="text"><![CDATA[&emsp;大四已经实习了四个多月,在工作上遇到了很多技术问题,原本是十分开心的,毕竟不断地遇到问题解决问题技术才能得到提高。&emsp;但是逐渐的感觉到这种学习方式似乎不适合我,个人是有些强迫症的,遇到了问题总想要刨根问底,不懂的地方就要去研究,每次遇到了耗时较长的资料时,总会放入收藏夹想着有时间了慢慢看,但是互联网是一个高速发展的行业,虽然解决问题的速度可以跟遇到问题的速度持平,但是想要刨根问底的话,速度却远远达不到出现问题的速度。&emsp;我曾因为一个http请求却无法被request.getparameter()获取到参数的问题去研究各种content_type下的http报文格式,下载了tomcat源码从启动类开始看起,一点点的追踪,看完整个的报文解析流程,然而知识是延伸的,看到了tomcat的线程处理方式,就顺便看完(其实我也不知道该如何表述我学习的程度)了各种io模型,比如tomcat的直接起线程莽上的方式,或者像是netty中主从线程模型这种,看完了这些我又想去看netty的源码,然而至今他依然排在我的任务列表里面没有去做。我也曾经遇到了根据用户传入的参数从数据库导出大数据制定excel表格提供用户下载的功能,虽然这个功能不是我做的,但是当时在看这份代码的时候,我就认为他不完美,究竟哪里不完美呢?首先,原始是用POI的XSSFWorkbook,在大数据量情况下分分钟爆掉内存,然后我去搜索了资料,发现用SXSSFWorkbook确实可以解决爆内存的问题,他是可以将过程数据贮藏在硬盘中,但是这样我依旧认为他不完美,因为他用到了硬盘,需要多次io。后来因为前辈一句流式导出,我去研究了导出方案,通过查阅资料,发现excel2007以后本质是一个zip压缩包的形式,并且内容为xml格式存储,那么既然是这样,他就应该支持流式导出,通过翻阅博客或者官方文档,我了解了它里面常用的每个字段的含义,并且看了几份业务中导出的excel表格,经过解剖以后作为参照和测试,最终确认了,虽然excel中部分文件的头部是有一个内容总大小的标识位的,但是即时不填写,excel也能照常运行,这样的话,excel流式导出便有了希望,这段研究测试基本是在业余时间进行的,大概花了两天多。但是剖析完,我却遇到了一个十分棘手的问题,那就是excel本身是有内部的压缩算法的,它会将字符串单独放在一张xml中,在核心文本区域仅仅保存其引用,这个压缩算法虽然是可以被无视的,经过实验,即使你不对其进行字符串压缩,但是只要按照他的引用规则来生成xml文件,依旧可以正常使用,只不过文件体积会根据文件内容类型而增大,我想到了可以采用类似操作系统内存管理的FIFO算法或者FLU算法来进行不完全的压缩,虽然理论上可行,但是将花费的时间太多了。后来有一段时间,我又觉得算法是程序员的基础,开始刷leetcode,然而又是因为各种想学的东西或者想玩的东西(沉迷小说,已卸载!(╯▔皿▔)╯)中途打断了。&emsp;尴尬了,老毛病又犯了,不把事情弄清楚,就会觉得非常难受。&emsp;就这样,我发现我想弄明白的事情越来越多,我的任务清单越来越长,当我发现我想要学的东西增长速度以指数增长远大于log式学习的时候,我开始不想学习了,这也就是近期我没再更新过博客的一部分原因,在这之前,我一度开着netty源码准备详细研究里面的线程模型。&emsp;我认为在某些方面自己还是比较幸运的,我偶然看到了知乎的一个问题回答”25岁做什么,可以在5年后受益匪浅?”里面有答主说:”有人问他,给他5年时间专研某个领域,可否成为该领域的专家,他认为可以。”同样的,我也认为可以。同时我也看到了一个答主的回答,当然,那个回答我已经找不到了,他说:”我在xx(抱歉已经记不清了)领域就是专家,别的领域你跟我比,但是我为什么要跟你比,只要你擅长的比别人都强就够了,不要拿自己不会的去跟别人比,我一直口语不太好,遇到个对外项目要谈进行沟通,口语不好怎么办,叫个翻译就好了,反正在我的领域,我就是强。”&emsp;看完后,我想到了很多。现在这个时代的互联网发展速度极快,这既是幸运又是悲哀,对于喜欢的人来说,就像是有无数的财富摆在眼前,但是他却让人眼花缭乱没有方向。我曾记得小时候我想当程序员的时候,我家那片还不叫作程序员,那叫啥呢?”干IT的”。当时的我感觉IT就像是个匠人,就像是艺术家,为了达到极致不断地打磨,差不多就类似以前的暴雪爸爸,每个游戏一发布即是巅峰。儿时的梦想到了要实现的年纪,却成为了快餐化的职业,一个个看准了高薪挤进来,虽然能力上我们没有区别,但是却仅仅将它看作一个职业。&emsp;我曾一度被行业快速发展的巨浪卷着四处飘荡,漫无目的,为了适应找工作需要而去学习。现在,我终于看清了,既然我是真心的喜欢这个行业,那么就按着自己的心意去学习,做好自己的规划,而不是面向薪资学习。&emsp;我不认为自己有着某种天赋,但是就像答主所说:”我们还远远达不到需要拼天赋的程度。当你遇到需要拼天赋的时候,回过头看一看,发现自己已经走了很远很远。”&emsp;我是个做事比较莽(这个词还是打王者时候出现的,我的理解是,看似骚的一匹,其实稳如老狗,奥利给?/手动滑稽)而且喜欢钻牛角尖的人,但我并不认为这是个缺点。希望未来五年,这种性格可以让我碾过路上遇到的困难。&emsp;接下来! 《计算机网络基础》,《计算机网络基础：自顶向下》 《TCP/IP详解1:协议》,《鸟哥的LINUX私房菜:基础篇》,抓包分析 协议分析能力,底层协议,《TCP/IP详解:实现》,《计算机网络》 高性能io 设计模式,深入线程及并发控制 网络编程框架解剖,netty,tomcat解剖 自己实现网络编程框架 分布式网络编程框架学习 自己实现分布式网络框架&emsp;虽然不知道能走多快,也不知道这条路线到底对不对。但是,我喜欢! &emsp;奥利给!]]></content>
      <categories>
        <category>简记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FutureTask源码分析]]></title>
    <url>%2F2019%2F10%2F05%2FFutureTask%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[FutureTask直接继承了RunnableFuture,间接继承了Future,Runnable。当我们使用Runnable时,是无法获得返回值的,而RunnableFuture则是为了解决这一个问题而存在 首先,这段代码不熟悉的可以去看这篇文章 如何使用Unsafe类方法 12345678910111213141516171819// Unsafe mechanics private static final sun.misc.Unsafe UNSAFE; private static final long stateOffset; private static final long runnerOffset; private static final long waitersOffset; static &#123; try &#123; UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = FutureTask.class; stateOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("state")); runnerOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("runner")); waitersOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("waiters")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; 如果没有问题我们继续,在该类中,还有一点你会发现,他用到了自定义的链表,并且在get阻塞等待以及任务完成时都会操作该链表,例如awaitDone(boolean timed, long nanos)方法中的这些操作,该链表的作用是,如果多个线程同时get阻塞等待该任务,这些线程的信息分别保存在链表上的一个节点中,那么当任务完成时可以通过该操作来即时唤醒这些线程,超时的被从链表中移除,例如下面代码demo 123456789101112131415161718192021222324252627282930313233@Test public void test42() throws InterruptedException &#123; //构造FutureTask FutureTask futureTask = new FutureTask(() -&gt; &#123; Thread.sleep(5000); System.out.println("callable has run"); return "123"; &#125;); //运行FutureTask中传入的任务 new Thread(() -&gt; futureTask.run()).start(); //开启第一个get new Thread(() -&gt; &#123; try &#123; System.out.println("Thread one:"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //开启第二个get new Thread(() -&gt; &#123; try &#123; System.out.println("Thread two:"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //主线程睡眠等待其他线程结束 Thread.sleep(10000); &#125; 在该类中有一处代码,这里保存该任务的状态,这种方式很常见,也可以方便的通过比较大小等方式来判断其状态范围 12345678private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; callable是接到的任务,即时构造时采用的Future也会为了统一而被封装为Callable,outcome是返回值,如果任务执行过程中出现异常,那么outcome中保存的则是异常信息,waitNode则是刚刚提到的链表,runner是运行该任务的线程信息,在本类中常被用来做CAS操作,只有当其为null run()才可被调用,避免连续调用两次run()导致重复运行任务 12345678/** The underlying callable; nulled out after running */private Callable&lt;V&gt; callable;/** The result to return or exception to throw from get() */private Object outcome; // non-volatile, protected by state reads/writes/** The thread running the callable; CASed during run() */private volatile Thread runner;/** Treiber stack of waiting threads */private volatile WaitNode waiters; finishCompletion()方法就是之前提到的唤醒链表上所有get阻塞的线程LockSupport.unpark和park可以理解为信号量runAndReset()这是个protected方法,作用是,通过不改变state的状态使其可以运行多次,普通的run()运行一次以后state状态就改变了 其他的代码没啥难度,看下源码附带的注释就能理解了]]></content>
      <categories>
        <category>源码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExecutor源码分析]]></title>
    <url>%2F2019%2F10%2F05%2FThreadPoolExecutor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[看到网上讲线程池源码的文章一堆大坑,只能自己扒源码扒篇文章出来了,坐标jdk8 最重要的一个坑放在前面假如你设置的核心线程数=2,最大线程数=4。很多人都讲向线程池添加任务时会先扩充到最大线程数,多出来的再向队列添加,我只想说,这是非常致命的错误 看如下代码,在添加任务时,从源码或从注释中明确表示分了三步1.如果现存线程数小于核心线程数,则创建线程,添加的任务直接在该线程运行2.如果核心线程数满了,则add到队列中3.如果队列满了,则尝试扩充线程,任务在新创建的线程中运行 那我们结合之前提到的错误方式来看,如果这一步理解错了会发生什么。如果我们采用的是无界队列,那会直接导致我们的任务被无限制的添加到队列中而不会主动去扩充线程数,如果核心线程消费速度小于生产速度,会直接导致OOM,这点我们务必要确认清楚 123456789101112131415int c = ctl.get();if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get();&#125;if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false);&#125;else if (!addWorker(command, false)) reject(command); 强调完一个巨坑以后,我们来看一下线程池源码 关于线程池源码的几个特点:1.之前提到的三步添加任务的坑2.为了方便读取,采用了位运算将线程池状态和工作线程数整合到了一个AtomicInteger中,高位代表状态,低位代表工作现场数 123456//这是整合了线程池状态和工作线程数的AtomicIntegerprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//这是解析ctl线程池状态和工作线程数的几个方法private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 3.执行任务的行为:我们可以通过runWorker方法(该方法被Worker中的run调用,一个Worker即可以当作一个封装好的工作线程)看到,该方法中有一个while循环调用,条件分为两种情况,如果是该线程运行的首个任务,会直接接收任务运行(该任务被封装在Worker中),如果是后续任务,则会从队列中取得任务进行(在getTask方法中会对我们设置的线程超时时间来进行判断,从而起到当非核心线程超时时,返回false使其跳出while循环,从而终止该线程)4.核心线程和非核心线程其实并无区别,AtomicInteger大家都知道,可以做到原子性操作,当工作线程数大于核心线程数且超时时,会同时请求减少工作线程数,竞争到的则作为非核心线程而关闭,没有竞争到的作为核心线程继续运行。可见,两种线程仅仅是称呼上的不同5.无处不在的双重检查,即时用了双重检查,但是由于两行代码之间并不是原子性的,我们无法保证双重检查一定可以避免并发操作产生的时间间隙,但确实可以避免一些并发造成的间隙。但是既然线程池是如此操作的,那么很大概率上可能编程人员对此进行过测试,认为双重检查有助于提高效率。另外双重检查也有预防一些因时间间隙产生的BUG的作用,下文会讲到6.类似beforeExecute这种方法,里面没有做什么事情,这是留给子类来实现的钩子函数 讲完了特点这里列出几个最重要的函数来说一下,其他的自己看就可以了 addWorker函数主要分为两个部分,第一部分是增加工作线程计数,第二部分是创建工作线程,详细可以看代码块中我的注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: //for循环内的这部分是增加工作线程计数 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); /* 这里还是双重检测的作用,即时在调用addWorker之前已经检查过一遍了,比较有趣的是if中的逻辑判断 有点绕这里来解释下,意思为:如果线程池已经SHUTDOWN了,那么它将不再接受新的任务开启工作线程 (这里我们之前提到过,如果工作线程小于核心线程时,添加的任务会直接在新创建的线程执行) 但是有一种情况除外,那就是在SHUTDOWN状态下,firstTask等于null且队列中仍有任务(从文章一开始的三步 添加任务中可以看到,如果第一步判断时工作线程大于等于核心线程数,但是在判断结束之后工作线程全部 结束了(如果核心线程数设置为0或者线程池被结束了(当线程池被结束时,已经添加进来的任务不会被结束而是 等待其执行完毕)),那么如果后续没有任务再添加,我们现在队列中的任务将永远不会被执行 所以在三步添加任务的第二步中的双重检查,有防止这个问题发生的作用,他通过给addWorker传递一个值 为null的firstTask,促使其创建出一个工作线程继续完成队列中的任务) */ if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //接下来的为创建工作线程 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; //这里采用锁,个人认为是为了设置largestPoolSize时出现并发问题 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) //如果创建失败,会减少工作线程计数 addWorkerFailed(w); &#125; return workerStarted;&#125; 运行任务的方法,这个方法有个特点是,如果线程池结束,他仅仅会interrupt标识一下(这里有必要说明,interrupt并不是强制终止线程,而是做标记,具体线程的反应依赖于其代码实现),而不会做出任何反应,其终止仅仅依赖于getTask()的返回值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; //根据上文,如果传入的任务为null,或者如果第一个任务执行完了,则会去队列中获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) //这里仅仅做标记,并无法真正的终止线程 wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; //真正执行用户定义的任务 task.run(); &#125; catch (RuntimeException x) &#123; //抛出异常并不会造成终止,而是被本方法中外围的try捕获了,这一点可以参考FutureTask类中的操作,会将异常放置到一个对象中 thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask方法 12345678910111213141516171819202122232425262728293031323334353637383940414243private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) /* 此处就是之前提到的,CAS竞争从而停掉非核心线程,这里要强调一下,如果竞争失败,则会超时等待从 队列中获取任务,如果超时,则进行下一轮竞争请求返回null从而停掉本线程,直到工作线程等于核心 线程数才会一直阻塞等待从队列获取任务(前提是allowCoreThreadTimeOut==false,当然他的默认 值就是false,除非你主动对其进行了改变) */ return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125;]]></content>
      <categories>
        <category>源码</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何使用Unsafe类方法]]></title>
    <url>%2F2019%2F10%2F05%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Unsafe%E7%B1%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先Unsafe类是不建议被使用的,因为他面向底层,可能在每一代jdk版本中发生变化,除非你有把握在在每一次升级jdk时维护你的项目 Unsafe是作为单例而存在的,当我们尝试调用getUnsafe方法时,会报安全错误,这是由于双亲加载机制导致的。通常我们可以通过反射来绕过这些检测 在如下代码中,我们通过反射获取到了Unsafe类的实例,Unsafe类中的方法往往都是通过偏移量来操作对象的,我们可以看到,我们定义了Thread对象,并且通过objectFieldOffset获取其偏移量,在test()方法中,通过CAS来将其置换,成功的使用了Unsafe中的方法 1234567891011121314151617181920212223242526272829303132333435public class UnsafeTest &#123; private volatile Thread runner; private static final long runnerOffset; private static final Unsafe UNSAFE; static &#123; try &#123; Field f = Unsafe.class.getDeclaredField("theUnsafe"); f.setAccessible(true); UNSAFE = (Unsafe) f.get(null); //UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = UnsafeTest.class; runnerOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("runner")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; public void test()&#123; UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread()); &#125; public void print()&#123; System.out.println(runner); &#125; public static void main(String[] args) &#123; UnsafeTest unsafeTest = new UnsafeTest(); unsafeTest.test(); unsafeTest.print(); &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDEA修改java版本号]]></title>
    <url>%2F2019%2F09%2F15%2FIDEA%E4%BF%AE%E6%94%B9java%E7%89%88%E6%9C%AC%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[总共有4处需要修改,直接上图(在后面),如果懒得每次改版本号,也可以利用maven插件 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;自行找个版本&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[隧道连接redis集群报错]]></title>
    <url>%2F2019%2F09%2F15%2F%E9%9A%A7%E9%81%93%E8%BF%9E%E6%8E%A5redis%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[####问题描述&emsp;java springboot程序访问redis,由于redis集群分布于多个目标服务器上,且均有防火墙阻拦,平时调试都是通过tunnel建立隧道来访问。单个redis通过隧道访问成功,但是redis集群通过隧道访问失败。 使用的jar包如下 12&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; 单个redis连接时配置如下(已经提前建立好隧道) 12spring.redis.host: 单个ipspring.redis.port: 单个端口 redis集群连接时配置如下(已经提前建立好隧道) 1spring.redis.cluster.nodes: localhost:6379 按照单个redis连接配置时正常连接,按照集群配置时报错 1234567org.springframework.data.redis.ClusterStateFailureException: Could not retrieve cluster information. CLUSTER NODES returned with error. - ipA:端口A failed: Could not get a resource from the pool - ipB:端口B failed: Could not get a resource from the pool - ipC:端口C failed: Could not get a resource from the pool - ipD:端口D failed: Could not get a resource from the pool - ipE:端口E failed: Could not get a resource from the pool - ipF:端口F failed: Could not get a resource from the pool ####问题排查因为配置文件配置了生成环境开发环境测试环境等一系列的环境,分别对应不同的集群配置,因为当时只配置了一个ip端口,以为是读取配置文件出现错乱,所以在这方面排查了一段时间 后来通过分析源码发现了问题,我们在配置文件中配置的服务器ip和端口,在集群模式下仅仅相当于入口的作用。即,先与配置文件中的ip端口建立socket链接,然后发送cluster获取集群信息命令,然后断开该socket链接,转而直接跟各个集群服务器建立socket链接,从而导致后续请求不会走我们配置的隧道。也就出现了之前我们只配置了一个ip和端口缺出现了和6个redis均连接失败的情况,误以为时配置读取问题]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql设置默认值无效]]></title>
    <url>%2F2019%2F09%2F14%2Fmysql%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%80%BC%E6%97%A0%E6%95%88%2F</url>
    <content type="text"><![CDATA[场景:数据库mysql,框架hibernate 原因: 根据hibernate打印出的sql信息可以发现,如果实体类字段为null,则仍会insert这个字段为null,而mysql设置的默认值生效的前提是,当我们insert一条记录时,我们不指定某字段的值,他才会自动生成默认值,而我们用save的时候指定该字段的值为null,此时如果我们mysql设置的为not null,那么同时也会报错 解决: @DynamicInsert(默认为true) @DynamicUpdate(默认为true) 这两个注解是类注解,作用为:当插入/更新一条记录时,只insert/update改变的信息,而不是将所有字段都update为当前的 即,没有注解时update的sql为 12 Hibernate: select student0_.id as id1_0_0_, student0_.default_value as default_2_0_0_, student0_.password as password3_0_0_, student0_.username as username4_0_0_ from user_student student0_ where student0_.id=?Hibernate: update user_student set default_value=?, password=?, username=? where id=? 有注解时的sql为 12 Hibernate: select student0_.id as id1_0_0_, student0_.default_value as default_2_0_0_, student0_.password as password3_0_0_, student0_.username as username4_0_0_ from user_student student0_ where student0_.id=?Hibernate: update user_student set username=? where id=? 可以看到,当需要update时(如果没有做更改则无论有无注解均不会执行update命令),无注解的将所有字段全都update为当前值,有注解的则只update修改值。在每次update之前,均会执行select查询出数据库当前该字段的状态进行比较后在执行更新操作 网上有人说@DynamicInsert这个注解的作用是,如果值为null,则不set该值。 从片面的角度来看,这句话是对的,如果我们在save时指定id,因为insert对于一条记录只会出现一次,在执行insert之前,hibernate回去数据库执行select查询,如果查询不到数据,那么我们当前值的null和他当前缓存种的值null是相等的,就认为该值没有修改,在后面执行insert时mysql就会给该值赋予默认值。如果我们没指定id,那么他就不会select,同理,跟缓存中的null相等,在组建insert语句时就不会附带该值 那么有这么一种情况,假若我们save了一个新记录,然后又update该记录,但是在update时,有个字段我们没有赋值,其为null,那么跟从数据库select出的数据发生了变化,就会set null向数据库中,此时如果我们数据库时not null的,就会报错,反之,则会该字段的值被设为了null]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的锁]]></title>
    <url>%2F2019%2F08%2F28%2Fjava%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁的几种用法####synchronizede.g:1用synchronized对一个代码块加锁,object可以是任意的对象,任何其他synchronized(该对象)的代码块均需要获取到锁以后才可以执行,如果object=this,那么就是锁住的整个对象 123synchronized(object) &#123; //代码块&#125; e.g:2下方代码锁住的是此方法所在的对象,也就是如果该对象中两个不同的方法前面均有synchronized时,在多个线程操作同一个对象时,同一时间只有一个方法可以被调用 123public synchronized void work()&#123; System.out.println(123);&#125; e.g:3如果是对一个class或者static类型的对象加锁,那么因为class和static类型的对象只会在jvm虚拟机保存一份,所以加锁要额外注意e.g:4特别强调的一点是,synchronized是针对对象加锁,Class和static也可以看作一个对象,假如说出现下面代码,此时你的锁是无效的,虽然引用没变,但是引用指向的对象已经改变 123456Object obj = new Object();synchronized(obj)&#123; obj = new Object(); //代码块&#125;` 待续 拓展:分布式锁]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2019%2F08%2F28%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[####什么是锁?&emsp;锁是一个多方可以共同访问的元素,各个访问者通过对该元素的信息的判断,按照一定事先约定的行为进行协调的功能。这个元素可以是任何的东西,根据事先约定的行为的不同也会随之变化。 &emsp;例如,一个队列,如果来访者发现自己的id在该队列的头部,那么就认为自己拥有了锁,可以执行某些逻辑,这时候这个队列就相当于一个锁。锁也可以是一个boolean类型的对象,当他为true或者false时,其他线程可以来竞争使得boolean状态改变,从而认为自己获取了锁(当然需要考虑使用场景)。锁也可以是一个信号量,也可以是一个节点,例如zookeeper中,一个节点存在与否就意味着是否可以竞争锁(当然行为是我们自己来定的,zookeeper和redis仅仅是提供了一个放置锁的地方)。当然,最重要的一点就是原子性,我们在加锁和解锁的时候,要充分考虑使用场景来决定对锁的判断策略 ####redis锁的实现&emsp;对于redis分布式锁来说,常用的莫过于SETNX,SET,DEL这几个函数了tip:现在SET函数可以传递参数,例如过期时间,在已存在值时的反应,对于添加成功或者失败的返回值这几个元素,所以SET已经完全可以取代SETNX,甚至说比SETNX表现更好。因为SETNX在加锁时还要设置过期时间字段,需要由客户端根据这个字段来判断锁是否过期,这样一牵扯到非原子性的问题,就会十分复杂 &emsp;最简单的加锁解锁代码如下,由于在解锁时,伴随着锁过期的可能,我们需要先判断锁是否是本客户端加的,再去解锁,否则A加锁,A过期,B加锁,A完成任务解锁,就把B加的锁解掉了。解锁操作我们可以想象,他是先查询再操作,不是原子性,所以我们需要封装LUA脚本来使这两条语句具备原子性具体SET参数意义可以自行搜索 123456789101112131415161718192021222324252627282930313233343536/*** Non-blocking try to hold a lock* if true,the work must be finished within millisecond,else the distributed-lock is meaningless* @param key the key of lock* @param value a unique String,it will be used When release* @param expiration it will expirate after now+expiration* @return true if access,else false* */public boolean tryLock(String key,String value,long expiration)&#123; //try to create a record if not exist Object res = redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; JedisCommands connect = (JedisCommands) redisConnection.getNativeConnection(); //SETNX can be replace by SET from Redis 2.6.12 version return connect.set(key,value,"NX","PX",expiration); &#125;); return res!=null;&#125;/*** Non-blocking release a lock,if lock has expiration,nothing happen* @param key the key of lock* @param value the String you set When try to hold a lock* */public void relaseLock(String key,String value)&#123; redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; Object obj = redisConnection.getNativeConnection(); System.out.println(obj.getClass().getName()); if (obj instanceof JedisCluster) &#123; JedisCluster connection = (JedisCluster) obj; return connection.eval(LUA,Collections.singletonList(key),Collections.singletonList(value)); &#125;else if (obj instanceof Jedis)&#123; Jedis connection = (Jedis) obj; return connection.eval(LUA,Collections.singletonList(key),Collections.singletonList(value)); &#125; return null; &#125;) ;&#125; 虽然SET方法是瞬时的,无法阻塞,但是我们可以自己封装方法来达到阻塞加锁的效果 123456789101112131415161718192021222324252627/*** blocking try to hold a lock* if true,the work must be finished within millisecond,else the distributed-lock is meaningless* @param key the key of lock* @param value a unique String,it will be used When release* @param expiration it will expirate after now+expiration* @param overtime if getLock unfinish after overtime,return false* @param frequency the frequency try to get a Lock,more small it will have a large probability to get a Lock* and more pressure on the CPU,* @return true if access,else false* */public boolean getLock(String key,String value,long expiration,long overtime,long frequency)&#123; Future future = executor.submit(() -&gt; &#123; boolean flag = false; while (!flag)&#123; flag = tryLock(key,value,expiration); Thread.sleep(frequency); &#125; return flag; &#125;); try &#123; return (boolean) future.get(overtime,TimeUnit.MILLISECONDS); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; future.cancel(true); return false; &#125;&#125; tip:假如我们要做这种近似无限循环直到符合条件的操作,建议根据业务场景适当的Thread.sleep();让出cpu时间片,减少cpu压力。具体体现为,如果没有sleep,那么cpu的使用率在8线程测试机上直接飙升30%,而加入sleep后cpu使用率低于3%,另外true也可以改为flag标记位,以为今后增加中断功能做拓展 123while&#123;true&#125;&#123; //业务代码&#125; &emsp;上面我们说了分布式锁的简单加锁和解锁,那么接下来就出现了问题了,假如redis崩溃,我们的锁就全部失效。当然我们一般会搭建redis集群,每个redis都会有主从配置,但是有一点要注意,主从redis在同步的时候是异步的,无法保证实时一致性,也就是说如果我们A加了锁,主redis崩溃,锁未同步到从redis,B认为没有加锁,所以他可以成功加锁,这就产生了冲突,对于这种情况,antirez提出的redlock算法或许可以解决这个问题(还未仔细研究redlock算法,无法断言)]]></content>
      <categories>
        <category>探索笔记</category>
      </categories>
      <tags>
        <tag>distributed-lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简记20190927]]></title>
    <url>%2F2019%2F08%2F27%2F%E7%AE%80%E8%AE%B020190927%2F</url>
    <content type="text"><![CDATA[今天用到了metricbeat组件diskio.iostat部分,突然看到一个比较在意的点,对于system.diskio.iostat.read.request.per_sec这个字段,有的描述是每秒读取的扇区数,有的被描述成每秒访问磁盘数。一开始以为是翻译问题,突然联想到磁盘访问原理,我们对磁盘访问的最小单位是扇区,也就是每秒访问扇区数在这个场景下是可以等同理解为每秒访问磁盘次数的]]></content>
      <categories>
        <category>简记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Exception thrown when sending a message with key='null']]></title>
    <url>%2F2019%2F08%2F25%2FBUG_kafka_01%2F</url>
    <content type="text"><![CDATA[报错122019-08-20 18:45:09 [nioEventLoopGroup-3-15] ERROR o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key=&apos;null&apos; and payload=&apos;xxxxxxxxxxxxxx&apos; to topic abc-event:org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms. 原因&emsp;连接的远程kafka,服务器防火墙没开]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程模型]]></title>
    <url>%2F2019%2F08%2F17%2F%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[首先我们来谈一谈java中常见的几种IO线程模型 我们知道一般io(socket)都是由accept,read,write,close几种状态组成 ####同步阻塞(bio)在read时需要无限等待直到消息到达,就是阻塞,同步则指的是每一步都需要等待上一步完成然后被调用 ####同步非阻塞()同步阻塞和同步非阻塞的区别就在于,在read时无论是否有数据,立刻返回。那么或许有人会问了,这样有什么意义,还需要自己写while循环包裹来促使其不断访问直到数据到达。其实针对这一点,如果一个程序在底层进入了阻塞状态,也就意味着我们失去了对其控制,对于socket来说,我们只能通过close来使其断开连接离开阻塞状态,而如果我们是非阻塞的情况下,我们发现read数据未到达,可以先允许该线程去做其他工作,过一会再来read一次检测下消息是否到达,同时我们也可以通过标记位来控制其后续行为 ####io多路复用(nio)其实nio也被算作同步非阻塞,但是在使用时也可以成为异步非阻塞,不过我们不必拘泥于这些分类,在发展中,是先有的模型,后来才被分类,所以很多情况下分类是模棱两可的。io多路复用跟之前说的同步非阻塞有点关系,io多路复用的read也是非阻塞的,跟之前的最大区别在于,他采用了Selector选择器负责监听每一个socket的各种行为,当该行为被激活的时候,通知后续线程去处理。我们可以想象,此时有巨量的socket链接进来,我们需要为每一个socket创建一个线程来read(即使是使用线程池减少了创建线程的消耗,那么大量的线程也依旧会在while(){//read}上浪费掉),此时我们就需要一个方案来解放这些线程无意义的循环read一个管理者,来管理所有的Socket,这也就诞生了Selector选择器,由Selector负责检测是否有accept,read,write行为,并且通知其他线程来处理,这样我们可以节约大量线程,配合线程池我们就可以用有限的资源处理大量的连接假设我们将流程分类为,io监听和io接收,业务处理三部分,那么nio的核心就是在于将io监听给提取出来单独管理 ####异步说到异步,阻塞与非阻塞的界限更为模糊。下面让我们来看一段代码,这段代码并不是异步,他只是一个回调雏形,后面我会谈到 123456789101112131415161718192021public interface CallBack &#123; void callback();&#125;public class Main &#123; public void work(CallBack callBack)&#123; //业务代码省略... callBack.callback(); &#125; public static void main(String[] args) &#123; Main main = new Main(); System.out.println(1); main.work(new CallBack() &#123; @Override public void callback() &#123; System.out.println(2); &#125; &#125;); System.out.println(3); &#125;&#125; 如果你对代理模式比较熟悉,那么这里你肯定会产生疑问:这不就是代理模式么?嗯,没错,这个东西在我眼里就是代理模式,只不过我们一般使用的代理模式的代码是写死在代理类中,而这里我们传入了自定义的代码,这就是回调的雏形 你肯定会问,这有什么用?还不如直接在一个方法里从头到尾写下来。这是因为我们还没有引入其他的模型,假设我们引入多线程,那么我们的代码就成了这样 1234567891011121314151617181920212223242526public interface CallBack &#123; void callback();&#125;public class Main &#123; public void work(CallBack callBack)&#123; //业务代码 callBack.callback(); &#125; public static void main(String[] args) &#123; Main main = new Main(); System.out.println(1); new Thread(new Runnable() &#123; @Override public void run() &#123; main.work(new CallBack() &#123; @Override public void callback() &#123; System.out.println(2); &#125; &#125;); &#125; &#125;).start(); System.out.println(3); &#125;&#125; 通过对比,我们发现,引入了线程的概念后,他的意义就完全改变,变成了一种近似异步(不必在乎这些概念,你重点关注的应该是是否对于性能有真正的提升)的实现。假设我们面对这样一个场景(此处我们先以非阻塞为例,否则引入自变量过的多不宜于理解),两个socket AB互相长期通信,且每次通信在业务上(我们先将流程简单的分为为io,业务两部分)所需要耗费的时间是不确定的,假若说我们采用同步的方式,每一次A发往B,因B只有一根线程,需要顺序的处理读io,业务操作,写io后才可继续处理A的后续请求。而现在,我们将双方模型改为异步,A只要有请求就向B发送,无需等待B响应,当B读取完消息后(你可能会问A一直在发送消息,B怎么知道A是发送到一个请求还是两个请求,这一点你可以去了解粘包拆包的问题),将消息封装为一个任务,递交给线程池执行(执行完毕后会将执行回调函数来决定接下来的操作,由于任务耗时的不确定性,如果返回消息的话,消息的先后顺序也是不确定的,所以A在请求时需要附带消息的序列号),并立刻返回A一条消息表示自己已经接收到了请求。 到这里你会觉得一切豁然开朗,你仿佛明白了同步异步,阻塞非阻塞,感觉自己成为了大佬。但是,我刚才做的将同步改为异步的操作,真的提高了性能么,假设我线程池只设置一根线程,那么性能跟io和业务在同一根线程有区别么,这真的是异步带来的福利,还是仅仅是多线程带来的福利?我只不过是让A提前知道了,B已经接收到了来自A的消息,但是实际如果线程池只有一根线程的话,业务处理时间是不会改变的。那么异步的意义何在?仅仅是为了利用起多线程并发处理业务这个效果么? ……… 答案:&emsp;异步确实起到了利用多线程的作用,这里的异步我们要明确,异步并非是一个确切的概念,而是一个抽象宏观的概念,是针对于观察点而不断变化的,例如在当前这个场景中,如果A只有当收到B的处理结果才会继续发送,那么B的异步还算是真正的异步吗?我们当然可以说B是异步的,但是对于整体来说,他又是同步的,B在此时的是无法体现其性能优势的。假如说在这个基础上,有许许多多的A连接同一个B向其发送消息,此时B针对每一个连接起一个io线程(这里当然可以用Selector选择器配合io线程池),接到消息后扔到线程池(即使线程池只有一根线程,但是由于io是并发的,省去了io时间)去处理,这时候B又能体现他的性能优势了 那么接下来我们抛开异步同步阻塞非阻塞这个问题,从性能方面总结一下,之前我们提到的线程模型,变化繁多,那么他们为了性能所做的改变都有什么共同点呢?将职责精细划分,对于每一部分职责分别进行深度优化,使得每一部分职责成为一个组件,各组件之间相互通信,以避免某一组件因为另一组件的原因而造成无意义的等待在并发量低的环境下,由于我们机器可以开足够的线程来处理消息,即使义务处理因为io产生了等待,其他的消息也可以选择其他线程去处理。而当并发量增高,此时如果我们线程随之增高的话,会产生大量的线程上下文切换开销,所以我们不得不把控线程的数目,转而通过技巧来充分利用起每一条线程(例如线程池,组件功能划分等方式),这也就是这些线程模型存在并逐渐演化的原因 拓展: Tomcat源码笔记最尾处的Tomcat线程模型 待续]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码笔记]]></title>
    <url>%2F2019%2F08%2F14%2FTomcat%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ps:由于图片过大,所以限制了在博客中显示大小,大家可以右键查看图片看原图本系列均是基于9.0.21版本&emsp;本章我们不会涉及代码,而是笼统的分析Tomcat的实现原理,让大家对全局有一定的掌控,后面几章我会带大家分析代码 ####Tomcat是什么?&emsp;在我看来,Tomcat是利用各种模型和设计方式对socket的深度封装,做到适配各种协议同时达到一定性能的代码组,同时给我们写的各种业务代码(Servlet)提供了容器(也可以理解为tomcat可以将以对象的形式使用我们写的Servlet业务),这是Tomcat的核心。当然,Tomcat还实现了一些其他的比如生命周期管理,但是这些都是为了核心而服务的 &emsp;我们第一次接触Tomcat,相信大多数人都是Hello World。想想当时我们是怎么做的:首先我们建立了个项目,按照网上的教程建好了项目里面的文件夹,导入servlet包,然后开始编写xml配置文件,继承Servlet编写Get,Post代码,然后导出war包放到tomcat下的webapps文件夹,启动tomcat。so easy,然后我们就可以通过浏览器访问我们之前写好的接口了。 &emsp;但是,我们有没有想过是为什么,为什么我们GET中的代码会被调用,为什么我们访问一个网址会执行我们的代码,他又是怎么执行的。这一切,我们将从Servlet与Tomcat的源码解析中找到答案 ####消息接收&emsp;首先,消息是如何接收的。这里,我要阐述下自己的理解,在网络传输的世界里面,一切都是消息,消息是指什么?消息可以理解为一串二进制,一串byte或者字符串,当然,在网络模型的最底层,这些都会被转换为二进制来传输。 &emsp;协议又是什么?协议是一种事先约定的规范,规定了消息格式,消息处理方式等等各种机制,例如我们编写servlet最常用到的http协议,他的可视化表示就如同下面这些内容,其实,每一行后面都跟着\r\n,不过这是换行符,所以在屏幕上展现出来就是一行一行的数据 12345678GET / HTTP/1.1Host: localhost:8080User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:68.0) Gecko/20100101 Firefox/68.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateConnection: keep-aliveUpgrade-Insecure-Requests: 1 &emsp;了解了这些以后,我们就可以继续进行了,既然一切都是消息,那么当我们发送一个http请求的时候,Tomcat最开始接收到的也是一串像是上面这种的字符串,java中接收消息用的就是socket,Tomcat也不例外。所以我在文章最开始的时候说到,Tomcat实质就是对socket的深度封装。在获取到socket套接字以后,Tomcat开始解析,根据传入内容标明协议的不同,按照在代码中定义好的各种协议模板来解析这个字符串,解析完成后封装到Request和Response中交给Servlet执行用户自定义的业务代码,最后再由socket发送响应,这就是Tomcat最浅显的流程 生命周期Tomcat的各个组件也是有生命周期的,这个生命周期由一种设计模式(状态机)来控制,下面让我们了解一下 首先要介绍的是LifecycleMBeanBase类,下面是这个类的类图 我们从Lifecycle接口开始了解,Lifecycle定义了一个状态机,下面是Lifecycle的原注释 12345678910111213141516171819202122232425262728* start()* -----------------------------* | |* | init() |* NEW -»-- INITIALIZING |* | | | | ------------------«-----------------------* | | |auto | | |* | | \|/ start() \|/ \|/ auto auto stop() |* | | INITIALIZED --»-- STARTING_PREP --»- STARTING --»- STARTED --»--- |* | | | | |* | |destroy()| | |* | --»-----«-- ------------------------«-------------------------------- ^* | | | |* | | \|/ auto auto start() |* | | STOPPING_PREP ----»---- STOPPING ------»----- STOPPED -----»-----* | \|/ ^ | ^* | | stop() | | |* | | -------------------------- | |* | | | | |* | | | destroy() destroy() | |* | | FAILED ----»------ DESTROYING ---«----------------- |* | | ^ | |* | | destroy() | |auto |* | --------»----------------- \|/ |* | DESTROYED |* | |* | stop() |* ----»-----------------------------»------------------------------ 我们可以看到,这是一种状态机设计模式,规定了组件生命周期的状态转换,可以方便的进行组件生命周期的管理,从下图我们可以看到,从Server开始几乎每一个组件间接继承/实现了该状态机 接下来让我们看LifecycleBase,这是一个抽象类,实现了fireLifecycleEvent,init,start…等方法fireLifecycleEvent的设计其实是根据观察者模式init,start等方法仅仅是用来控制其生命周期的,每个方法例如init,在内部还会调用initInternal(),Tomcat的很多组件的业务代码全部都在xxxInternal()中,由子类负责实现 LifecycleMBeanBase则对LifecycleBase进行了进一步的实现,我们从他的图中可以看到 其中最关键的是initInternal()和destroyInternal(),主要实现了委托Register类来将子类(类如StandardServer等)注册到bean容器中。容器部分设计是符合JMX规范的,此处暂且不谈,如果在看源码过程中大家对ManagedBean或者MBeanServer抱有疑惑,可以先去学习一下JMX规范再回来看容器部分代码,不过即使跳过容器部分,也不影响接下来的部分 Tomcat初始化流程(仅需有个印象即可,想要学到东西的话还是要自己去研究代码)Tomcat工作主要有几个流程:init(负责new各级对象,组件依赖关系,加载配置文件),start(这一步完成时可以正常接收请求开始处理),处理消息,结束首先放一张tomcat init的流程图(简化版) Bootstrap:是入口,例如命令行输入service tomcat start等操作时,便是由这个类来解析,这个类均通过反射操作来调用Catalina Catalina:提供了操控Tomcat启停等行为的方法 LifecycleBase:状态机设计模式,我们后文会提及,StandardServer等大部分组件都会实现该状态机 StandardServer:顶级容器,一个Tomcat对应唯一一个Server,负责管理多个service的启停等行为 StandardService:可以完整执行功能的最小单元容器(如果不明白可以先继续看),下面是一个server.xml文件去掉注释后的内容,根据xml我们可以清楚的看到其构建逻辑,Server包含Service,Service包含Connector和Engine,Engine包含host。假如我们现在面临一个问题,有两个同名的项目需要发布或者希望不同项目部署在不同的端口,那么我们就可以在后面新增一个service 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; ScheduledThreadPoolExecutor:线程池,后面我在讲述线程模型的时候会讲到 Container容器模块,呈现包含关系,之间以责任链形式调用,这里注意一点,虽然方法名是invoke,但实际上并不是通过反射来调用,类似的在tomcat中也有很多继承了Runnable但是有些模块用不到start而是使用run的情况{ Engine{ Host{ Context{ Wrapper } } }} Endpoint:核心部分,后面讲线程模型我会提到 Tomcat的start流程其实跟init流程类似,在宏观上几乎没有改动,因此省略 ####Tomcat接收消息流程这里我认为一张图足以 ####一些关键的节点这里将提供一些消息在Tomcat中传递的关键节点,可以帮助大家通过全局搜索快速定位到源码 init时:&emsp;这里有人会疑惑类的初始化和注入依赖在哪里,答案是digester.parse。这种感觉就像是我们写springMVC时配置的xml一样,在这里xml就是server.xml,digester会根据这个xml来解析并注入依赖 NIO接收消息时:&emsp;关键类Acceptor,其run方法是核心,endpoint.setSocketOptions是转折点,随后一系列操作将accept到的封装为PollerEvent加入队列&emsp;关键类Poller,从队列取处PollerEvent注册到socketChannel的Selector选择器中,并且负责轮询读写事件,将其封装后扔到线程池中&emsp;关键类SocketProcessor,被上文封装的Runnable,负责接下来的读取解析处理返回操作&emsp;关键类Http11Processor,inputBuffer.parseRequestLine获取并解析请求,如果是文件传输类型,那么不会解析消息体,如果是表格那种文本的,就会一起读取出来&emsp;具体从socket读取消息的地方:Http11InputBuffer类的socketWrapper.read。NioSocketWrapper类的nRead = fillReadBuffer(block, to)&emsp;关键类Http11Processor。inputBuffer.parseHeaders将读取出的消息解析为消息头 ####这里我们讲Tomcat线程模型 基础知识:线程模型 TomcatNIO的线程模型其实非常简单,简单到什么程度?让我们看图 甚至于io操作和业务操作在同一根线程上进行,没有经过分离,poller的职责仅仅是检测事件,并不负责io操作, 注意这仅仅是NIO模式,不包括另外两种NIO2和APR模式 我们看server.xml配置文档的时候可以看到允许我们设置一些参数,这里之前tomcatNIO接收请求逻辑图已经描述过,不再赘述。 至于Poller,你在看旧文章时有人会说允许最大值不超过2个。没错,在之前的版本是这样,但是在9.0,我们看到注释文档中有句话,在NIO下Poller被改为仅有一个 1234&lt;update&gt; Remove &lt;code&gt;pollerThreadCount&lt;/code&gt; Connector attribute for NIO, one poller thread is sufficient. (remm)&lt;/update&gt; 通过这些,我们可以分析到,Tomcat NIO模式下,是通过粗暴的增加线程来处理请求,如果同时请求数过多,会被ServerSocketChannel阻拦掉,如果交给线程池的read达到线程池上限,那么就会加入队列中进行排队,这也就是Tomcat无法承受大量并发的原因所在]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于全面屏手机app点击无效问题]]></title>
    <url>%2F2019%2F07%2F14%2F%E5%85%B3%E4%BA%8E%E5%85%A8%E9%9D%A2%E5%B1%8F%E6%89%8B%E6%9C%BAapp%E7%82%B9%E5%87%BB%E6%97%A0%E6%95%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[概要&emsp;最近使用红手指(云手机)时触摸频繁失效,不被响应 现象&emsp;1.在使用云手机时,操作越频繁,失效概率越大&emsp;2.大约2-3分钟失效一段时间&emsp;3.点击左侧调整画质按钮后,可以恢复正常一段时 间(有时调整画质按钮也无法响应)&emsp;4.app的log日志中并没有接收到点击事件 原因&emsp;由于水滴屏等屏幕在运行此类app没有对流海屏做适应时,摄像头左右存在一个真空带,这个真空带在我们日常使用时是极容易被手掌内侧挤压(手越胖越容易,当然也与使用习惯有关),被挤压时因为其显示黑色使我们下意识认为这已经不属于屏幕范围,但是在挤压时会破坏一部分app的点击监听事件,导致app无法接收到操作请求,让用户以为是app未响应或者其他的问题]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端添加数据后动态刷新时获取获取后端数据是旧的]]></title>
    <url>%2F2019%2F07%2F05%2F%E5%89%8D%E7%AB%AF%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE%E5%90%8E%E5%8A%A8%E6%80%81%E5%88%B7%E6%96%B0%E6%97%B6%E8%8E%B7%E5%8F%96%E8%8E%B7%E5%8F%96%E5%90%8E%E7%AB%AF%E6%95%B0%E6%8D%AE%E6%98%AF%E6%97%A7%E7%9A%84%2F</url>
    <content type="text"><![CDATA[情况一(后端缓存)第一种情况是由于后端使用了缓存,且添加数据后由于后端代码问题导致缓存刷新不及时产生的 情况二(前端异步请求)由于服务器响应请求总会有延迟,前端前后相差几毫秒发出了修改请求和查询请求。这种情况下由于网络问题,前端会出现有时可以刷新成功,有时旧数据的情况。解决方法就是前端同步下请求,收到第一个请求的返回后再发送下一个请求]]></content>
      <categories>
        <category>BUG</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql大小写问题]]></title>
    <url>%2F2019%2F07%2F02%2Fmysql%E5%A4%A7%E5%B0%8F%E5%86%99%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[直接上报错,简单来讲就是报错说表没找到 123456782019-07-02 12:26:48.782 WARN 16022 --- [nio-8080-exec-2] o.h.engine.jdbc.spi.SqlExceptionHelper : SQL Error: 1146, SQLState: 42S022019-07-02 12:26:48.782 ERROR 16022 --- [nio-8080-exec-2] o.h.engine.jdbc.spi.SqlExceptionHelper : Table &apos;summertrain.Market_good&apos; doesn&apos;t existorg.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement ...Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement ... 74 moreCaused by: java.sql.SQLSyntaxErrorException: Table &apos;summertrain.Market_good&apos; doesn&apos;t exist ... 92 more 由于团队成员都会先从本地进行调试,本地调试成功就会推送到远程服务器让其自动部署本次情况发生时,成员本地调试通过,远程确报错如上内容 这是由于大小写问题引起的,写这个错误的成员,其本地数据库大小写不敏感,而我们远程服务器使用的mysql大小写敏感,从而summertrain.Market_good,M大写导致出现异常在更改其所有大写M为小写m后,推送到服务器,测试了可以正常使用 如果不想mysql对大小写敏感的话,可以在my.ini配置文件的字段mysqld下增加：lower_case_table_names=1(0表示大小写敏感,1表示不敏感,2表示存储时按大小写,比较时统一按小写比较)。如果我们设置表名大小写的话,需要操作系统支持,例如有的操作系统对于文件名是不区分大小写的,此时设置0会导致mysql启动异常]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>base</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[i++不是原子性操作]]></title>
    <url>%2F2019%2F07%2F02%2Fi%2B%2B%E4%B8%8D%E6%98%AF%E5%8E%9F%E5%AD%90%E6%80%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[正文 1234567891011121314151617public class CasStudy01 &#123; private static int count = 0; public static void main(String[] args) &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; count++; &#125; &#125;; for (int i = 0; i &lt; 10000; i++) &#123; new Thread(runnable).start(); &#125; Thread.sleep(1000);//为了等子线程全部运行结束 System.out.println(count); &#125;&#125; 输出:9945 Process finished with exit code 0 刚才的代码,照我们的设想,他应该是输出10000,然而每次我们run这段demo,输出结果各不相同这是因为count++这一行代码并不是原子操作,这一行代码实际在运行时,被分为取值,修改,存储三步操作,所以1,2两个线程同时取出值a,并且自增1修改为a+1,再存储的话,两次自增实际上只自增了1]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AtomicLong]]></title>
    <url>%2F2019%2F07%2F02%2FAtomicLong%2F</url>
    <content type="text"><![CDATA[正文一.AtomicLong是做什么用的首先我们可以先看一下我的另一篇文章i++不是原子性操作 此时,我们通常选择会是进行这样的操作 123456789101112131415161718192021public class CasStudy01 &#123; private static int count = 0; private synchronized static void add()&#123; count++; &#125; public static void main(String[] args) throws InterruptedException &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; add(); &#125; &#125;; for (int i = 0; i &lt; 10000; i++) &#123; new Thread(runnable).start(); &#125; Thread.sleep(1000); System.out.println(count); &#125;&#125; 我们将count++操作放在了一个带锁的方法里面,来保证其线程安全性。然而,我们知道,加锁解锁操作会造成性能的消耗,在并发量不算太高的情况下,我们可以考虑采用AtomicLong(无锁的方式,采用/2019/07/02/CAS机制/)来保证线程安全性 二.AtomicLong的实现AtomicLong在源码中持有Unsafe类的实例,其大部分操作都是交付给Unsafe类来完成的(Unsafe中大多是本地方法,虽然我们可以通过反射来调用,但是官方强烈不建议我们这么做) AtomicLong里面持有一个long类型的valueOffset变量,这个变量表示的是其value值的内存偏移量(详见JVM内存模型),当我们调用incrementAndGet时,会交付Unsafe类来进行操作 123public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;&#125; 我们传入本类的实例,value的偏移量,以及增加量 12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 在Unsafe中就会进行CAS操作,使得value增加1,这是线程安全的 三.AtomicLong的缺点当并发量极大的时候,由于CAS机制本身的原因,导致CAS失败率极高,从而拖慢性能。此时,我们可以考虑使用LongAdder(待补充)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS机制]]></title>
    <url>%2F2019%2F07%2F02%2FCAS%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[正文一.什么是CAS机制CAS机制的全名叫做compare and swap让我们来看一行代码 1public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 这行代码源于Unsafe类(待补充),参数var1和var2我们先不考虑,var4表示旧值,var6表示新值,这行代码的作用是,如果var4的值等于内存中的现有值,那么将内存中的值替换为var6同时返回true,否则返回false。这就是CAS机制,同时也是其在Java中的体现 二.为什么要使用CAS/有哪些好处一般情况下,当我们并发访问同一个int变量时,我们往往需要加锁操作,但每次加锁会造成大量的开销,影响性能,所以就有了CAS机制,可以让我们在不加锁的情况下做到线程安全 三.CAS机制存在哪些问题1.ABA问题先看一段代码,代码源于Unsafe类①这一步的意义是得到内存中的现有值(参数可忽略) 12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2);① &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6; &#125; ABA问题简述:如代码所示,假设存在线程1,2。线程1运行了①之后等待,线程2开始运行,线程2将A改变为B,再将B改变为A,线程2结束,线程1继续运行,此时,线程1会认为A依旧是原来他读取到的A,期间并没有改变,并且将他按照正常流程改变为B。当然,在正常情况下,变量加减方面这并不会造成什么影响,但是若将CAS用在堆栈或者链表上(网上搜索一下有很多这种ABA问题的例子),或由于业务错误,同时发出了两次修改金钱100为50的操作,但是此时又加入了一个修改金钱50为100的操作(参考自漫画：什么是CAS机制？（进阶篇）),那么就会出现严重的问题解决方案:最常见的ABA问题的解决方案就是诸如java并发包中的AtomicStampedReference类,其内部实现类似于。不同点是,其内部维护了一个内部类Pair,采用记录版本号的方式来避免ABA问题,不过每次在更改时都会new一个新的Pair来进行CAS,如果对性能有极高的要求,那么需要谨慎选择 2.由于在使用CAS时,往往使用的是重试机制,即在while循环中一直重试CAS直到成功为止,所以在极高并发情况下,CAS的失败率将增大,会导致严重的性能问题,对于这个问题,很多时候解决方案是在一般程度并发时采取CAS,极高并发时进行排队]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jpa查询部分字段获取实体类]]></title>
    <url>%2F2019%2F07%2F01%2Fjpa%E6%9F%A5%E8%AF%A2%E9%83%A8%E5%88%86%E5%AD%97%E6%AE%B5%E8%8E%B7%E5%8F%96%E5%AE%9E%E4%BD%93%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[代码已经放到github,test测试中的demo2对应的是sql方式,demo3对应的是hql方式,demo1是分页查询,我另一篇文章会讲到github地址 前言我们平时使用jpa查询时,有两种情况,一种是查询全部字段,另一种是查询部分字段,当我们按通常的sql语句写法查询部分字段时,会出现jpa无法自动解析类型的情况,例如这类报错 1org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute query; SQL [ SELECT sa.name FROM student sa ]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute query 解决方案针对hql和sql分别有两种解决方案 一. &emsp;hql情况下,我们可以用这种方式来解决,有必要注意的一点是,Student里面一定要有相应的构造类 123//TODO 查询部分字段的demo-hql@Query(value = " SELECT new Student(s.name) FROM Student s")List&lt;Student&gt; temp03(); 二. 在sql情况下,我们可以用这种方式解决,首先我们将查出来的数据领jpa解析为map,然后通过我们自己写的map转实体类方法来解决 1234//TODO 查询部分字段的demo-sql@Query(value = " SELECT sa.name FROM student sa ", nativeQuery = true)List&lt;Map&lt;String,Object&gt;&gt; temp02(); 下面是我自己写的一个map转实体类的工具方法 1234567891011121314151617181920212223242526272829303132333435363738/**将map转换为实体类,在jpa查询部分字段时会用到* 使用的时候注意,因为int类型会初始化的问题,无法被FASTJSON忽略掉,所以返回的json可能会带有额外的数字0* 由于是通过属性名来匹配,所以如果数据库字段名和参数名不一致,会导致部分字段映射不到实体,应该这么写* @Query(value = " select id,bar_code01 barCode01,bar_code02 barCode02,bar_code03 barCode03,name,comment from library_good ",nativeQuery=true)* 在查询时取别名,将其跟类的属性名一致 */public static &lt;T&gt;T mapToEntity(Map&lt;String,Object&gt; map,Class&lt;T&gt; targetClass) throws IllegalAccessException, InstantiationException &#123; Class superClass; Field[] fields; T target = targetClass.newInstance(); //接收targetClass的Field List&lt;Field&gt; targetfieldList = new LinkedList&lt;&gt;(); superClass = targetClass; while(superClass!=null&amp;&amp;superClass!=Object.class)&#123; //由于该方法只能获取superClass的参数(private,protect,public等任何声明),但无法获取父类的参数,这里我们迭代一波 fields = superClass.getDeclaredFields(); targetfieldList.addAll(Arrays.asList(fields)); superClass = superClass.getSuperclass(); &#125; //匹配并赋值 for (Field targetfield : targetfieldList) &#123; for (Map.Entry&lt;String, Object&gt; mapEntry : map.entrySet()) &#123; if (targetfield.getName().equals(mapEntry.getKey()))&#123; //暂时保存权限 boolean targetFlag = targetfield.isAccessible(); //赋予权限 targetfield.setAccessible(true); //赋值 targetfield.set(target,mapEntry.getValue()); //恢复原权限 targetfield.setAccessible(targetFlag); break; &#125; &#125; &#125; return target;&#125; 有一点需要注意,由于其底层用了反射,所以无论是通过该种方式取数据还是存数据,均需要setAccessible(true),否则会出现IllegalAccessException异常]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux安装jdk(非openjdk)]]></title>
    <url>%2F2019%2F07%2F01%2Flinux%E5%AE%89%E8%A3%85jdk(%E9%9D%9Eopenjdk)%2F</url>
    <content type="text"><![CDATA[1.官网下载压缩包,这里我下载的是解压版不是rpm版本,现在可能需要你登陆才可以下载,自己去注册个账户吧,或者用其他方式得到压缩包oracle下载jdk8的网址 2.解压压缩包tar -zxvf 你压缩包的名字.tar.gz 3.安装vim,这是个文本编辑器,你可以把它理解为记事本这种东西,至少我的ubuntu18.04是不自带vim的你可以使用sudo apt install vim这条命令安装,也可以在命令行输入vim按照他的提示安装 3.修改配置文件,原理跟window一样,只要将路径添加到配置文件中,操作系统就可以检测到我们想要安装的东西vim /etc/profile(这里需要注意了,要用root权限进行,前面加sudo) 4.打开配置文件后,我们在尾部追加如下内容,vim的操作方式请自行搜索 123export JAVA_HOME=你的jdk目录,注意是根目录,不是bin目录export CLASSPATH=$JAVA_HOME/lib/export PATH=$JAVA_HOME/bin:$PATH 5.使操作系统重新加载配置文件,注意需要root权限source /etc/profile 6.输入java -version出现java版本信息即我们配置成功了]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>base</tag>
        <tag>linux</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[getParamter为何接收不到postman构造的信息]]></title>
    <url>%2F2019%2F06%2F28%2FgetParamter%E4%B8%BA%E4%BD%95%E6%8E%A5%E6%94%B6%E4%B8%8D%E5%88%B0postman%E6%9E%84%E9%80%A0%E7%9A%84%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[之前发生了这样一件事,由于是用的postman发送的消息,消息体有几种常用构造方式:none,form-data,x-www-form-urlencoded有一些构造方式通过getParameter方法是获取不到数据的,接下来让我们一起看一下这个问题 首先我对两种构造方式进行了抓包,看到他们发出去的请求首先时form-data格式下的Get,Post方式 1234567891011121314151617181920GET http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------130695699130126180335395User-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 255c0f6d-0296-4095-af08-3a0bc1e1f756Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 281Connection: keep-alive----------------------------130695699130126180335395Content-Disposition: form-data; name=&quot;username&quot;admin----------------------------130695699130126180335395Content-Disposition: form-data; name=&quot;password&quot;123456----------------------------130695699130126180335395-- 123456789101112131415161718192021POST http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------666026373795318990654180User-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: f7e5f00a-65d9-4aba-961d-34762e8c410cHost: localhost:8080accept-encoding: gzip, deflatecontent-length: 281Connection: keep-alive----------------------------666026373795318990654180Content-Disposition: form-data; name=&quot;username&quot;admin----------------------------666026373795318990654180Content-Disposition: form-data; name=&quot;password&quot;123456----------------------------666026373795318990654180--` 接下来是x-www-form-urlencoded格式下的Get,Post方式 123456789101112GET http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: application/x-www-form-urlencodedUser-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 7e03a95e-5539-4a2a-b0e7-0fe399a4af28Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 30Connection: keep-aliveusername=admin&amp;password=123456 123456789101112POST http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: application/x-www-form-urlencodedUser-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 13ed95bb-803d-451c-b046-db4e5eb142b2Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 30Connection: keep-aliveusername=admin&amp;password=123456 根据实验结果,在POST模式下x-www-form-urlencoded才可以通过getParameter获取数据,那么导致这一问题的原因是什么呢?通过代码,锁定了Tomcat Request类的parseParameters方法 12345678910111213141516//这里对消息格式进行判断if ("multipart/form-data".equals(contentType)) &#123; parseParts(false); success = true; return;&#125;//在这一行对method进行了判断,如果是POST,则进行接下来的解析,如果是其他的,那么直接返回if( !getConnector().isParseBodyMethod(getMethod()) ) &#123; success = true; return;&#125;//这里对消息格式进行判断if (!("application/x-www-form-urlencoded".equals(contentType))) &#123; success = true; return;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet源码笔记]]></title>
    <url>%2F2019%2F06%2F28%2FServlet%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要简单介绍下servlet源码结构 介绍首先类的主要结构关系需要提及一下 1234567891011121314151617模块一interface ServletRequestinterface HttpServletRequest extends ServletRequestclass ServletRequestWrapper implements ServletRequestclass HttpServletRequestWrapper extends ServletRequestWrapper implements HttpServletRequest模块二interface ServletConfiginterface Servletabstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializableabstract class HttpServlet extends GenericServlet 看到上面的类继承关系可能会有点陌生,接下来我给出一段demo 123456789public class HelloWord extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response)&#123; &#125; @Override protected void doPost(HttpServletRequest request, HttpServletResponse response)&#123; &#125; 好了,这下应该不陌生了,我们用Servlet写代码一般都是继承HttpServlet来进行,这属于第二模块,而我们代码中操作的request属于第一模块 在具体分析代码之前,有必要先科普下Servlet的生命周期,平时我们在写Servlet服务端的时候,是没有main入口类的,仔细想想,没有入口类为何可以启动?答案来了,是因为tomcat,如果将Servlet看作对象的话,那么tomcat就是Servlet的容器,tomcat负责操控Servlet的生命周期,tomcat从他自己的入口类启动,运行时调用Servlet从而进行一切操作。我看了很多的博客教程,他们都是这么说的: 1&amp;emsp;tomcat作为servlet容器,当http请求进来时,发现没有servlet,那么则初始化一个servlet,将http请求封装为Request交给servlet处理,且servlet为单例重复使用,若长时间未调用才会销毁 但是在tomcat8.5.28+servlet4.0环境下,在不调整任何参数时(默认),我的测试跟上述操作有点出入,servlet并不是在接到http请求时才初始化,而是在随tomcat启动时便已经初始化,这一点可以根据我对servlet初始化init方法打断点,并且以debug方式启动可以看出,各位尽可以自行尝试,当然这不是重点,大体流程了解即可。 首先我们从第二模块开始 Servlet这个接口类定义了一系列与tomcat相互交互的一系列接口 ServletConfig看名字也知道是提供配置信息的一个接口 GenericServlet这个是对Servlet和ServletConfig接口的一些实现,另外增加了一些log方法来传递异常 HttpServlet这个类就定义了对GET,PUT,POST,HEAD,DELETE等各种HTTP方法的处理方式那么问题来了,我们知道之前定义的Servlet接口类提供给tomcat一些交互接口,那么唯一涉及到各种操作的只有service方法,他是如何跟各种HTTP方法的处理结合起来的呢?在源码面前的朋友可以追着service方法一路下来,最终在HttpServlet中可以看到service方法的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 从代码中可以看到,他是负责匹配头部信息来进行分发操作,不清楚http报文的朋友可以看下面,这是用firefox浏览器发送的一组请求,第一行的GET即为method.equals(…)中的method内容 12345678910GET / HTTP/1.1Host: localhost:8080User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:67.0) Gecko/20100101 Firefox/67.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateConnection: keep-aliveUpgrade-Insecure-Requests: 1Pragma: no-cacheCache-Control: no-cache 到此为止第二模块基本结束 接下来分析第一模块 ServletRequest主要用来获取被储存信息,例如储存被tomcat封装后的http信息 HttpServletRequest特别针对http协议的各种参数在ServletRequest基础上进行了扩展 ServletRequestWrapper也是个扩展,不过有个特殊的地方要注意,这个类的构造方法public ServletRequestWrapper(ServletRequest request)接收了一个ServletRequest对象,以后的参数就从这个对象里面拿取 HttpServletRequestWrapper就是上面三个类的实现了,没什么意思 #####通过这些介绍,Servlet已经不再神秘,大家可以仔细去看源码,其实Servlet构造十分简单,真正起到关键作用的还是例如Tomcat等Servlet容器基础知识:Tomcat源码笔记]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用git完成服务器自动化部署解决方案]]></title>
    <url>%2F2019%2F06%2F24%2F%E5%88%A9%E7%94%A8git%E5%AE%8C%E6%88%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言本篇主要讲述在团队合作时,如何利用脚本和git在前后端分离模式下,测试时的服务器自动化部署问题(只是个人想法和实践,仅作参考。下方代码已经经过测试,保证做好适配后可用) 适用情况:团队合作,前后端分离,后端需根据前端需求持续变更代码并提供给前端测试 需要的环境:linux服务器,git,maven,java 2019.6.25更新昨天忘记了说一个重要的问题,如果你是在window环境下写的shell脚本到linux环境下运行,由于两者系统换行符不一致,需要在linux中执行vim你的脚本名,进入脚本:set ff=unix,注意”:”这个符号需要带着,不明白的请去搜vim命令一定要赋予脚本可执行权限,赋权具体命令下文sh代码有提及刚才看了些博客,有提到用hook触发,而不是自己去循环访问,思路待定 原答案&emsp;首先讲成果,上代码,我会在其中伴随大量讲解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#!/bin/sh###本代码中的该项目特有名称均会用其他文本代替,例如我的项目名就用demo代替###该项目的git文件夹我们暂且称呼为demofunction updateAndRestart()&#123; #切换到online分支,这个地方需要根据自己的git分支做适配 git checkout online #git rev-parse online命令用于查看本地的online分支最后一次提交id LOCALONLINE=$(git rev-parse online) #用于这句话就是打印到控制台,没什么意义 echo "本地ONLINE为$&#123;LOCALONLINE&#125;" #从远程仓库fetch,这里选择fetch而不是pull也是为了性能考虑,如有偏差,请根据自己想法修改 git fetch echo "从远程仓库拉取结束" #获取已经fetch下来的远程仓库的HEAD,这里要做郑重说明,如果git rev-parse orgin/online虽然是获取远程仓库online分支的最后一次提交,但是他不会真的去连接远程仓库拉取信息,而是读取本地的远程仓库的缓存信息,所以之前需要git fetch也是为了刷新本地缓存的作用。 #关于如何直接去远程查看远程仓库最后一次提交这个问题,我找了一半天没有找到这个方法 REMOTEONLINE=$(git rev-parse origin/online) echo "远程HEAD为$&#123;REMOTEONLINE&#125;" #检查远程仓库是否与本地ONLINE一致,若不一致,则证明了远程已更新 if [[ $LOCALONLINE != $REMOTEONLINE ]]; then echo "进入重启-------------------------------------------" #将远程分支的更新合并到本地,由于git pull命令可以理解为git fetch+git merge,这一步的意义这里不做赘述 git merge $REMOTEONLINE #杀死所有名为下列的进程 #这里只讲一点,由于awk命令下文介绍过,那么此时可以想象文本状态是kill -9 进程pid,sh命令是把之前的输出当作脚本来执行,那么就成果实现了批量kill进程 jps | grep demo.jar|awk '&#123;print "kill -9 " $1&#125;'|sh #重新打包jar mvn clean package #给jar授权 #这里有必要作下说明,此脚本我是运行在root用户下(这点很重要,如果是其他用户,则在权限方面需要注意做适配) #chomd是赋权命令,后面参数则是其权限,参数每部分的具体意义请自行查询 #这条命令是授予demo.jar的root用户可执行权限(原本被mvn打包后默认为读写权限,没有执行权限) chmod 744 /你的目录/demo.jar #这个文件我不知道是什么,在window环境下尝试情况,删除了也不会有什么影响。有人说.jar是不带依赖的,original是带依赖的,但是观察文件大小,发现original文件只有几十k,明显不是带着依赖一起打包的样子 chmod 744 /你的目录/demo.jar.original #后台运行jar,具体意义可见后半部分文章 nohup java -jar /你的目录t/demo.jar &gt; /你的目录/xxx-`date +%Y-%m-%d-%H-%M-%S`.log 2&gt;&amp;1 &amp; sleep 15 fi&#125;###上面的是函数,只有调用时才会运行,首先运行的是下面代码#首先cd到你的demo存放目录,这一步可有可无,根据你的项目路径做好适配就行cd /xxx/xxx/demo#下面这行代码是脚本启动时用来检测是否demo程序正在运行#这里顺便讲解下shell和java的知识# jps该命令可以理解为和ps命令类似,只不过是用来显示java进程# |这个管道命令我无法解释,自己去搜索引擎# grep用来抓取出包含demo.jar字段的行# awk一种文本处理命令,将文本按照我们定义的规则处理# 这里'&#123;print $1&#125;'代表的是输出每行的第一个参数(在我的linux系统中,每行的第一个参数正好是java进程的pid,其他人需要根据情况适配,注意'引号一定要有)# wc -l是统计命令,由于之前都是一行一行打印的,所以此命令可以很轻松统计有多少在运行# 综上所述,该条命令的意义在于:统计名为demo.jar的java进程的数目,awk这段命令后来想了想属于冗余命令了,可视情况去除SUMMERTRAINPID=$(jps | grep demo.jar |awk '&#123;print $1&#125;' |wc -l)if [[ SUMMERTRAINPID!=0 ]]; then echo "脚本开始,检测到程序未启动,先启动程序------------------------" #summertrain-`date +%Y-%m-%d-%H-%M-%S` #下面这条命令是在后台启动demo.jar并且将输出重定向到指定的log文件,如果文件不存在会新建 #其实nohup java -jar /你的路径/demo.jar &gt; /你log日志的路径/文件名.log &amp;这条命令就可以做到这一点 #下面这条命令多出来的几个字段表示的是将error日志也重定向到log文件 #小提示,在自己的脚本,log日志太长不易于观看,所以可以文件名可以在后缀加上`date +%Y-%m-%d-%H-%M-%S`,参数可以在生成文件时自动加上当前实际后缀,例如demolog-`date +%Y-%m-%d-%H-%M-%S`.log nohup java -jar /你的路径/demo.jar &gt; /你log日志的路径/文件名.log 2&gt;&amp;1 &amp; #这里我令他休眠15秒等待java程序启动 sleep 15fi#接下来开始循环检测是否git有更新while truedo echo "自动循环中" updateAndRestart sleep 10done 后记:写该脚本时参考了git命令,shell语法,linux命令shell脚本中的空格一定要注意,少一个空格往往意义就会不同如果团队人数更多,那么该方法不再试用,每次程序启动都需一定时间。届时改为分布式项目,每个模块独立部署。]]></content>
      <categories>
        <category>探索笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql启动(无需添加到服务)]]></title>
    <url>%2F2019%2F06%2F22%2Fmysql%E5%90%AF%E5%8A%A8(%E6%97%A0%E9%9C%80%E6%B7%BB%E5%8A%A0%E5%88%B0%E6%9C%8D%E5%8A%A1)%2F</url>
    <content type="text"><![CDATA[已经安装配置好mysql,无需将mysql添加到服务项中即可启动 1.打开cmd,通过cd到mysql安装/解压文件夹下 2.调用bin下的mysqld.exe文件(如果是linux则可能是.sh) 3.参数为my.ini/my.cnf 4.具体命令为&emsp;bin/mysqld –defaults-file=./my.ini 5.输入该命令后cmd应该会挂起,此时mysql已经启动成功。如果关闭cmd命令行那么mysql关闭]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用笔记]]></title>
    <url>%2F2019%2F06%2F21%2Fgit%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[详细介绍git使用和配置(不包括安装) 什么是git? 首先我用通俗语言解释下,git是一种版本控制工具,你既可以在本地进行版本控制,也可以与搭建好git服务器的远端进行同步 如何使用? windows的可以官方下载安装包,linux可以命令行下载(对于window来说可能需配置环境变量,可有可无) 配置全局信息 随便找个地方右键打开git bash ps:这里配置的昵称和邮箱可以随便写,作用体现在,假如你提交了git,那么在git记录中会显示提交者昵称和邮箱,即为下面输入的 输入git config –global user.name “你的昵称” 输入git config –global user.name “你的邮箱” 创建git仓库 随便找个地方新建文件夹进去打开git bash(此处建议选一个父文件夹作为git仓库目录) 输入git init 该命令的作用是在当前文件夹下生成git仓库所需文件(注意,这里git仓库通常指的是一个项目,而不是管理多个项目的仓库,而且生成的文件为.git是个隐藏文件夹) 使用git 当我们在文件夹下做了操作以后(添加修改删除文件),可以git add . .代表暂存全部文件,当然也可以是其他写法或部分文件 此时我们已经add成功,接下来git commit -m”此次提交的注释” 此时,本地的使用基本就到这里(此外还有分支,冲突等各种概念,不在本篇讲) 关联github/码云(也可以是其他的或者自己搭建的git服务器) 首先我们在git bash中生成一对密钥,命令为:ssh-keygen -t rsa -C “你之前填写的邮箱” 其实一般码云或者github都要官方绑定密钥教程,基本都一样 生成密钥后我们把密钥配置到git服务器上 如果是github之类的你从个人setting可以找到配置密钥的地方,如果是个人git服务器则可能需要手动添加 刚才生成的密钥分为公钥和私钥,一般公钥以.pub结尾,这部分涉及到密码学,你只需要知道这是非对称密钥用来代替用户密码做身份验证就好了,具体内容请自行搜索 在window中默认保存在C://user/{你的用户名}/.ssh文件夹中 当我们配置到服务器公钥后,就可以正常的git clone 远程私有仓库等操作 可视化界面SourceTree SourceTree需要注册啥的,可能被墙了,自己解决 这里要提到一点,它仅仅是个可视化界面,仍然需要你安装git 团队里有人出现了SourceTree没有权限的问题,打开密钥设置界面(不同版本打开位置有所不同,大概都是在工具-选项这一块),找到之前我们生成的密钥(上文提到过位置),将私钥添加进去即可 解决冲突 这里我不建议大家团队合作时在采用pull来拉代码,这样的话如果有冲突,文件会被标记为冲突,建议用fetch先检测一下 如果是在commit之前拉取,产生了冲突,那么可以针对冲突的文件,抛弃自己的修改(等fetch+merge之后在手动增加回来) 如果是在commit之后拉取产生了冲突,就会出现无法拉取也无法推送的情况,这时候我们可以撤销commit操作,使其返回到上一种情况 1234567git reset [--参数] 提交id参数有: mixed:不删除改动的代码,撤销commit和add soft:不删除改动代码,撤销commit hard:删除改动代码,撤销commit和add(这种是用指定的提交id强行覆盖掉现有代码)示例: git reset --soft xxxxxxxxx 这里我们说的是命令行的操作,如果是sourceTree,那么对应的就是”重置当前分支到此次提交” 如果想要抛弃对方的提交,使自己本次提交强行覆盖掉对方,那么可以见下方代码。如果是sourceTree的话,则需要取选项里面允许强制提交。此外,如果用的github之类的这种托管远程仓库,那么对方可能还会设置了权限,只有拥有者有权限强制推送,项目所属人去github里面设置一下就好(这一点笔者没有实践) 1git push --force origin 一些其他的诸如merge,rebase的用法 这些用法笔者的理解有限,这里附一个知乎的提问,大家可以参考下在开发过程中使用git rebase还是git merge，优缺点分别是什么？ 一些其他的bug如何解决 现象:原本中文编码变成了/xxx/xxx之类的八进制码解决:修改本地git仓库下的.git隐藏文件夹下config文件,在[core]部分新增quotepath = false字段保存即可 git忽略规则&emsp;当我们同步到远程仓库时,配置了.gitignore可以令git按照我们定义的规则,选择性的跟踪本地仓库的文件&emsp;具体的语法规范这里不做描述,搜索引擎搜教程即可&emsp;这里我将列出学生team一个springboot项目合作时使用的.gitignore。对官方生成的git做了少许改动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263HELP.mdtarget/!.mvn/wrapper/maven-wrapper.jar!**/src/main/**!**/src/test/**###团队合作config######由于团队合作时每个成员数据库账户密码不一样,所以每个成员都有个个人配置信息,在通用配置里面引入###person.properties###springboot######此处表示忽略测试文件夹###/src/test/java### STS ###.apt_generated.classpath.factorypath.project.settings.springBeans.sts4-cache### IntelliJ IDEA ###.idea*.iws*.iml*.ipr### NetBeans ###/nbproject/private//nbbuild//dist//nbdist//.nb-gradle/build/### VS Code ###.vscode/# Log file*.log# Compiled class file*.class# BlueJ files*.ctxt# Mobile Tools for Java (J2ME).mtj.tmp/# Package Files #*.jar*.war*.nar*.ear*.zip*.tar.gz*.rarhs_err_pid* &emsp;常见问题:配置了.gitignore仍然无法忽略&emsp;解决方式:git rm –cached filename&emsp;删除该filename文件的本地缓存,然后再进行add和commit等操作,等push到远端后,以后再就不会被追踪&emsp;原因:这是由于在配置.gitignore之前该文件就已经被git追踪造成的,]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>base</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[welcome]]></title>
    <url>%2F2019%2F06%2F20%2Fwelcome%2F</url>
    <content type="text"><![CDATA[####测试图片,图片无效 图片下标 下一行文本 ####测试图片,图片无效]]></content>
  </entry>
</search>
