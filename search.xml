<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker for mac网络不通]]></title>
    <url>%2F2020%2F08%2F08%2Fdocker%20for%20mac%E7%BD%91%E7%BB%9C%E4%B8%8D%E9%80%9A%2F</url>
    <content type="text"><![CDATA[现象:docker安装在linux上一切正常,安装在mac上,宿主机无法ping通容器ip经常出现在宿主机连接容器kafka集群的情况下,无法连通 docker与宿主机之间网络模型这是由于docker是借助Linux内核的Namespace技术来实现的,而在mac上无法这样。所以在mac上安装docker实际上是先安装了一个linux虚拟机,然后在这台linux虚拟机内部跑docker那么mac上的docker和原生linux上的docker网络结构便不一致,如下图所示 1.linux docker网络结构 2.Docker Toolbox网络结构(已逐渐被第三种取代) 3.HyperKit (Docker Desktop for Mac)网络结构 从图中我们可以看到如果是linux机器上安装docker,可以通过网桥直接使用容器id来访问容器而在mac机器上,这两种结构均无法直接通过容器ip访问容器(因为隔了两层网络) 宿主机与容器访问的解决方案对于图2的结构我们即使在docker run时指定了-p,也无法在宿主机通过端口访问到。 因为此时的映射如下图,仅仅将docker容器端口映射到了linux虚拟机上 所以我们如果想要从宿主机通过localhost:post访问到对应容器,还需要手动将linux虚拟机的对应端口映射到宿主机上(当然,在docker中的几个容器如果没有设置防火墙可以互相通过各自内网ip访问,因为他们在同一网域) docker端口映射 docker+虚拟机端口映射 刚才我们说了宿主机主动访问容器的方法,那么接下来说容器中访问宿主机的方法。 方法一:如果宿主机连接了外网/局域网,可以通过宿主机ip来访问,具体数据流向如下图 网络结构2,容器中访问宿主机方法一数据流向 方法二:由于linux虚拟机既可以通过网桥一访问宿主机,又可以通过网桥二访问容器,那么我们在linux虚拟机中做vpn,将容器的流量传输到宿主机中 网络结构2,容器中访问宿主机方法二数据流向 方法三(并不确定Docker Toolbox是否提供该功能):通过docker提供的域名来访问宿主机 对于图3的结构其实该结构本质上与结构2本质并没有什么区别,只不过宿主机与linux虚拟机之间的数据交互由原来的网桥改为了sock文件(可能位于/var/run/docker.sock) 但是HyperKit (Docker Desktop for Mac)相比于Docker Toolbox,提供了自动的端口映射,也就是说,我们在docker run -p指定端口映射以后,会自动帮我们把这个端口映射到宿主机,无需我们手动操作虚拟机 另外如果容器想要访问宿主机,可以通过docker for mac提供的本地域名kubernetes.docker.internal来访问(无法保证每个版本的域名都是这个,如不一致,请使用官方提供的最新域名)。该域名仅最大作用于宿主机范围,对外部机器不适用 很遗憾我并未找到kubernetes.docker.internal的原理。虽然你可以从宿主机的hosts中找到127.0.0.1 kubernetes.docker.internal这一条,但我肯定这并不是使他起作用的根本,原因如下: 如果仅仅根据dns查找原理,子dns通过kubernetes.docker.internal收到的ip仅仅是127.0.0.1 在容器中ping该域名,得到了一个内网ip,然而从宿主机通过ifconfig,并无法找到该对应的该内网ip(这是当然,因为他们是通过sock文件进行网络通信) 在宿主机hosts添加一条127.0.0.1 kubernetes.docker.test后,从容器中ping kubernetes.docker.test,得到的ip为127.0.0.1 由此可见,必然docker for mac在linux虚拟机上帮我们做了一些工作,他可能通过类似转发流量的行为来达到这一目的 关于连接docker中kafka集群失败的原因及解决方法之前提到的网络结构仅仅是一部分原因,另一部分则是由于kafka等组件的配置问题 有一点我们要知道,当我们从宿主机连接kafka集群时,会首先访问zookeeper获取kafka挂载到zookeeper的host和port。 在kafka的server.properties配置文件中,我们可以看到,kafka默认的寻找zookeeper的ip为localhost。显而易见,由于每个容器都有一套自己的网络,通过localhost是无法找到zookeeper的。所以这里我们可以通过填写zookeeper容器在docker的内部ip,或者通过域名来访问zookeeper(实际数据流向为kafka容器-&gt;虚拟机-&gt;宿主机-&gt;经过zookeeper映射出来的端口-&gt;虚拟机-&gt;zookeeper容器),这样kafka才能连通zookeeper将自身信息挂载上 另外还有一个问题我们需要解决,在默认情况下,kafka挂载到zookeeper的host为自身的容器id,显然我们的宿主机是无法将容器id当作host找到该容器的。那么挂载为自己容器id的原因是什么呢?答案是,kafka会先尝试获取advertised.host.name,如果未设置则尝试获取host.name,如果均未设置则会调用java.net.InetAddress.getCanonicalHostName()方法获取hostname(该参数可以通过/etc/hostname来找到其配置),在容器中hostname默认为容器id,所以我们通过添加advertised.host.name的参数为kubernetes.docker.internal域名,即可使宿主机得到的host为kubernetes.docker.internal,从而通过映射出去的端口找到kafka容器 注:不同版本获取的参数或者获取参数的顺序或位置可能不同,但基本原理一致]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>mac</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[go语法]]></title>
    <url>%2F2020%2F08%2F04%2Fgo%20%E8%AF%AD%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这里主要记录一下使用golang以来遇到的一些疑惑 一.context作用在go中,context不仅仅是存储上下文信息,他同时也用作协程之间的信号。我们可以把它当作一个树状结构,且每个节点都有一个map,可以携带信息的信号量。context具有父context和子context的概念,利用管道(可以简单理解为阻塞队列)来通知其关闭 二.协程生命周期]]></content>
      <categories>
        <category>go</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql存储过程]]></title>
    <url>%2F2020%2F08%2F04%2Fmysql%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.此篇记录简单的mysql存储过程,意在分表,将1个数据库表根据id分为多个表,用于数据迁移。然而实测速度极慢(本地1000W条数据分表,1分钟分了5W条),根据搜集资料显示,瓶颈疑似出现在游标,google回答建议采用临时表代替游标 2.根据搜集资料,现阶段不建议使用存储过程,而是在业务层写脚本来处理数据。因为存储过程极其依赖数据库,难以迁移,且现阶段多为分布式数据库,存储过程难以运行于分布式环境,存储过程难以调试维护,存储过程会加重数据库负担,数据库应该仅承担数据存储职责而非业务职责 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364注意,如果mysql窗口是打开的mysql这一层级,则需要选择数据库才可继续接下来操作,否则会提示选择数据库//将结束符暂时更改为//,以免被程序中的语句分隔符;影响DELIMITER ////创建存储过程,如果本身已存在同名存储过程,则创建失败CREATE PROCEDURE wk()//开始写存储过程BEGIN //语法1:变量声明必须在所有函数之前 declare i int; declare tmp varchar(100); declare userId int; declare nickname varchar(32); declare phone varchar(13); declare addr varchar(100); declare email varchar(50); declare profile_photo_number varchar(50); declare tabl varchar(32); declare myvar text; //语法1:该语句已经属于函数部分,所以变量声明需要在这之前,否则报错 DECLARE cur CURSOR FOR SELECT * FROM et_user_profile; //语法2:set语句给变量赋值 set i = 0; //语法3:while循环语句 while i &lt; 100 do //语法4:此处CONCAT拼接字符串,给分表添加后缀 SET tmp = CONCAT(&apos;et_user_profile_&apos;,i); //语法5:由于mysql存储过程中的sql语句不支持动态变量,所以只能先拼接出最终字符串,再将字符串转换为执行语句执行 //语法6:set @语句可以免于提前声明变量,相当于声明+赋值语句 SET @STMT :=CONCAT(&apos;CREATE TABLE IF NOT EXISTS &apos;,tmp,&apos; ( `id` INT UNSIGNED PRIMARY KEY COMMENT &quot;id follow et_user.id&quot;, `nickname` VARCHAR(32) NOT NULL COMMENT &quot;nickname&quot;, `phone` VARCHAR(13) NOT NULL COMMENT &quot;phone&quot;, `addr` VARCHAR(100) NOT NULL COMMENT &quot;address&quot;, `email` VARCHAR(50) NOT NULL COMMENT &quot;email&quot;, `profile_photo_number` VARCHAR(50) NOT NULL COMMENT &quot;profile_photo_number&quot; );&apos;); PREPARE STMT FROM @STMT; EXECUTE STMT; set i = i +1; end while; //语法7:打开之前声明的游标 OPEN cur; //语法8:设置循环点 myloop: LOOP //语法9:从游标中提取数据(一次一行,可理解为迭代) FETCH cur INTO userId,nickname,phone,addr,email,profile_photo_number; //语法10:if语句 IF done=1 THEN //语法11:离开循环点 LEAVE myloop; END IF; set tabl = CONCAT(&apos;et_user_profile_&apos;,floor(userId%100)); SET @STMT2 := CONCAT(&apos;insert into &apos;,tabl,&apos; values(&apos;,userId,&apos;,&apos;,&apos;&quot;&quot;&apos;,&apos;,&apos;,&apos;&quot;&quot;&apos;,&apos;,&apos;,&apos;&quot;&quot;&apos;,&apos;,&apos;,&apos;&quot;&quot;&apos;,&apos;,&apos;,&apos;&quot;&quot;&apos;,&apos;);&apos;); PREPARE STMT2 FROM @STMT2; EXECUTE STMT2; END LOOP myloop; CLOSE cur;//语法12:存储过程结束END ////语法13:将结束符改回DELIMITER ;//语法14:调用刚才创建的存储过程,由于存储过程直接存于mysql中,故可以后重复使用,不必立刻调用call wk();]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>存储过程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[TCP[IP]PORT->[IP]PORT (CLOSED)/(ESTABLISHED)]]></title>
    <url>%2F2020%2F07%2F30%2Fgo_mac_http_fd%2F</url>
    <content type="text"><![CDATA[状况一: TCP[IP]PORT-&gt;[IP]PORT (CLOSED)用jmeter压测go web项目时突然新的请求被阻塞无法被执行,通过命令lsof -nP -i -l查看,发现大量类似这样信息,此时jmeter已经stop,客户端与服务端之间并不存在存活的请求分析:待补充结论:由于服务端未设置超时时间 状况二:TCP[IP]PORT-&gt;[IP]PORT (ESTABLISHED)结论:正常现象,表示连接状态的socket]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[can't assign requested address,i/o timeout,too many open files in system]]></title>
    <url>%2F2020%2F07%2F30%2Fcan't%20assign%20requested%20address%2F</url>
    <content type="text"><![CDATA[状况一:can’t assign requested addressgo用了mysql连接池,高并发压测时出现该报错分析:该报错是由于mac自身fd句柄打开数限制,并且mysql连接池并非一开始就创建出连接,而是随着请求进来才创建连接,大量并发同时进入,占满了mac的fd,导致mysql连接池无法使用fd,无法分配新的连接结论:修改mac参数限制/上服务器测临时修改方式,命令行直接输入永久修改方式,写入/etc/sysctl.conf后重启sysctl kern.maxfiles 查看系统所能打开的最大文件数（文件描述符）(全局)sudo sysctl -w kern.maxfiles 修改sysctl kern.maxfilesperproc 查看系统所能打开的最大文件数（文件描述符）(一个进程)sudo sysctl -w kern.maxfilesperproc 修改ulimit －n 查看shell能打开的最大文件数ulimit -n 123123 修改(123123为任意值,但不得大于kern.maxfilesperproc)sysctl net.inet.ip.portrange 查看端口范围sysctl -w net.inet.ip.portrange.first=32768 修改 状况二:dial tcp 127.0.0.1:3306:i/o timeout分析:待补充结论:解决方式同状况一 状况三:too many open files in system分析:原因同状况一结论:解决方式同状况一]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>mac</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql事务]]></title>
    <url>%2F2019%2F11%2F30%2Fmysql%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[ps:这篇文章本来写了一半,然后突然没了,没了!心态爆炸!写文章一定要及时保存! 下面我所提到的mysql事务,均是基于InnoDB引擎(平时我们常用的引擎),千万不要将对InnoDB的理解代入其他的引擎 &emsp;提到mysql,对于业务场景来说,肯定是需要懂一些mysql事务方面的内容,那么本篇就来谈一下关于mysql事务的问题 &emsp;说到事务,我们就会问了,何时要用到事务?又或者事务是用来做什么的?其实,在我看来,事务是用来将一系列的非原子性操作封装成某种程度上外部感知上的原子性操作(这里要注意,事务并不是将所有操作压缩起来,类似redis中LUA脚本那样,而是你每句sql是确实的被执行了的,数据库也确实发生了修改的,只是用了某种技巧使得其可以支持事务失败时的回滚,以及其对其他外部行为可见性等,这个我们后面会讲到) &emsp;以汇款行为为例,我们需要从A账户中取出金额,放到B账户下,在这两个行为的过程中,可能会发生各种意外导致数字货币的丢失,那么为了防止这种情况发生,我们就需要想办法将其打包成原子性操作,其中一种方式就是用mysql事务(当然,这仅仅是数据库层面上的方式,我们当然还有其他可选方式,但这不在本次讨论范围内) &emsp;下面我们先来简单介绍一下mysql事务的几种隔离级别(这里要解释一下为什么会有隔离级别这个东西,因为上文我们提到过,mysql事务的原子性并不是将我们所要进行的操作压缩在一起执行,而是每次的sql语句确实的被mysql执行了,那么如果两个事务同时进行,那么我们如何保证一个事务所做的修改对于另一个事务而言的可见性呢?这就涉及到了事务隔离级别)。事务隔离级别分为以下几种,后面我会再详细的分析隔离级别是如何实现的 Read uncommitted 从名字可以看出这种模式可以允许你读取另一个事务已经执行但是未进行commit之前的修改 Read committed 同理,这个模式只能读取另一个事务已经commit的修改 Repeatable read 在提到这种模式之前,我们先思考下之前的两种模式(我们此时要注意换位思考,即假设A,B两个事务同时运行,我们要分别从AB的角度去看待原子性) Read uncommitted显而易见,如果是当A读取,B修改(这里我们把它想象成连续修改可能更容易理解)时,对于A而言他看到的B事务并不是原子性的(即如果A连续读,会发现B造成的修改是在不断变动的) Read committed可以说他的一部分已经开始向原子性靠拢了,还是当A读取,B连续修改这种情况下,对于从A的角度而言B的修改是原子性的,从B的角度而言A的修改也是原子性的(即B只能看到A事务开启前或提交后的值),如果你认为这就已经达到了原子性,那么恭喜你漏了一个很重要的一点。在这种情况下,从A的角度而言A自身并不是原子性的,我这么说或许大家会感到奇怪,那么首先我们再来看一下对原子性的理解。何为原子性?即如果A,B两个行为,他们互相看对方是原子性的,并且A看A也必须是原子性的(即在他们动作执行开始到结束,在他们的眼里整个世界是停滞的,只有他们自己在活跃)。好,理解了这一点,我们再回来看,假设A事务正在执行,B事务也在执行,那么如果B不提交A就已经执行完了,在这种情况下,A认为整个世界只有他在活跃,那么如果A事务执行时B提交了呢?那么在A眼里整个世界就不是停滞的,还有B的存在,B的种种行为都会影响到A的判断,具体会有何种影响我们后面再说 让我们回到Repeatable read,理解了上面的,我们就很容易理解Repeatable read这种模式,字面上来看,就是可重复读,那么他的作用是什么呢,拿上面的举例来说,即A执行(严格来讲并不是执行,而是只在第一次select操作时,后面我会说明原因)的一瞬间,在他看来整个世界对他停滞了,即时外界有任何事务的提交,也不会影响他,直到他完成自己的工作,而在mysql中,这也是默认的隔离级别。这里有个提示,所有的命令都是活跃在事务中的,即时你只有单条sql语句,mysql也会默认给你包装为一个事务,那么平时我们单条sql语句并不需要执行commit是因为有个属性autocommit=1自动帮我们执行了commit Serializable 这种模式就比较简单粗暴了,每次读取数据时都会获取表级共享锁(这里不明白的同学可以简单的将其理解为被获取共享锁的对象只能看不能动),由于直接给你表套了个共享锁,所以其他事务对于本事务都是原子性的(其他事务连动数据都动不了,更别提原子性不原子性的问题了。如果其他事务的修改操作先于本串行化事务开始时,由于排他锁会阻止加共享锁,所以直到加排他锁的事务commit,本Serializable的事务根本无法执行,反之也同理,连修改都无法进行,还谈什么修改可见不可见的问题呢) &emsp;在这里我并不会总结几种隔离级别和脏读不可重复度幻读等的关系,因为在搜资料的过程中发现大家对这些概念说法有一定的差别,当然这并不意味谁的理解是错的,只是站在不同角度而已,下面以两个版本来说 &emsp;先说网上的各种教程的版本 脏读 读到了其他事务未提交的数据,在Read uncommitted模式下会发生 不可重复读 一个事务中两次select获取的数据不一样,在Read committed,Read uncommitted模式下会发生 幻读 同一个事物中连续读两次发现读到的行(该行可能以前存在也可能不存在)不一样,在Read committed,Read uncommitted,Repeatable read模式下均会发生 &emsp;再说下自己的理解(在看接下来内容之前先看下这篇,) &emsp;看完MVCC机制之后,我们可以思考这么一个问题,假如AB两个事务(Repeatable read模式),A先全表读一次,B插入一条数据(事务并未提交),A全表update一次,A再读一次,那么他读出来的跟第一次读出来的一样吗? &emsp;如果仔细看过刚才MVCC机制的文章,会发现,其实刚才的那个问题,A两次读取出的已经不一样了,那么仔细思考一下,这算不算脏读呢?这算不算重复读呢?这算不算幻读呢?(对于幻读当然你也可以把条件定义为其他事务的改变对于本事务来说不可见而不是当前事务的修改对自身不可见,但在这里我并不想纠结于文字)其实我也分不清。在很多情况下我们死记脏读,不可重复读,幻读是毫无意义的,不如直接去弄清他的原理,根据具体需要去分析 &emsp;接下来我们再仔细想一下之前的MVCC和前三种隔离级别(最后一种串行化隔离级别我们可以把它放到锁那部分来讨论了,这里提他并没有意义),我们不难感觉出,有哪里怪怪的,我们看到的和实际操作的是不一样的。那在这里,让我们再引入两个概念,当前读和快照读(请自行搜索),现在我们不难看出,无论是MVCC还是三种隔离级别都是针对于读(select)这一行为而言,他们并没有规定insert,update,delete等操作,看过MVCC我们知道,update和delete是由undo log来维护的,并且会置入操作他们的事务的id(insert也会置入id,但是网上说他不由undo log维护,具体我还要再去验证),虽然读会受此id影响,但是修改(这里泛指增删改)并不会走MVCC判断事务id,也就是说,你只要有方式能触碰到该条记录(例如update where id=),则这条记录会被你修改,并且事务id会置为你的事务id,那么以后的select,就会受MVCC影响而可以查询出来这条数据,当然还有很多情况,这里随便列举一个 事务A读了一下表发现了abc三条数据,事务B读了一下表发现了abc三条数据,事务A插入了一条数据d,事务B再读表发现还是abc三条数据,那么事务B插入了一条数据d(注意,此时跟事务A刚才插入的主键重复),那么插入失败。 &emsp;到这里mysql事务的介绍差不多就结束了,仅靠MVCC是不足以支撑我们对原子性的要求的,事实上大部分情况都是MVCC与锁配合来达到我们的期望(好吧,其实我本来想用需求这个词来表达,但是不禁想到了产品提需求的噩梦,相信很多人都对此深有感触) &emsp;最后提一点题外话,如果你想测试mysql的事务,千万不要在springboot或者hibernate框架中测试,他们自身的事务管理机制会扰乱你的测试,在下面的几篇(可能要鸽一阵子,毕竟这俩框架体量比较庞大)会分析一下为何他们会扰乱你的测试 ps:其实在进行测试时,有一个地方暂时没搞清楚,假设事务AB(Repeatable read模式均为),B全表读一次,A删除一条数据并提交,B全表读一次。第一次读取和第二次读取出的行记录(仅仅是少了一行,每行的数据是符合RR的)在mysql workbench 8.0CE模式下是不同的(事务A的删除对B可见),而在navicat premium 12和mysql命令行模式下两次读取出是相同的(事务A的删除对事务B不可见),有人可以指点下吗]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FutureTask源码分析]]></title>
    <url>%2F2019%2F10%2F05%2FFutureTask%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[FutureTask直接继承了RunnableFuture,间接继承了Future,Runnable。当我们使用Runnable时,是无法获得返回值的,而RunnableFuture则是为了解决这一个问题而存在 在该类中,有一点你会发现,他用到了自定义的链表,并且在get阻塞等待以及任务完成时都会操作该链表,例如awaitDone(boolean timed, long nanos)方法中的这些操作,该链表的作用是,如果多个线程同时get阻塞等待该任务,这些线程的信息分别保存在链表上的一个节点中,那么当任务完成时可以通过该操作来即时唤醒这些线程,超时的被从链表中移除,例如下面代码demo 123456789101112131415161718192021222324252627282930313233@Test public void test42() throws InterruptedException &#123; //构造FutureTask FutureTask futureTask = new FutureTask(() -&gt; &#123; Thread.sleep(5000); System.out.println("callable has run"); return "123"; &#125;); //运行FutureTask中传入的任务 new Thread(() -&gt; futureTask.run()).start(); //开启第一个get new Thread(() -&gt; &#123; try &#123; System.out.println("Thread one:"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //开启第二个get new Thread(() -&gt; &#123; try &#123; System.out.println("Thread two:"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //主线程睡眠等待其他线程结束 Thread.sleep(10000); &#125; 在该类中有一处代码,这里保存该任务的状态,这种方式很常见,也可以方便的通过比较大小等方式来判断其状态范围 12345678private volatile int state;private static final int NEW = 0;private static final int COMPLETING = 1;private static final int NORMAL = 2;private static final int EXCEPTIONAL = 3;private static final int CANCELLED = 4;private static final int INTERRUPTING = 5;private static final int INTERRUPTED = 6; callable是接到的任务,即使构造时采用的Future也会为了统一而被封装为Callable,outcome是返回值,如果任务执行过程中出现异常,那么outcome中保存的则是异常信息,waitNode则是刚刚提到的链表,runner是运行该任务的线程信息,在本类中常被用来做CAS操作,只有当其为null,run()才可被调用,避免连续调用两次run()导致重复运行任务 12345678/** The underlying callable; nulled out after running */private Callable&lt;V&gt; callable;/** The result to return or exception to throw from get() */private Object outcome; // non-volatile, protected by state reads/writes/** The thread running the callable; CASed during run() */private volatile Thread runner;/** Treiber stack of waiting threads */private volatile WaitNode waiters; finishCompletion()方法就是之前提到的唤醒链表上所有get阻塞的线程LockSupport.unpark和park可以理解为信号量runAndReset()这是个protected方法,作用是,通过不改变state的状态使其可以运行多次,普通的run()运行一次以后state状态就改变了 其他的代码没啥难度,看下源码附带的注释就能理解了]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ThreadPoolExecutor源码分析]]></title>
    <url>%2F2019%2F10%2F05%2FThreadPoolExecutor%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[看到网上讲线程池源码的文章一堆大坑,只能自己扒源码扒篇文章出来了,坐标jdk8 最重要的一个坑放在前面假如你设置的核心线程数=2,最大线程数=4。很多人都讲向线程池添加任务时会先扩充到最大线程数,多出来的再向队列添加,我只想说,根据源码分析并不是这样 看如下代码,在添加任务时,从源码或从注释中明确表示分了三步1.如果现存线程数小于核心线程数,则创建线程,添加的任务直接在该线程运行2.如果核心线程数满了,则add到队列中3.如果队列满了,则尝试扩充线程,任务在新创建的线程中运行 那我们结合之前提到的错误方式来看,如果这一步理解错了会发生什么。如果我们采用的是无界队列,那会直接导致我们的任务被无限制的添加到队列中而不会主动去扩充线程数,如果核心线程消费速度小于生产速度,会直接导致OOM,这点我们务必要确认清楚 123456789101112131415int c = ctl.get();if (workerCountOf(c) &lt; corePoolSize) &#123; if (addWorker(command, true)) return; c = ctl.get();&#125;if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); else if (workerCountOf(recheck) == 0) addWorker(null, false);&#125;else if (!addWorker(command, false)) reject(command); 强调完一个巨坑以后,我们来看一下线程池源码 关于线程池源码的几个特点:1.之前提到的三步添加任务的坑2.为了方便读取,采用了位运算将线程池状态和工作线程数整合到了一个AtomicInteger中,高位代表状态,低位代表工作现场数 123456//这是整合了线程池状态和工作线程数的AtomicIntegerprivate final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));//这是解析ctl线程池状态和工作线程数的几个方法private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY; &#125;private static int workerCountOf(int c) &#123; return c &amp; CAPACITY; &#125;private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 3.执行任务的行为:我们可以通过runWorker方法(该方法被Worker中的run调用,一个Worker即可以当作一个封装好的工作线程)看到,该方法中有一个while循环调用,条件分为两种情况,如果是该线程运行的首个任务,会直接接收任务运行(该任务被封装在Worker中),如果是后续任务,则会从队列中取得任务进行(在getTask方法中会对我们设置的线程超时时间来进行判断,从而起到当非核心线程超时时,返回false使其跳出while循环,从而终止该线程)4.核心线程和非核心线程其实并无区别,AtomicInteger大家都知道,可以做到原子性操作,当工作线程数大于核心线程数且超时时,会同时请求减少工作线程数,竞争到的则作为非核心线程而关闭,没有竞争到的作为核心线程继续运行。可见,两种线程仅仅是称呼上的不同5.无处不在的双重检查,即时用了双重检查,但是由于两行代码之间并不是原子性的,我们无法保证双重检查一定可以避免并发操作产生的时间间隙,但确实可以避免一些并发造成的间隙。但是既然线程池是如此操作的,那么很大概率上可能编程人员对此进行过测试,认为双重检查有助于提高效率。另外双重检查也有预防一些因时间间隙产生的BUG的作用,下文会讲到6.类似beforeExecute这种方法,里面没有做什么事情,这是留给子类来实现的钩子函数 讲完了特点这里列出几个最重要的函数来说一下,其他的自己看就可以了 addWorker函数主要分为两个部分,第一部分是增加工作线程计数,第二部分是创建工作线程,详细可以看代码块中我的注释 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: //for循环内的这部分是增加工作线程计数 for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); /* 这里还是双重检测的作用,即时在调用addWorker之前已经检查过一遍了,比较有趣的是if中的逻辑判断 有点绕这里来解释下,意思为:如果线程池已经SHUTDOWN了,那么它将不再接受新的任务开启工作线程 (这里我们之前提到过,如果工作线程小于核心线程时,添加的任务会直接在新创建的线程执行) 但是有一种情况除外,那就是在SHUTDOWN状态下,firstTask等于null且队列中仍有任务(从文章一开始的三步 添加任务中可以看到,如果第一步判断时工作线程大于等于核心线程数,但是在判断结束之后工作线程全部 结束了(如果核心线程数设置为0或者线程池被结束了(当线程池被结束时,已经添加进来的任务不会被结束而是 等待其执行完毕)),那么如果后续没有任务再添加,我们现在队列中的任务将永远不会被执行 所以在三步添加任务的第二步中的双重检查,有防止这个问题发生的作用,他通过给addWorker传递一个值 为null的firstTask,促使其创建出一个工作线程继续完成队列中的任务) */ if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp; firstTask == null &amp;&amp; ! workQueue.isEmpty())) return false; for (;;) &#123; int wc = workerCountOf(c); if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; if (compareAndIncrementWorkerCount(c)) break retry; c = ctl.get(); // Re-read ctl if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; //接下来的为创建工作线程 boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; w = new Worker(firstTask); final Thread t = w.thread; if (t != null) &#123; //这里采用锁,个人认为是为了防止设置largestPoolSize时出现并发问题 final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); workers.add(w); int s = workers.size(); if (s &gt; largestPoolSize) largestPoolSize = s; workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; if (workerAdded) &#123; t.start(); workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) //如果创建失败,会减少工作线程计数 addWorkerFailed(w); &#125; return workerStarted;&#125; 运行任务的方法,这个方法有个特点是,如果线程池结束,他仅仅会interrupt标识一下(这里有必要说明,interrupt并不是强制终止线程,而是做标记,具体线程的反应依赖于其代码实现),而不会做出任何反应,其终止仅仅依赖于getTask()的返回值 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); Runnable task = w.firstTask; w.firstTask = null; w.unlock(); // allow interrupts boolean completedAbruptly = true; try &#123; //根据上文,如果传入的任务为null,或者如果第一个任务执行完了,则会去队列中获取任务 while (task != null || (task = getTask()) != null) &#123; w.lock(); // If pool is stopping, ensure thread is interrupted; // if not, ensure thread is not interrupted. This // requires a recheck in second case to deal with // shutdownNow race while clearing interrupt if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) //这里仅仅做标记,并无法真正的终止线程 wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; //真正执行用户定义的任务 task.run(); &#125; catch (RuntimeException x) &#123; //抛出异常并不会造成终止,而是被本方法中外围的try捕获了,这一点可以参考FutureTask类中的操作,会将异常放置到一个对象中 thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; processWorkerExit(w, completedAbruptly); &#125;&#125; getTask方法 12345678910111213141516171819202122232425262728293031323334353637383940414243private Runnable getTask() &#123; boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // Are workers subject to culling? boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) /* 此处就是之前提到的,CAS竞争从而停掉非核心线程,这里要强调一下,如果竞争失败,则会超时等待从 队列中获取任务,如果超时,则进行下一轮竞争请求返回null从而停掉本线程,直到工作线程等于核心 线程数才会一直阻塞等待从队列获取任务(前提是allowCoreThreadTimeOut==false,当然他的默认 值就是false,除非你主动对其进行了改变) */ return null; continue; &#125; try &#123; Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) return r; timedOut = true; &#125; catch (InterruptedException retry) &#123; timedOut = false; &#125; &#125;&#125;]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>ThreadPoolExecutor</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何使用Unsafe类方法]]></title>
    <url>%2F2019%2F10%2F05%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8Unsafe%E7%B1%BB%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先Unsafe类是不建议被使用的,因为他面向底层,可能在每一代jdk版本中发生变化,除非你有把握在在每一次升级jdk时维护你的项目 Unsafe是作为单例而存在的,当我们尝试调用getUnsafe方法时,会报安全错误,这是由于双亲加载机制导致的。通常我们可以通过反射来绕过这些检测 在如下代码中,我们通过反射获取到了Unsafe类的实例,Unsafe类中的方法往往都是通过偏移量来操作对象的,我们可以看到,我们定义了Thread对象,并且通过objectFieldOffset获取其偏移量,在test()方法中,通过CAS来将其置换,成功的使用了Unsafe中的方法 1234567891011121314151617181920212223242526272829303132333435public class UnsafeTest &#123; private volatile Thread runner; private static final long runnerOffset; private static final Unsafe UNSAFE; static &#123; try &#123; Field f = Unsafe.class.getDeclaredField("theUnsafe"); f.setAccessible(true); UNSAFE = (Unsafe) f.get(null); //UNSAFE = sun.misc.Unsafe.getUnsafe(); Class&lt;?&gt; k = UnsafeTest.class; runnerOffset = UNSAFE.objectFieldOffset (k.getDeclaredField("runner")); &#125; catch (Exception e) &#123; throw new Error(e); &#125; &#125; public void test()&#123; UNSAFE.compareAndSwapObject(this, runnerOffset, null, Thread.currentThread()); &#125; public void print()&#123; System.out.println(runner); &#125; public static void main(String[] args) &#123; UnsafeTest unsafeTest = new UnsafeTest(); unsafeTest.test(); unsafeTest.print(); &#125;&#125;]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA修改java版本号]]></title>
    <url>%2F2019%2F09%2F15%2FIDEA%E4%BF%AE%E6%94%B9java%E7%89%88%E6%9C%AC%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[总共有4处需要修改,直接上图(在后面),如果懒得每次改版本号,也可以利用maven插件 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;自行找个版本&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>IDEA</category>
      </categories>
      <tags>
        <tag>IDEA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[隧道连接redis集群报错]]></title>
    <url>%2F2019%2F09%2F15%2F%E9%9A%A7%E9%81%93%E8%BF%9E%E6%8E%A5redis%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[####问题描述&emsp;java springboot程序访问redis,由于redis集群分布于多个目标服务器上,且均有防火墙阻拦,平时调试都是通过tunnel建立隧道来访问。单个redis通过隧道访问成功,但是redis集群通过隧道访问失败。 使用的jar包如下 12&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; 单个redis连接时配置如下(已经提前建立好隧道) 12spring.redis.host: 单个ipspring.redis.port: 单个端口 redis集群连接时配置如下(已经提前建立好隧道) 1spring.redis.cluster.nodes: localhost:6379 按照单个redis连接配置时正常连接,按照集群配置时报错 1234567org.springframework.data.redis.ClusterStateFailureException: Could not retrieve cluster information. CLUSTER NODES returned with error. - ipA:端口A failed: Could not get a resource from the pool - ipB:端口B failed: Could not get a resource from the pool - ipC:端口C failed: Could not get a resource from the pool - ipD:端口D failed: Could not get a resource from the pool - ipE:端口E failed: Could not get a resource from the pool - ipF:端口F failed: Could not get a resource from the pool ####问题排查因为配置文件配置了生成环境开发环境测试环境等一系列的环境,分别对应不同的集群配置,因为当时只配置了一个ip端口,以为是读取配置文件出现错乱,所以在这方面排查了一段时间 后来通过分析源码发现了问题,我们在配置文件中配置的服务器ip和端口,在集群模式下仅仅相当于入口的作用。即,先与配置文件中的ip端口建立socket链接,然后发送cluster获取集群信息命令,然后断开该socket链接,转而直接跟各个集群服务器建立socket链接,从而导致后续请求不会走我们配置的隧道。也就出现了之前我们只配置了一个ip和端口缺出现了和6个redis均连接失败的情况,误以为时配置读取问题]]></content>
      <categories>
        <category>redis</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql设置默认值无效]]></title>
    <url>%2F2019%2F09%2F14%2Fmysql%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%80%BC%E6%97%A0%E6%95%88%2F</url>
    <content type="text"><![CDATA[场景:数据库mysql,框架hibernate 原因: 根据hibernate打印出的sql信息可以发现,如果实体类字段为null,则仍会insert这个字段为null,而mysql设置的默认值生效的前提是,当我们insert一条记录时,我们不指定某字段的值,他才会自动生成默认值,而我们用save的时候指定该字段的值为null,此时如果我们mysql设置的为not null,那么同时也会报错 解决: @DynamicInsert(默认为true) @DynamicUpdate(默认为true) 这两个注解是类注解,作用为:当插入/更新一条记录时,只insert/update改变的信息,而不是将所有字段都update为当前的 即,没有注解时update的sql为 12 Hibernate: select student0_.id as id1_0_0_, student0_.default_value as default_2_0_0_, student0_.password as password3_0_0_, student0_.username as username4_0_0_ from user_student student0_ where student0_.id=?Hibernate: update user_student set default_value=?, password=?, username=? where id=? 有注解时的sql为 12 Hibernate: select student0_.id as id1_0_0_, student0_.default_value as default_2_0_0_, student0_.password as password3_0_0_, student0_.username as username4_0_0_ from user_student student0_ where student0_.id=?Hibernate: update user_student set username=? where id=? 可以看到,当需要update时(如果没有做更改则无论有无注解均不会执行update命令),无注解的将所有字段全都update为当前值,有注解的则只update修改值。在每次update之前,均会执行select查询出数据库当前该字段的状态进行比较后在执行更新操作 网上有人说@DynamicInsert这个注解的作用是,如果值为null,则不set该值。 从片面的角度来看,这句话是对的,如果我们在save时指定id,因为insert对于一条记录只会出现一次,在执行insert之前,hibernate回去数据库执行select查询,如果查询不到数据,那么我们当前值的null和他当前缓存种的值null是相等的,就认为该值没有修改,在后面执行insert时mysql就会给该值赋予默认值。如果我们没指定id,那么他就不会select,同理,跟缓存中的null相等,在组建insert语句时就不会附带该值 那么有这么一种情况,假若我们save了一个新记录,然后又update该记录,但是在update时,有个字段我们没有赋值,其为null,那么跟从数据库select出的数据发生了变化,就会set null向数据库中,此时如果我们数据库时not null的,就会报错,反之,则会该字段的值被设为了null]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的锁]]></title>
    <url>%2F2019%2F08%2F28%2Fjava%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁的几种用法####synchronizede.g:1用synchronized对一个代码块加锁,object可以是任意的对象,任何其他synchronized(该对象)的代码块均需要获取到锁以后才可以执行,如果object=this,那么就是锁住的整个对象 123synchronized(object) &#123; //代码块&#125; e.g:2下方代码锁住的是此方法所在的对象,也就是如果该对象中两个不同的方法前面均有synchronized时,在多个线程操作同一个对象时,同一时间只有一个方法可以被调用 123public synchronized void work()&#123; System.out.println(123);&#125; e.g:3如果是对一个class或者static类型的对象加锁,那么因为class和static类型的对象只会在jvm虚拟机保存一份,所以加锁要额外注意 e.g:4特别强调的一点是,synchronized是针对对象加锁,Class和static也可以看作一个对象,假如说出现下面代码,此时你的锁是无效的,虽然引用没变,但是引用指向的对象已经改变 123456Object obj = new Object();synchronized(obj)&#123; obj = new Object(); //代码块&#125;` 待续 拓展:分布式锁]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2019%2F08%2F28%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[####什么是锁?&emsp;锁是一个多方可以共同访问的元素,各个访问者通过对该元素的信息的判断,按照一定事先约定的行为进行协调的功能。这个元素可以是任何的东西,根据事先约定的行为的不同也会随之变化。 &emsp;例如,一个队列,如果来访者发现自己的id在该队列的头部,那么就认为自己拥有了锁,可以执行某些逻辑,这时候这个队列就相当于一个锁。锁也可以是一个boolean类型的对象,当他为true或者false时,其他线程可以来竞争使得boolean状态改变,从而认为自己获取了锁(当然需要考虑使用场景)。锁也可以是一个信号量,也可以是一个节点,例如zookeeper中,一个节点存在与否就意味着是否可以竞争锁(当然行为是我们自己来定的,zookeeper和redis仅仅是提供了一个放置锁的地方)。当然,最重要的一点就是原子性,我们在加锁和解锁的时候,要充分考虑使用场景来决定对锁的判断策略 ####redis锁的实现&emsp;对于redis分布式锁来说,常用的莫过于SETNX,SET,DEL这几个函数了tip:现在SET函数可以传递参数,例如隐式的过期时间(由redis负责,无需手工维护),在已存在值时的反应,对于添加成功或者失败的返回值这几个元素,所以SET已经完全可以取代SETNX,甚至说比SETNX表现更好。因为SETNX在加锁时还要额外添加过期时间字段,需要由客户端根据这个字段来判断锁是否过期,这样一牵扯到非原子性的问题,就会十分复杂 &emsp;最简单的加锁解锁代码如下,由于在解锁时,伴随着锁过期的可能,我们需要先判断锁是否是本客户端加的,再去解锁,否则A加锁,A过期,B加锁,A完成任务解锁,就把B加的锁解掉了。解锁操作我们可以想象,他是先查询再操作,不是原子性,所以我们需要封装LUA脚本来使这两条语句具备原子性具体SET参数意义可以自行搜索 123456789101112131415161718192021222324252627282930313233343536/*** Non-blocking try to hold a lock* if true,the work must be finished within millisecond,else the distributed-lock is meaningless* @param key the key of lock* @param value a unique String,it will be used When release* @param expiration it will expirate after now+expiration* @return true if access,else false* */public boolean tryLock(String key,String value,long expiration)&#123; //try to create a record if not exist Object res = redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; JedisCommands connect = (JedisCommands) redisConnection.getNativeConnection(); //SETNX can be replace by SET from Redis 2.6.12 version return connect.set(key,value,"NX","PX",expiration); &#125;); return res!=null;&#125;/*** Non-blocking release a lock,if lock has expiration,nothing happen* @param key the key of lock* @param value the String you set When try to hold a lock* */public void relaseLock(String key,String value)&#123; redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; Object obj = redisConnection.getNativeConnection(); System.out.println(obj.getClass().getName()); if (obj instanceof JedisCluster) &#123; JedisCluster connection = (JedisCluster) obj; return connection.eval(LUA,Collections.singletonList(key),Collections.singletonList(value)); &#125;else if (obj instanceof Jedis)&#123; Jedis connection = (Jedis) obj; return connection.eval(LUA,Collections.singletonList(key),Collections.singletonList(value)); &#125; return null; &#125;) ;&#125; 虽然SET方法是瞬时的,无法阻塞,但是我们可以自己封装方法来达到阻塞加锁的效果 123456789101112131415161718192021222324252627/*** blocking try to hold a lock* if true,the work must be finished within millisecond,else the distributed-lock is meaningless* @param key the key of lock* @param value a unique String,it will be used When release* @param expiration it will expirate after now+expiration* @param overtime if getLock unfinish after overtime,return false* @param frequency the frequency try to get a Lock,more small it will have a large probability to get a Lock* and more pressure on the CPU,* @return true if access,else false* */public boolean getLock(String key,String value,long expiration,long overtime,long frequency)&#123; Future future = executor.submit(() -&gt; &#123; boolean flag = false; while (!flag)&#123; flag = tryLock(key,value,expiration); Thread.sleep(frequency); &#125; return flag; &#125;); try &#123; return (boolean) future.get(overtime,TimeUnit.MILLISECONDS); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; future.cancel(true); return false; &#125;&#125; tip:假如我们要做这种近似无限循环直到符合条件的操作,建议根据业务场景适当的Thread.sleep();让出cpu时间片,减少cpu压力。具体体现为,如果没有sleep,那么cpu的使用率在8线程测试机上直接飙升30%,而加入sleep后cpu使用率低于3%,另外true也可以改为flag标记位,以为今后增加中断功能做拓展 123while&#123;true&#125;&#123; //业务代码&#125; &emsp;上面我们说了分布式锁的简单加锁和解锁,那么接下来就出现了问题了,假如redis崩溃,我们的锁就全部失效。当然我们一般会搭建redis集群,每个redis都会有主从配置,但是有一点要注意,主从redis在同步的时候是异步的,无法保证实时一致性,也就是说如果我们A加了锁,主redis崩溃,锁未同步到从redis,B认为没有加锁,所以他可以成功加锁,这就产生了冲突,对于这种情况,antirez提出的redlock算法或许可以解决这个问题(还未仔细研究redlock算法,无法断言)]]></content>
      <categories>
        <category>lock</category>
      </categories>
      <tags>
        <tag>distributed-lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简记20190927]]></title>
    <url>%2F2019%2F08%2F27%2F%E7%AE%80%E8%AE%B020190927%2F</url>
    <content type="text"><![CDATA[今天用到了metricbeat组件diskio.iostat部分,突然看到一个比较在意的点,对于system.diskio.iostat.read.request.per_sec这个字段,有的描述是每秒读取的扇区数,有的被描述成每秒访问磁盘数。一开始以为是翻译问题,突然联想到磁盘访问原理,我们对磁盘访问的最小单位是扇区,也就是每秒访问扇区数在这个场景下是可以等同理解为每秒访问磁盘次数的]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Exception thrown when sending a message with key='null']]></title>
    <url>%2F2019%2F08%2F25%2Fkafka%20Exception%20thrown%20when%20sending%20a%20message%20with%20key%3D'null'%2F</url>
    <content type="text"><![CDATA[报错122019-08-20 18:45:09 [nioEventLoopGroup-3-15] ERROR o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key=&apos;null&apos; and payload=&apos;xxxxxxxxxxxxxx&apos; to topic abc-event:org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms. 原因&emsp;连接的远程kafka,服务器防火墙没开]]></content>
      <categories>
        <category>kafka</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程模型]]></title>
    <url>%2F2019%2F08%2F17%2F%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[首先我们来谈一谈java中常见的几种IO线程模型 我们知道一般io(socket)都是由accept,read,write,close几种状态组成 ####同步阻塞(bio)在read时需要无限等待直到消息到达,就是阻塞,同步则指的是每一步都需要等待上一步完成然后被调用 ####同步非阻塞()同步阻塞和同步非阻塞的区别就在于,在read时无论是否有数据,立刻返回。那么或许有人会问了,这样有什么意义,还需要自己写while循环包裹来促使其不断访问直到数据到达。其实针对这一点,如果一个程序在底层进入了阻塞状态,也就意味着我们失去了对其控制,对于socket来说,我们只能通过close来使其断开连接离开阻塞状态,而如果我们是非阻塞的情况下,我们发现read数据未到达,可以先允许该线程去做其他工作,过一会再来read一次检测下消息是否到达,同时我们也可以通过标记位来控制其后续行为 ####io多路复用(nio)其实nio也被算作同步非阻塞,不过我们不必拘泥于这些分类,在发展中,是先有的模型,后来才被分类,所以很多情况下分类是模棱两可的。io多路复用跟之前说的同步非阻塞有点关系,io多路复用的read也是非阻塞的,跟之前的最大区别在于,他采用了Selector选择器负责监听每一个socket的各种行为,当该行为被激活的时候,通知后续线程去处理。我们可以想象,此时有巨量的socket链接进来,我们需要为每一个socket创建一个线程来read(即使是使用线程池减少了创建线程的消耗,那么大量的线程也依旧会在while(){//read}上浪费掉),此时我们就需要一个方案来解放这些线程无意义的循环read一个管理者,来管理所有的Socket,这也就诞生了Selector选择器,由Selector负责检测是否有accept,read,write行为,并且通知其他线程来处理,这样我们可以节约大量线程,配合线程池我们就可以用有限的资源处理大量的连接假设我们将流程分类为,io监听和io接收,业务处理三部分,那么nio的核心就是在于将io监听给提取出来单独管理 ####异步说到异步,阻塞与非阻塞的界限更为模糊。下面让我们来看一段代码,这段代码并不是异步,他只是一个回调雏形,后面我会谈到 123456789101112131415161718192021public interface CallBack &#123; void callback();&#125;public class Main &#123; public void work(CallBack callBack)&#123; //业务代码省略... callBack.callback(); &#125; public static void main(String[] args) &#123; Main main = new Main(); System.out.println(1); main.work(new CallBack() &#123; @Override public void callback() &#123; System.out.println(2); &#125; &#125;); System.out.println(3); &#125;&#125; 如果你对代理模式比较熟悉,那么这里你肯定会产生疑问:这不就是代理模式么?嗯,没错,这个东西在我眼里就是代理模式,这里我们传入了自定义的代码,这就是回调的雏形 你肯定会问,这有什么用?还不如直接在一个方法里从头到尾写下来。这是因为我们还没有引入其他的模型,假设我们引入多线程,那么我们的代码就成了这样 1234567891011121314151617181920212223242526public interface CallBack &#123; void callback();&#125;public class Main &#123; public void work(CallBack callBack)&#123; //业务代码 callBack.callback(); &#125; public static void main(String[] args) &#123; Main main = new Main(); System.out.println(1); new Thread(new Runnable() &#123; @Override public void run() &#123; main.work(new CallBack() &#123; @Override public void callback() &#123; System.out.println(2); &#125; &#125;); &#125; &#125;).start(); System.out.println(3); &#125;&#125; 通过对比,我们发现,引入了线程的概念后,他的意义就完全改变,变成了一种近似异步(不必在乎这些概念,你重点关注的应该是是否对于性能有真正的提升)的实现。假设我们面对这样一个场景(此处我们先以非阻塞为例,否则引入自变量过的多不宜于理解),两个socket AB互相长期通信,且每次通信在业务上(我们先将流程简单的分为为io,业务两部分)所需要耗费的时间是不确定的,假若说我们采用同步的方式,每一次A发往B,因B只有一根线程,需要顺序的处理读io,业务操作,写io后才可继续处理A的后续请求。而现在,我们将双方模型改为异步,A只要有请求就向B发送,无需等待B响应,当B读取完消息后(你可能会问A一直在发送消息,B怎么知道A是发送到一个请求还是两个请求,这一点你可以去了解粘包拆包的问题),将消息封装为一个任务,递交给线程池执行(执行完毕后会将执行回调函数来决定接下来的操作,由于任务耗时的不确定性,如果返回消息的话,消息的先后顺序也是不确定的,所以A在请求时需要附带消息的序列号),并立刻返回A一条消息表示自己已经接收到了请求。 到这里你会觉得一切豁然开朗,你仿佛明白了同步异步,阻塞非阻塞。但是,我刚才做的将同步改为异步的操作,真的提高了性能么,假设我线程池只设置一根线程,那么性能跟io和业务在同一根线程有区别么,这真的是异步带来的福利,还是仅仅是多线程带来的福利?我只不过是让A提前知道了,B已经接收到了来自A的消息,但是实际如果线程池只有一根线程的话,业务处理时间是不会改变的。那么异步的意义何在?仅仅是为了利用起多线程并发处理业务这个效果么? ……… 答案:&emsp;异步确实起到了利用多线程的作用,这里的异步我们要明确,异步并非是一个确切的概念,而是一个抽象宏观的概念,是针对于观察点而不断变化的,例如在当前这个场景中,如果A只有当收到B的处理结果才会继续发送,那么B的异步还算是真正的异步吗?我们当然可以说B是异步的,但是对于整体来说,他又是同步的,B在此时的是无法体现其性能优势的。假如说在这个基础上,有许许多多的A连接同一个B向其发送消息,此时B针对每一个连接起一个io线程(这里当然可以用Selector选择器配合io线程池),接到消息后扔到线程池(即使线程池只有一根线程,但是由于io是并发的,省去了io时间)去处理,这时候B又能体现他的性能优势了 那么接下来我们抛开异步同步阻塞非阻塞这个问题,从性能方面总结一下,之前我们提到的线程模型,变化繁多,那么他们为了性能所做的改变都有什么共同点呢?将职责精细划分,对于每一部分职责分别进行深度优化,使得每一部分职责成为一个组件,各组件之间相互通信,以避免某一组件因为另一组件的原因而造成无意义的等待在并发量低的环境下,由于我们机器可以开足够的线程来处理消息,即使义务处理因为io产生了等待,其他的消息也可以选择其他线程去处理。而当并发量增高,此时如果我们线程随之增高的话,会产生大量的线程上下文切换开销,所以我们不得不把控线程的数目,转而通过技巧来充分利用起每一条线程(例如线程池,组件功能划分等方式),这也就是这些线程模型存在并逐渐演化的原因 拓展: Tomcat源码笔记最尾处的Tomcat线程模型 待续]]></content>
      <categories>
        <category>模型</category>
      </categories>
      <tags>
        <tag>模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码笔记]]></title>
    <url>%2F2019%2F08%2F14%2FTomcat%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ps:由于图片过大,所以限制了在博客中显示大小,大家可以右键查看图片看原图本系列均是基于9.0.21版本&emsp;本章我们不会涉及代码,而是笼统的分析Tomcat的实现原理,让大家对全局有一定的掌控,后面几章我会带大家分析代码 ####Tomcat是什么?&emsp;在我看来,Tomcat是利用各种模型和设计方式对socket的深度封装,做到适配各种协议同时达到一定性能的代码组,同时给我们写的各种业务代码(Servlet)提供了容器(也可以理解为tomcat可以将以对象的形式使用我们写的Servlet业务),这是Tomcat的核心。当然,Tomcat还实现了一些其他的比如生命周期管理,但是这些都是为了核心而服务的 &emsp;我们第一次接触Tomcat,相信大多数人都是Hello World。想想当时我们是怎么做的:首先我们建立了个项目,按照网上的教程建好了项目里面的文件夹,导入servlet包,然后开始编写xml配置文件,继承Servlet编写Get,Post代码,然后导出war包放到tomcat下的webapps文件夹,启动tomcat。so easy,然后我们就可以通过浏览器访问我们之前写好的接口了。 &emsp;但是,我们有没有想过是为什么,为什么我们GET中的代码会被调用,为什么我们访问一个网址会执行我们的代码,他又是怎么执行的。这一切,我们将从Servlet与Tomcat的源码解析中找到答案 ####消息接收&emsp;首先,消息是如何接收的。这里,我要阐述下自己的理解,在网络传输的世界里面,一切都是消息,消息是指什么?消息可以理解为一串二进制,一串byte或者字符串,当然,在网络模型的最底层,这些都会被转换为二进制来传输。 &emsp;协议又是什么?协议是一种事先约定的规范,规定了消息格式,消息处理方式等等各种机制,例如我们编写servlet最常用到的http协议,他的可视化表示就如同下面这些内容,其实,每一行后面都跟着\r\n,不过这是换行符,所以在屏幕上展现出来就是一行一行的数据 12345678GET / HTTP/1.1Host: localhost:8080User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:68.0) Gecko/20100101 Firefox/68.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateConnection: keep-aliveUpgrade-Insecure-Requests: 1 &emsp;了解了这些以后,我们就可以继续进行了,既然一切都是消息,那么当我们发送一个http请求的时候,Tomcat最开始接收到的也是一串像是上面这种的字符串,java中接收消息用的就是socket,Tomcat也不例外。所以我在文章最开始的时候说到,Tomcat实质就是对socket的深度封装。在获取到socket套接字以后,Tomcat开始解析,根据传入内容标明协议的不同,按照在代码中定义好的各种协议模板来解析这个字符串,解析完成后封装到Request和Response中交给Servlet执行用户自定义的业务代码,最后再由socket发送响应,这就是Tomcat最浅显的流程 生命周期Tomcat的各个组件也是有生命周期的,这个生命周期由一种设计模式(状态机)来控制,下面让我们了解一下 首先要介绍的是LifecycleMBeanBase类,下面是这个类的类图 我们从Lifecycle接口开始了解,Lifecycle定义了一个状态机,下面是Lifecycle的原注释 12345678910111213141516171819202122232425262728* start()* -----------------------------* | |* | init() |* NEW -»-- INITIALIZING |* | | | | ------------------«-----------------------* | | |auto | | |* | | \|/ start() \|/ \|/ auto auto stop() |* | | INITIALIZED --»-- STARTING_PREP --»- STARTING --»- STARTED --»--- |* | | | | |* | |destroy()| | |* | --»-----«-- ------------------------«-------------------------------- ^* | | | |* | | \|/ auto auto start() |* | | STOPPING_PREP ----»---- STOPPING ------»----- STOPPED -----»-----* | \|/ ^ | ^* | | stop() | | |* | | -------------------------- | |* | | | | |* | | | destroy() destroy() | |* | | FAILED ----»------ DESTROYING ---«----------------- |* | | ^ | |* | | destroy() | |auto |* | --------»----------------- \|/ |* | DESTROYED |* | |* | stop() |* ----»-----------------------------»------------------------------ 我们可以看到,这是一种状态机设计模式,规定了组件生命周期的状态转换,可以方便的进行组件生命周期的管理,从下图我们可以看到,从Server开始几乎每一个组件间接继承/实现了该状态机 接下来让我们看LifecycleBase,这是一个抽象类,实现了fireLifecycleEvent,init,start…等方法fireLifecycleEvent的设计其实是根据观察者模式init,start等方法仅仅是用来控制其生命周期的,每个方法例如init,在内部还会调用initInternal(),Tomcat的很多组件的业务代码全部都在xxxInternal()中,由子类负责实现 LifecycleMBeanBase则对LifecycleBase进行了进一步的实现,我们从他的图中可以看到 其中最关键的是initInternal()和destroyInternal(),主要实现了委托Register类来将子类(类如StandardServer等)注册到bean容器中。如果在看源码过程中大家对ManagedBean或者MBeanServer抱有疑惑,可以先去学习一下JMX规范再回来看容器部分代码,不过即使跳过容器部分,也不影响接下来的部分 Tomcat初始化流程(仅需有个印象即可,想要学到东西的话还是要自己去研究代码)Tomcat工作主要有几个流程:init(负责new各级对象,组件依赖关系,加载配置文件),start(这一步完成时可以正常接收请求开始处理),处理消息,结束首先放一张tomcat init的流程图(简化版) Bootstrap:是入口,例如命令行输入service tomcat start等操作时,便是由这个类来解析,这个类均通过反射操作来调用Catalina Catalina:提供了操控Tomcat启停等行为的方法 LifecycleBase:状态机设计模式,我们后文会提及,StandardServer等大部分组件都会实现该状态机 StandardServer:顶级容器,一个Tomcat对应唯一一个Server,负责管理多个service的启停等行为 StandardService:可以完整执行功能的最小单元容器(如果不明白可以先继续看),下面是一个server.xml文件去掉注释后的内容,根据xml我们可以清楚的看到其构建逻辑,Server包含Service,Service包含Connector和Engine,Engine包含host。假如我们现在面临一个问题,有两个同名的项目需要发布或者希望不同项目部署在不同的端口,那么我们就可以在后面新增一个service 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; ScheduledThreadPoolExecutor:线程池,后面我在讲述线程模型的时候会讲到 Container容器模块,呈现包含关系,之间以责任链形式调用,这里注意一点,虽然方法名是invoke,但实际上并不是通过反射来调用,类似的在tomcat中也有很多继承了Runnable但是有些模块用不到start而是使用run的情况{ Engine{ Host{ Context{ Wrapper } } }} Endpoint:核心部分,后面讲线程模型我会提到 Tomcat的start流程其实跟init流程类似,在宏观上几乎没有改动,因此省略 ####Tomcat接收消息流程这里我认为一张图足以 ####一些关键的节点这里将提供一些消息在Tomcat中传递的关键节点,可以帮助大家通过全局搜索快速定位到源码 init时:&emsp;这里有人会疑惑类的初始化和注入依赖在哪里,答案是digester.parse。这种感觉就像是我们写springMVC时配置的xml一样,在这里xml就是server.xml,digester会根据这个xml来解析并注入依赖 NIO接收消息时:&emsp;关键类Acceptor,其run方法是核心,endpoint.setSocketOptions是转折点,随后一系列操作将accept到的封装为PollerEvent加入队列&emsp;关键类Poller,从队列取处PollerEvent注册到socketChannel的Selector选择器中,并且负责轮询读写事件,将其封装后扔到线程池中&emsp;关键类SocketProcessor,被上文封装的Runnable,负责接下来的读取解析处理返回操作&emsp;关键类Http11Processor,inputBuffer.parseRequestLine获取并解析请求,如果是文件传输类型,那么不会解析消息体,如果是表格那种文本的,就会一起读取出来&emsp;具体从socket读取消息的地方:Http11InputBuffer类的socketWrapper.read。NioSocketWrapper类的nRead = fillReadBuffer(block, to)&emsp;关键类Http11Processor。inputBuffer.parseHeaders将读取出的消息解析为消息头 ####这里我们讲Tomcat线程模型 基础知识:线程模型 TomcatNIO的线程模型其实非常简单,简单到什么程度?让我们看图 甚至于io操作和业务操作在同一根线程上进行,没有经过分离,poller的职责仅仅是检测事件,并不负责io操作, 注意这仅仅是NIO模式,不包括另外两种NIO2和APR模式 我们看server.xml配置文档的时候可以看到允许我们设置一些参数,这里之前tomcatNIO接收请求逻辑图已经描述过,不再赘述。 至于Poller,你在看旧文章时有人会说允许最大值不超过2个。没错,在之前的版本是这样,但是在9.0,我们看到注释文档中有句话,在NIO下Poller被改为仅有一个 1234&lt;update&gt; Remove &lt;code&gt;pollerThreadCount&lt;/code&gt; Connector attribute for NIO, one poller thread is sufficient. (remm)&lt;/update&gt; 通过这些,我们可以分析到,Tomcat NIO模式下,是通过粗暴的增加线程来处理请求,如果同时请求数过多,会被ServerSocketChannel阻拦掉,如果交给线程池的read达到线程池上限,那么就会加入队列中进行排队,这也就是Tomcat无法承受大量并发的原因所在]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端添加数据后动态刷新时获取获取后端数据是旧的]]></title>
    <url>%2F2019%2F07%2F05%2F%E5%89%8D%E7%AB%AF%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE%E5%90%8E%E5%8A%A8%E6%80%81%E5%88%B7%E6%96%B0%E6%97%B6%E8%8E%B7%E5%8F%96%E8%8E%B7%E5%8F%96%E5%90%8E%E7%AB%AF%E6%95%B0%E6%8D%AE%E6%98%AF%E6%97%A7%E7%9A%84%2F</url>
    <content type="text"><![CDATA[情况一(后端缓存)第一种情况是由于后端使用了缓存,且添加数据后由于后端代码问题导致缓存刷新不及时产生的 情况二(前端异步请求)由于服务器响应请求总会有延迟,前端前后相差几毫秒发出了修改请求和查询请求。这种情况下由于网络问题,前端会出现有时可以刷新成功,有时旧数据的情况。解决方法就是前端同步下请求,收到第一个请求的返回后再发送下一个请求]]></content>
      <categories>
        <category>未分类</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql大小写问题]]></title>
    <url>%2F2019%2F07%2F02%2Fmysql%E5%A4%A7%E5%B0%8F%E5%86%99%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[直接上报错,简单来讲就是报错说表没找到 123456782019-07-02 12:26:48.782 WARN 16022 --- [nio-8080-exec-2] o.h.engine.jdbc.spi.SqlExceptionHelper : SQL Error: 1146, SQLState: 42S022019-07-02 12:26:48.782 ERROR 16022 --- [nio-8080-exec-2] o.h.engine.jdbc.spi.SqlExceptionHelper : Table &apos;summertrain.Market_good&apos; doesn&apos;t existorg.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement ...Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement ... 74 moreCaused by: java.sql.SQLSyntaxErrorException: Table &apos;summertrain.Market_good&apos; doesn&apos;t exist ... 92 more 由于团队成员都会先从本地进行调试,本地调试成功就会推送到远程服务器让其自动部署本次情况发生时,成员本地调试通过,远程确报错如上内容 这是由于大小写问题引起的,写这个错误的成员,其本地数据库大小写不敏感,而我们远程服务器使用的mysql大小写敏感,从而summertrain.Market_good,M大写导致出现异常在更改其所有大写M为小写m后,推送到服务器,测试了可以正常使用 如果不想mysql对大小写敏感的话,可以在my.ini配置文件的字段mysqld下增加：lower_case_table_names=1(0表示大小写敏感,1表示不敏感,2表示存储时按大小写,比较时统一按小写比较)。如果我们设置表名大小写的话,需要操作系统支持,例如有的操作系统对于文件名是不区分大小写的,此时设置0会导致mysql启动异常]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[i++不是原子性操作]]></title>
    <url>%2F2019%2F07%2F02%2Fi%2B%2B%E4%B8%8D%E6%98%AF%E5%8E%9F%E5%AD%90%E6%80%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[正文1234567891011121314151617public class CasStudy01 &#123; private static int count = 0; public static void main(String[] args) &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; count++; &#125; &#125;; for (int i = 0; i &lt; 10000; i++) &#123; new Thread(runnable).start(); &#125; Thread.sleep(1000);//为了等子线程全部运行结束 System.out.println(count); &#125;&#125; 输出:9945 Process finished with exit code 0 刚才的代码,照我们的设想,他应该是输出10000,然而每次我们run这段demo,输出结果各不相同这是因为count++这一行代码并不是原子操作,这一行代码实际在运行时,被分为取值,修改,存储三步操作,所以1,2两个线程同时取出值a,并且自增1修改为a+1,再存储的话,两次自增实际上只自增了1]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS机制]]></title>
    <url>%2F2019%2F07%2F02%2FCAS%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[正文一.什么是CAS机制CAS机制的全名叫做compare and swap让我们来看一行代码 1public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 这行代码源于Unsafe类(待补充),参数var1和var2我们先不考虑,var4表示旧值,var6表示新值,这行代码的作用是,如果var4的值等于内存中的现有值,那么将内存中的值替换为var6同时返回true,否则返回false。这就是CAS机制,同时也是其在Java中的体现 二.为什么要使用CAS/有哪些好处一般情况下,当我们并发访问同一个int变量时,我们往往需要加锁操作,但每次加锁会造成大量的开销,影响性能,所以就有了CAS机制,可以让我们在不加锁的情况下做到线程安全 三.CAS机制存在哪些问题1.ABA问题先看一段代码,代码源于Unsafe类①这一步的意义是得到内存中的现有值(参数可忽略) 12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2);① &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6; &#125; ABA问题简述:如代码所示,假设存在线程1,2。线程1运行了①之后等待,线程2开始运行,线程2将A改变为B,再将B改变为A,线程2结束,线程1继续运行,此时,线程1会认为A依旧是原来他读取到的A,期间并没有改变,并且将他按照正常流程改变为B。当然,在正常情况下,变量加减方面这并不会造成什么影响,但是若将CAS用在堆栈或者链表上(网上搜索一下有很多这种ABA问题的例子),或由于业务错误,同时发出了两次修改金钱100为50的操作,但是此时又加入了一个修改金钱50为100的操作(参考自漫画：什么是CAS机制？（进阶篇）),那么就会出现严重的问题解决方案:最常见的ABA问题的解决方案就是诸如java并发包中的AtomicStampedReference类,其内部实现类似于。不同点是,其内部维护了一个内部类Pair,采用记录版本号的方式来避免ABA问题,不过每次在更改时都会new一个新的Pair来进行CAS,如果对性能有极高的要求,那么需要谨慎选择 2.由于在使用CAS时,往往使用的是重试机制,即在while循环中一直重试CAS直到成功为止,所以在极高并发情况下,CAS的失败率将增大,会导致严重的性能问题,对于这个问题,很多时候解决方案是在一般程度并发时采取CAS,极高并发时进行排队。LongAddr钟采用了分治的办法,拥有多个计数器,在高并发时将计数任务分配到多个计数器中,分担压力]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AtomicLong]]></title>
    <url>%2F2019%2F07%2F02%2FAtomicLong%2F</url>
    <content type="text"><![CDATA[正文一.AtomicLong是做什么用的首先我们可以先看一下我的另一篇文章i++不是原子性操作 此时,我们通常选择会是进行这样的操作 123456789101112131415161718192021public class CasStudy01 &#123; private static int count = 0; private synchronized static void add()&#123; count++; &#125; public static void main(String[] args) throws InterruptedException &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; add(); &#125; &#125;; for (int i = 0; i &lt; 10000; i++) &#123; new Thread(runnable).start(); &#125; Thread.sleep(1000); System.out.println(count); &#125;&#125; 我们将count++操作放在了一个带锁的方法里面,来保证其线程安全性。然而,我们知道,加锁解锁操作会造成性能的消耗,在并发量不算太高的情况下,我们可以考虑采用AtomicLong(无锁的方式,采用/2019/07/02/CAS机制/)来保证线程安全性 二.AtomicLong的实现AtomicLong在源码中持有Unsafe类的实例,其大部分操作都是交付给Unsafe类来完成的(Unsafe中大多是本地方法,虽然我们可以通过反射来调用,但是官方强烈不建议我们这么做) AtomicLong里面持有一个long类型的valueOffset变量,这个变量表示的是其value值的内存偏移量(详见JVM内存模型),当我们调用incrementAndGet时,会交付Unsafe类来进行操作 123public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;&#125; 我们传入本类的实例,value的偏移量,以及增加量 12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 在Unsafe中就会进行CAS操作,使得value增加1,这是线程安全的 三.AtomicLong的缺点当并发量极大的时候,由于CAS机制本身的原因,导致CAS失败率极高,从而拖慢性能。此时,我们可以考虑使用LongAdder(待补充)]]></content>
      <categories>
        <category>java</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jpa查询部分字段获取实体类]]></title>
    <url>%2F2019%2F07%2F01%2Fjpa%E6%9F%A5%E8%AF%A2%E9%83%A8%E5%88%86%E5%AD%97%E6%AE%B5%E8%8E%B7%E5%8F%96%E5%AE%9E%E4%BD%93%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[代码已经放到github,test测试中的demo2对应的是sql方式,demo3对应的是hql方式,demo1是分页查询,我另一篇文章会讲到github地址 前言我们平时使用jpa查询时,有两种情况,一种是查询全部字段,另一种是查询部分字段,当我们按通常的sql语句写法查询部分字段时,会出现jpa无法自动解析类型的情况,例如这类报错 1org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute query; SQL [ SELECT sa.name FROM student sa ]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute query 解决方案针对hql和sql分别有两种解决方案 一. &emsp;hql情况下,我们可以用这种方式来解决,有必要注意的一点是,Student里面一定要有相应的构造类 123//TODO 查询部分字段的demo-hql@Query(value = " SELECT new Student(s.name) FROM Student s")List&lt;Student&gt; temp03(); 二. 在sql情况下,我们可以用这种方式解决,首先我们将查出来的数据领jpa解析为map,然后通过我们自己写的map转实体类方法来解决 1234//TODO 查询部分字段的demo-sql@Query(value = " SELECT sa.name FROM student sa ", nativeQuery = true)List&lt;Map&lt;String,Object&gt;&gt; temp02(); 下面是我自己写的一个map转实体类的工具方法 1234567891011121314151617181920212223242526272829303132333435363738/**将map转换为实体类,在jpa查询部分字段时会用到* 使用的时候注意,因为int类型会初始化的问题,无法被FASTJSON忽略掉,所以返回的json可能会带有额外的数字0* 由于是通过属性名来匹配,所以如果数据库字段名和参数名不一致,会导致部分字段映射不到实体,应该这么写* @Query(value = " select id,bar_code01 barCode01,bar_code02 barCode02,bar_code03 barCode03,name,comment from library_good ",nativeQuery=true)* 在查询时取别名,将其跟类的属性名一致 */public static &lt;T&gt;T mapToEntity(Map&lt;String,Object&gt; map,Class&lt;T&gt; targetClass) throws IllegalAccessException, InstantiationException &#123; Class superClass; Field[] fields; T target = targetClass.newInstance(); //接收targetClass的Field List&lt;Field&gt; targetfieldList = new LinkedList&lt;&gt;(); superClass = targetClass; while(superClass!=null&amp;&amp;superClass!=Object.class)&#123; //由于该方法只能获取superClass的参数(private,protect,public等任何声明),但无法获取父类的参数,这里我们迭代一波 fields = superClass.getDeclaredFields(); targetfieldList.addAll(Arrays.asList(fields)); superClass = superClass.getSuperclass(); &#125; //匹配并赋值 for (Field targetfield : targetfieldList) &#123; for (Map.Entry&lt;String, Object&gt; mapEntry : map.entrySet()) &#123; if (targetfield.getName().equals(mapEntry.getKey()))&#123; //暂时保存权限 boolean targetFlag = targetfield.isAccessible(); //赋予权限 targetfield.setAccessible(true); //赋值 targetfield.set(target,mapEntry.getValue()); //恢复原权限 targetfield.setAccessible(targetFlag); break; &#125; &#125; &#125; return target;&#125; 有一点需要注意,由于其底层用了反射,所以无论是通过该种方式取数据还是存数据,均需要setAccessible(true),否则会出现IllegalAccessException异常]]></content>
      <categories>
        <category>jpa</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux安装jdk(非openjdk)]]></title>
    <url>%2F2019%2F07%2F01%2Flinux%E5%AE%89%E8%A3%85jdk(%E9%9D%9Eopenjdk)%2F</url>
    <content type="text"><![CDATA[1.官网下载压缩包,这里我下载的是解压版不是rpm版本,现在可能需要你登陆才可以下载,自己去注册个账户吧,或者用其他方式得到压缩包oracle下载jdk8的网址 2.解压压缩包tar -zxvf 你压缩包的名字.tar.gz 3.安装vim,这是个文本编辑器,你可以把它理解为记事本这种东西,至少我的ubuntu18.04是不自带vim的你可以使用sudo apt install vim这条命令安装,也可以在命令行输入vim按照他的提示安装 3.修改配置文件,原理跟window一样,只要将路径添加到配置文件中,操作系统就可以检测到我们想要安装的东西vim /etc/profile(这里需要注意了,要用root权限进行,前面加sudo) 4.打开配置文件后,我们在尾部追加如下内容,vim的操作方式请自行搜索 123export JAVA_HOME=你的jdk目录,注意是根目录,不是bin目录export CLASSPATH=$JAVA_HOME/lib/export PATH=$JAVA_HOME/bin:$PATH 5.使操作系统重新加载配置文件,注意需要root权限source /etc/profile 6.输入java -version出现java版本信息即我们配置成功了]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet源码笔记]]></title>
    <url>%2F2019%2F06%2F28%2FServlet%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要简单介绍下servlet源码结构 介绍首先类的主要结构关系需要提及一下 1234567891011121314151617模块一interface ServletRequestinterface HttpServletRequest extends ServletRequestclass ServletRequestWrapper implements ServletRequestclass HttpServletRequestWrapper extends ServletRequestWrapper implements HttpServletRequest模块二interface ServletConfiginterface Servletabstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializableabstract class HttpServlet extends GenericServlet 看到上面的类继承关系可能会有点陌生,接下来我给出一段demo 123456789public class HelloWord extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response)&#123; &#125; @Override protected void doPost(HttpServletRequest request, HttpServletResponse response)&#123; &#125; 好了,这下应该不陌生了,我们用Servlet写代码一般都是继承HttpServlet来进行,这属于第二模块,而我们代码中操作的request属于第一模块 在具体分析代码之前,有必要先科普下Servlet的生命周期,平时我们在写Servlet服务端的时候,是不需要写main入口类的,仔细想想,没有入口类为何可以启动?答案来了,是因为tomcat,如果将Servlet看作对象的话,那么tomcat就是Servlet的容器,tomcat负责操控Servlet的生命周期,tomcat从他自己的入口类启动,运行时调用Servlet从而进行一切操作。我看了很多的博客教程,他们都是这么说的: 1&amp;emsp;tomcat作为servlet容器,当http请求进来时,发现没有servlet,那么则初始化一个servlet,将http请求封装为Request交给servlet处理,且servlet为单例重复使用,若长时间未调用才会销毁 但是在tomcat8.5.28+servlet4.0环境下,在不调整任何参数时(默认),我的测试跟上述操作有点出入,servlet并不是在接到http请求时才初始化,而是在随tomcat启动时便已经初始化,这一点可以根据我对servlet初始化init方法打断点,并且以debug方式启动可以看出,各位尽可以自行尝试,当然这不是重点,大体流程了解即可。 第二模块 Servlet这个接口类定义了一系列与tomcat相互交互的一系列接口 ServletConfig看名字也知道是提供配置信息的一个接口 GenericServlet这个是对Servlet和ServletConfig接口的一些实现,另外增加了一些log方法来传递异常 HttpServlet这个类就定义了对GET,PUT,POST,HEAD,DELETE等各种HTTP方法的处理方式那么问题来了,我们知道之前定义的Servlet接口类提供给tomcat一些交互接口,那么唯一涉及到各种操作的只有service方法,他是如何跟各种HTTP方法的处理结合起来的呢?在源码面前的朋友可以追着service方法一路下来,最终在HttpServlet中可以看到service方法的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 从代码中可以看到,他是负责匹配头部信息来进行分发操作,不清楚http报文的朋友可以看下面,这是用firefox浏览器发送的一组请求,第一行的GET即为method.equals(…)中的method内容 12345678910GET / HTTP/1.1Host: localhost:8080User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:67.0) Gecko/20100101 Firefox/67.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateConnection: keep-aliveUpgrade-Insecure-Requests: 1Pragma: no-cacheCache-Control: no-cache 到此为止第二模块基本结束 接下来分析第一模块 ServletRequest主要用来获取被储存信息,例如储存被tomcat封装后的http信息 HttpServletRequest特别针对http协议的各种参数在ServletRequest基础上进行了扩展 ServletRequestWrapper也是个扩展,不过有个特殊的地方要注意,这个类的构造方法public ServletRequestWrapper(ServletRequest request)接收了一个ServletRequest对象,以后的参数就从这个对象里面拿取 HttpServletRequestWrapper就是上面三个类的实现了,没什么意思 #####通过这些介绍,Servlet已经不再神秘,大家可以仔细去看源码,其实Servlet构造十分简单,真正起到关键作用的还是例如Tomcat等Servlet容器基础知识:Tomcat源码笔记]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[getParamter为何接收不到postman构造的信息]]></title>
    <url>%2F2019%2F06%2F28%2FgetParamter%E4%B8%BA%E4%BD%95%E6%8E%A5%E6%94%B6%E4%B8%8D%E5%88%B0postman%E6%9E%84%E9%80%A0%E7%9A%84%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[之前发生了这样一件事,由于是用的postman发送的消息,消息体有几种常用构造方式:none,form-data,x-www-form-urlencoded有一些构造方式通过getParameter方法是获取不到数据的,接下来让我们一起看一下这个问题 首先我对两种构造方式进行了抓包,看到他们发出去的请求首先时form-data格式下的Get,Post方式 1234567891011121314151617181920GET http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------130695699130126180335395User-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 255c0f6d-0296-4095-af08-3a0bc1e1f756Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 281Connection: keep-alive----------------------------130695699130126180335395Content-Disposition: form-data; name=&quot;username&quot;admin----------------------------130695699130126180335395Content-Disposition: form-data; name=&quot;password&quot;123456----------------------------130695699130126180335395-- 123456789101112131415161718192021POST http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------666026373795318990654180User-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: f7e5f00a-65d9-4aba-961d-34762e8c410cHost: localhost:8080accept-encoding: gzip, deflatecontent-length: 281Connection: keep-alive----------------------------666026373795318990654180Content-Disposition: form-data; name=&quot;username&quot;admin----------------------------666026373795318990654180Content-Disposition: form-data; name=&quot;password&quot;123456----------------------------666026373795318990654180--` 接下来是x-www-form-urlencoded格式下的Get,Post方式 123456789101112GET http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: application/x-www-form-urlencodedUser-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 7e03a95e-5539-4a2a-b0e7-0fe399a4af28Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 30Connection: keep-aliveusername=admin&amp;password=123456 123456789101112POST http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: application/x-www-form-urlencodedUser-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 13ed95bb-803d-451c-b046-db4e5eb142b2Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 30Connection: keep-aliveusername=admin&amp;password=123456 根据实验结果,在POST模式下x-www-form-urlencoded才可以通过getParameter获取数据,那么导致这一问题的原因是什么呢?通过代码,锁定了Tomcat Request类的parseParameters方法 12345678910111213141516//这里对消息格式进行判断if ("multipart/form-data".equals(contentType)) &#123; parseParts(false); success = true; return;&#125;//在这一行对method进行了判断,如果是POST,则进行接下来的解析,如果是其他的,那么直接返回if( !getConnector().isParseBodyMethod(getMethod()) ) &#123; success = true; return;&#125;//这里对消息格式进行判断if (!("application/x-www-form-urlencoded".equals(contentType))) &#123; success = true; return;&#125;]]></content>
      <categories>
        <category>http</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用git完成服务器自动化部署解决方案]]></title>
    <url>%2F2019%2F06%2F24%2F%E5%88%A9%E7%94%A8git%E5%AE%8C%E6%88%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言本篇主要讲述在团队合作时,如何利用脚本和git在前后端分离模式下,测试时的服务器自动化部署问题(只是个人想法和实践,仅作参考。下方代码已经经过测试,保证做好适配后可用) 适用情况:团队合作,前后端分离,后端需根据前端需求持续变更代码并提供给前端测试 需要的环境:linux服务器,git,maven,java 2019.6.25更新昨天忘记了说一个重要的问题,如果你是在window环境下写的shell脚本到linux环境下运行,由于两者系统换行符不一致,需要在linux中执行vim你的脚本名,进入脚本:set ff=unix,注意”:”这个符号需要带着,不明白的请去搜vim命令一定要赋予脚本可执行权限,赋权具体命令下文sh代码有提及刚才看了些博客,有提到用hook触发,而不是自己去循环访问,思路待定 原答案&emsp;首先讲成果,上代码,我会在其中伴随大量讲解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#!/bin/sh###本代码中的该项目特有名称均会用其他文本代替,例如我的项目名就用demo代替###该项目的git文件夹我们暂且称呼为demofunction updateAndRestart()&#123; #切换到online分支,这个地方需要根据自己的git分支做适配 git checkout online #git rev-parse online命令用于查看本地的online分支最后一次提交id LOCALONLINE=$(git rev-parse online) #用于这句话就是打印到控制台,没什么意义 echo "本地ONLINE为$&#123;LOCALONLINE&#125;" #从远程仓库fetch,这里选择fetch而不是pull也是为了性能考虑,如有偏差,请根据自己想法修改 git fetch echo "从远程仓库拉取结束" #获取已经fetch下来的远程仓库的HEAD,这里要做郑重说明,如果git rev-parse orgin/online虽然是获取远程仓库online分支的最后一次提交,但是他不会真的去连接远程仓库拉取信息,而是读取本地的远程仓库的缓存信息,所以之前需要git fetch也是为了刷新本地缓存的作用。 #关于如何直接去远程查看远程仓库最后一次提交这个问题,我找了一半天没有找到这个方法 REMOTEONLINE=$(git rev-parse origin/online) echo "远程HEAD为$&#123;REMOTEONLINE&#125;" #检查远程仓库是否与本地ONLINE一致,若不一致,则证明了远程已更新 if [[ $LOCALONLINE != $REMOTEONLINE ]]; then echo "进入重启-------------------------------------------" #将远程分支的更新合并到本地,由于git pull命令可以理解为git fetch+git merge,这一步的意义这里不做赘述 git merge $REMOTEONLINE #杀死所有名为下列的进程 #这里只讲一点,由于awk命令下文介绍过,那么此时可以想象文本状态是kill -9 进程pid,sh命令是把之前的输出当作脚本来执行,那么就成果实现了批量kill进程 jps | grep demo.jar|awk '&#123;print "kill -9 " $1&#125;'|sh #重新打包jar mvn clean package #给jar授权 #这里有必要作下说明,此脚本我是运行在root用户下(这点很重要,如果是其他用户,则在权限方面需要注意做适配) #chomd是赋权命令,后面参数则是其权限,参数每部分的具体意义请自行查询 #这条命令是授予demo.jar的root用户可执行权限(原本被mvn打包后默认为读写权限,没有执行权限) chmod 744 /你的目录/demo.jar #这个文件我不知道是什么,在window环境下尝试情况,删除了也不会有什么影响。有人说.jar是不带依赖的,original是带依赖的,但是观察文件大小,发现original文件只有几十k,明显不是带着依赖一起打包的样子 chmod 744 /你的目录/demo.jar.original #后台运行jar,具体意义可见后半部分文章 nohup java -jar /你的目录t/demo.jar &gt; /你的目录/xxx-`date +%Y-%m-%d-%H-%M-%S`.log 2&gt;&amp;1 &amp; sleep 15 fi&#125;###上面的是函数,只有调用时才会运行,首先运行的是下面代码#首先cd到你的demo存放目录,这一步可有可无,根据你的项目路径做好适配就行cd /xxx/xxx/demo#下面这行代码是脚本启动时用来检测是否demo程序正在运行#这里顺便讲解下shell和java的知识# jps该命令可以理解为和ps命令类似,只不过是用来显示java进程# |这个管道命令我无法解释,自己去搜索引擎# grep用来抓取出包含demo.jar字段的行# awk一种文本处理命令,将文本按照我们定义的规则处理# 这里'&#123;print $1&#125;'代表的是输出每行的第一个参数(在我的linux系统中,每行的第一个参数正好是java进程的pid,其他人需要根据情况适配,注意'引号一定要有)# wc -l是统计命令,由于之前都是一行一行打印的,所以此命令可以很轻松统计有多少在运行# 综上所述,该条命令的意义在于:统计名为demo.jar的java进程的数目,awk这段命令后来想了想属于冗余命令了,可视情况去除SUMMERTRAINPID=$(jps | grep demo.jar |awk '&#123;print $1&#125;' |wc -l)if [[ SUMMERTRAINPID!=0 ]]; then echo "脚本开始,检测到程序未启动,先启动程序------------------------" #summertrain-`date +%Y-%m-%d-%H-%M-%S` #下面这条命令是在后台启动demo.jar并且将输出重定向到指定的log文件,如果文件不存在会新建 #其实nohup java -jar /你的路径/demo.jar &gt; /你log日志的路径/文件名.log &amp;这条命令就可以做到这一点 #下面这条命令多出来的几个字段表示的是将error日志也重定向到log文件 #小提示,在自己的脚本,log日志太长不易于观看,所以可以文件名可以在后缀加上`date +%Y-%m-%d-%H-%M-%S`,参数可以在生成文件时自动加上当前实际后缀,例如demolog-`date +%Y-%m-%d-%H-%M-%S`.log nohup java -jar /你的路径/demo.jar &gt; /你log日志的路径/文件名.log 2&gt;&amp;1 &amp; #这里我令他休眠15秒等待java程序启动 sleep 15fi#接下来开始循环检测是否git有更新while truedo echo "自动循环中" updateAndRestart sleep 10done 写该脚本时参考了git命令,shell语法,linux命令shell脚本中的空格一定要注意,少一个空格往往意义就会不同如果团队人数更多,那么该方法不再试用,每次程序启动都需一定时间。]]></content>
      <categories>
        <category>git</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql启动(无需添加到服务)]]></title>
    <url>%2F2019%2F06%2F22%2Fmysql%E5%90%AF%E5%8A%A8(%E6%97%A0%E9%9C%80%E6%B7%BB%E5%8A%A0%E5%88%B0%E6%9C%8D%E5%8A%A1)%2F</url>
    <content type="text"><![CDATA[已经安装配置好mysql,无需将mysql添加到服务项中即可启动 1.打开cmd,通过cd到mysql安装/解压文件夹下 2.调用bin下的mysqld.exe文件(如果是linux则可能是.sh) 3.参数为my.ini/my.cnf 4.具体命令为&emsp;bin/mysqld –defaults-file=./my.ini 5.输入该命令后cmd应该会挂起,此时mysql已经启动成功。如果关闭cmd命令行那么mysql关闭]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用笔记]]></title>
    <url>%2F2019%2F06%2F21%2Fgit%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[详细介绍git使用和配置(不包括安装) 什么是git? 首先我用通俗语言解释下,git是一种版本控制工具,你既可以在本地进行版本控制,也可以与搭建好git服务器的远端进行同步 如何使用? windows的可以官方下载安装包,linux可以命令行下载(对于window来说可能需配置环境变量,可有可无) 配置全局信息 随便找个地方右键打开git bash ps:这里配置的昵称和邮箱可以随便写,作用体现在,假如你提交了git,那么在git记录中会显示提交者昵称和邮箱,即为下面输入的 输入git config –global user.name “你的昵称” 输入git config –global user.name “你的邮箱” 创建git仓库 随便找个地方新建文件夹进去打开git bash(此处建议选一个父文件夹作为git仓库目录) 输入git init 该命令的作用是在当前文件夹下生成git仓库所需文件(注意,这里git仓库通常指的是一个项目,而不是管理多个项目的仓库,而且生成的文件为.git是个隐藏文件夹) 使用git 当我们在文件夹下做了操作以后(添加修改删除文件),可以git add . .代表暂存全部文件,当然也可以是其他写法或部分文件 此时我们已经add成功,接下来git commit -m”此次提交的注释” 此时,本地的使用基本就到这里(此外还有分支,冲突等各种概念,不在本篇讲) 关联github/码云(也可以是其他的或者自己搭建的git服务器) 首先我们在git bash中生成一对密钥,命令为:ssh-keygen -t rsa -C “你之前填写的邮箱” 其实一般码云或者github都要官方绑定密钥教程,基本都一样 生成密钥后我们把密钥配置到git服务器上 如果是github之类的你从个人setting可以找到配置密钥的地方,如果是个人git服务器则可能需要手动添加 刚才生成的密钥分为公钥和私钥,一般公钥以.pub结尾,这部分涉及到密码学,你只需要知道这是非对称密钥用来代替用户密码做身份验证就好了,具体内容请自行搜索 在window中默认保存在C://user/{你的用户名}/.ssh文件夹中 当我们配置到服务器公钥后,就可以正常的git clone 远程私有仓库等操作 可视化界面SourceTree SourceTree需要注册啥的,可能被墙了,自己解决 这里要提到一点,它仅仅是个可视化界面,仍然需要你安装git 团队里有人出现了SourceTree没有权限的问题,打开密钥设置界面(不同版本打开位置有所不同,大概都是在工具-选项这一块),找到之前我们生成的密钥(上文提到过位置),将私钥添加进去即可 解决冲突 这里我不建议大家团队合作时在采用pull来拉代码,这样的话如果有冲突,文件会被标记为冲突,建议用fetch先检测一下 如果是在commit之前拉取,产生了冲突,那么可以针对冲突的文件,抛弃自己的修改(等fetch+merge之后在手动增加回来) 如果是在commit之后拉取产生了冲突,就会出现无法拉取也无法推送的情况,这时候我们可以撤销commit操作,使其返回到上一种情况 1234567git reset [--参数] 提交id参数有: mixed:不删除改动的代码,撤销commit和add soft:不删除改动代码,撤销commit hard:删除改动代码,撤销commit和add(这种是用指定的提交id强行覆盖掉现有代码)示例: git reset --soft xxxxxxxxx 这里我们说的是命令行的操作,如果是sourceTree,那么对应的就是”重置当前分支到此次提交” 如果想要抛弃对方的提交,使自己本次提交强行覆盖掉对方,那么可以见下方代码。如果是sourceTree的话,则需要取选项里面允许强制提交。此外,如果用的github之类的这种托管远程仓库,那么对方可能还会设置了权限,只有拥有者有权限强制推送,项目所属人去github里面设置一下就好(这一点笔者没有实践) 1git push --force origin 一些其他的诸如merge,rebase的用法 这些用法笔者的理解有限,这里附一个知乎的提问,大家可以参考下在开发过程中使用git rebase还是git merge，优缺点分别是什么？ 一些其他的bug如何解决 现象:原本中文编码变成了/xxx/xxx之类的八进制码解决:修改本地git仓库下的.git隐藏文件夹下config文件,在[core]部分新增quotepath = false字段保存即可 git忽略规则&emsp;当我们同步到远程仓库时,配置了.gitignore可以令git按照我们定义的规则,选择性的跟踪本地仓库的文件&emsp;具体的语法规范这里不做描述,搜索引擎搜教程即可&emsp;这里我将列出学生team一个springboot项目合作时使用的.gitignore。对官方生成的git做了少许改动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263HELP.mdtarget/!.mvn/wrapper/maven-wrapper.jar!**/src/main/**!**/src/test/**###团队合作config######由于团队合作时每个成员数据库账户密码不一样,所以每个成员都有个个人配置信息,在通用配置里面引入###person.properties###springboot######此处表示忽略测试文件夹###/src/test/java### STS ###.apt_generated.classpath.factorypath.project.settings.springBeans.sts4-cache### IntelliJ IDEA ###.idea*.iws*.iml*.ipr### NetBeans ###/nbproject/private//nbbuild//dist//nbdist//.nb-gradle/build/### VS Code ###.vscode/# Log file*.log# Compiled class file*.class# BlueJ files*.ctxt# Mobile Tools for Java (J2ME).mtj.tmp/# Package Files #*.jar*.war*.nar*.ear*.zip*.tar.gz*.rarhs_err_pid* &emsp;常见问题:配置了.gitignore仍然无法忽略&emsp;解决方式:git rm –cached filename&emsp;删除该filename文件的本地缓存,然后再进行add和commit等操作,等push到远端后,以后再就不会被追踪&emsp;原因:这是由于在配置.gitignore之前该文件就已经被git追踪造成的,]]></content>
      <categories>
        <category>教程</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[welcome]]></title>
    <url>%2F2019%2F06%2F20%2Fwelcome%2F</url>
    <content type="text"><![CDATA[####测试图片,图片无效 图片下标 下一行文本 ####测试图片,图片无效]]></content>
  </entry>
</search>
