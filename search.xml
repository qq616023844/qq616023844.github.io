<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[IDEA运行tomcat源码]]></title>
    <url>%2F2019%2F09%2F15%2FIDEA%E8%BF%90%E8%A1%8Ctomcat%E6%BA%90%E7%A0%81%2F</url>
    <content type="text"><![CDATA[这里提供下Tomcat9最简单运行源码的实现 1.去官网下载tomcat源码 2.新建pom.xml文件,与webapps,conf等文件夹平级存放,增加一些缺少的jar包(这些其实可以自己多运行几次试出来缺哪些jar包),插件的作用是不用每次刷新maven的jar包都需要调整java版本号,不会改版本号的可以看IDEA修改java版本号 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;apacheTomcat9&lt;/groupId&gt; &lt;artifactId&gt;apacheTomcat9&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;name&gt;apacheTomcat9&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;dependencies&gt; &lt;!-- https://mvnrepository.com/artifact/org.apache.ant/ant --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.ant&lt;/groupId&gt; &lt;artifactId&gt;ant&lt;/artifactId&gt; &lt;version&gt;1.10.5&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/javax.xml/jaxrpc-api --&gt; &lt;dependency&gt; &lt;groupId&gt;javax.xml&lt;/groupId&gt; &lt;artifactId&gt;jaxrpc-api&lt;/artifactId&gt; &lt;version&gt;1.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/wsdl4j/wsdl4j --&gt; &lt;dependency&gt; &lt;groupId&gt;wsdl4j&lt;/groupId&gt; &lt;artifactId&gt;wsdl4j&lt;/artifactId&gt; &lt;version&gt;1.6.2&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.eclipse.jdt/core --&gt; &lt;dependency&gt; &lt;groupId&gt;org.eclipse.jdt&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;3.1.1&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; 3.删除test文件夹(因为有一些依赖我们没有引入,导致报错,test是测试用的demo不重要,可以直接删),删除webapps文件夹下的内容,放入自己打包好的war包(就是自己建的servlet项目打包出来的jar) 4.创建入口 5.修改JDTCompiler文件内容(报错的地方直接仿照前面的手动改成字符串就可以,tomcat8的源码似乎不会出现这种问题,如果懒得自己改的话我在文章最末尾贴了整个类的代码,可以自行复制) ps:JDTCompiler修改后的文件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524package org.apache.jasper.compiler;import java.io.BufferedOutputStream;import java.io.BufferedReader;import java.io.ByteArrayOutputStream;import java.io.File;import java.io.FileInputStream;import java.io.FileNotFoundException;import java.io.FileOutputStream;import java.io.IOException;import java.io.InputStream;import java.io.InputStreamReader;import java.io.Reader;import java.util.ArrayList;import java.util.HashMap;import java.util.List;import java.util.Locale;import java.util.Map;import java.util.StringTokenizer;import org.apache.jasper.JasperException;import org.apache.juli.logging.Log;import org.apache.juli.logging.LogFactory;import org.eclipse.jdt.core.compiler.IProblem;import org.eclipse.jdt.internal.compiler.ClassFile;import org.eclipse.jdt.internal.compiler.CompilationResult;import org.eclipse.jdt.internal.compiler.Compiler;import org.eclipse.jdt.internal.compiler.DefaultErrorHandlingPolicies;import org.eclipse.jdt.internal.compiler.ICompilerRequestor;import org.eclipse.jdt.internal.compiler.IErrorHandlingPolicy;import org.eclipse.jdt.internal.compiler.IProblemFactory;import org.eclipse.jdt.internal.compiler.classfmt.ClassFileReader;import org.eclipse.jdt.internal.compiler.env.ICompilationUnit;import org.eclipse.jdt.internal.compiler.env.INameEnvironment;import org.eclipse.jdt.internal.compiler.env.NameEnvironmentAnswer;import org.eclipse.jdt.internal.compiler.impl.CompilerOptions;import org.eclipse.jdt.internal.compiler.problem.DefaultProblemFactory;/** * JDT class compiler. This compiler will load source dependencies from the * context classloader, reducing dramatically disk access during * the compilation process. * * Based on code from Cocoon2. * * @author Remy Maucherat */public class JDTCompiler extends org.apache.jasper.compiler.Compiler &#123; private final Log log = LogFactory.getLog(JDTCompiler.class); // must not be static /** * Compile the servlet from .java file to .class file */ @Override protected void generateClass(Map&lt;String,SmapStratum&gt; smaps) throws FileNotFoundException, JasperException, Exception &#123; long t1 = 0; if (log.isDebugEnabled()) &#123; t1 = System.currentTimeMillis(); &#125; final String sourceFile = ctxt.getServletJavaFileName(); final String outputDir = ctxt.getOptions().getScratchDir().getAbsolutePath(); String packageName = ctxt.getServletPackageName(); final String targetClassName = ((packageName.length() != 0) ? (packageName + ".") : "") + ctxt.getServletClassName(); final ClassLoader classLoader = ctxt.getJspLoader(); String[] fileNames = new String[] &#123;sourceFile&#125;; String[] classNames = new String[] &#123;targetClassName&#125;; final List&lt;JavacErrorDetail&gt; problemList = new ArrayList&lt;&gt;(); class CompilationUnit implements ICompilationUnit &#123; private final String className; private final String sourceFile; CompilationUnit(String sourceFile, String className) &#123; this.className = className; this.sourceFile = sourceFile; &#125; @Override public char[] getFileName() &#123; return sourceFile.toCharArray(); &#125; @Override public char[] getContents() &#123; char[] result = null; try (FileInputStream is = new FileInputStream(sourceFile); InputStreamReader isr = new InputStreamReader( is, ctxt.getOptions().getJavaEncoding()); Reader reader = new BufferedReader(isr)) &#123; char[] chars = new char[8192]; StringBuilder buf = new StringBuilder(); int count; while ((count = reader.read(chars, 0, chars.length)) &gt; 0) &#123; buf.append(chars, 0, count); &#125; result = new char[buf.length()]; buf.getChars(0, result.length, result, 0); &#125; catch (IOException e) &#123; log.error(Localizer.getMessage("jsp.error.compilation.source", sourceFile), e); &#125; return result; &#125; @Override public char[] getMainTypeName() &#123; int dot = className.lastIndexOf('.'); if (dot &gt; 0) &#123; return className.substring(dot + 1).toCharArray(); &#125; return className.toCharArray(); &#125; @Override public char[][] getPackageName() &#123; StringTokenizer izer = new StringTokenizer(className, "."); char[][] result = new char[izer.countTokens()-1][]; for (int i = 0; i &lt; result.length; i++) &#123; String tok = izer.nextToken(); result[i] = tok.toCharArray(); &#125; return result; &#125; public boolean ignoreOptionalProblems() &#123; return false; &#125; &#125; final INameEnvironment env = new INameEnvironment() &#123; @Override public NameEnvironmentAnswer findType(char[][] compoundTypeName) &#123; StringBuilder result = new StringBuilder(); for (int i = 0; i &lt; compoundTypeName.length; i++) &#123; if(i &gt; 0) result.append('.'); result.append(compoundTypeName[i]); &#125; return findType(result.toString()); &#125; @Override public NameEnvironmentAnswer findType(char[] typeName, char[][] packageName) &#123; StringBuilder result = new StringBuilder(); int i=0; for (; i &lt; packageName.length; i++) &#123; if(i &gt; 0) result.append('.'); result.append(packageName[i]); &#125; if(i &gt; 0) result.append('.'); result.append(typeName); return findType(result.toString()); &#125; private NameEnvironmentAnswer findType(String className) &#123; if (className.equals(targetClassName)) &#123; ICompilationUnit compilationUnit = new CompilationUnit(sourceFile, className); return new NameEnvironmentAnswer(compilationUnit, null); &#125; String resourceName = className.replace('.', '/') + ".class"; try (InputStream is = classLoader.getResourceAsStream(resourceName)) &#123; if (is != null) &#123; byte[] classBytes; byte[] buf = new byte[8192]; ByteArrayOutputStream baos = new ByteArrayOutputStream(buf.length); int count; while ((count = is.read(buf, 0, buf.length)) &gt; 0) &#123; baos.write(buf, 0, count); &#125; baos.flush(); classBytes = baos.toByteArray(); char[] fileName = className.toCharArray(); ClassFileReader classFileReader = new ClassFileReader(classBytes, fileName, true); return new NameEnvironmentAnswer(classFileReader, null); &#125; &#125; catch (IOException exc) &#123; log.error(Localizer.getMessage("jsp.error.compilation.dependent", className), exc); &#125; catch (org.eclipse.jdt.internal.compiler.classfmt.ClassFormatException exc) &#123; log.error(Localizer.getMessage("jsp.error.compilation.dependent", className), exc); &#125; return null; &#125; private boolean isPackage(String result) &#123; if (result.equals(targetClassName)) &#123; return false; &#125; String resourceName = result.replace('.', '/') + ".class"; try (InputStream is = classLoader.getResourceAsStream(resourceName)) &#123; return is == null; &#125; catch (IOException e) &#123; // we are here, since close on is failed. That means it was not null return false; &#125; &#125; @Override public boolean isPackage(char[][] parentPackageName, char[] packageName) &#123; StringBuilder result = new StringBuilder(); int i=0; if (parentPackageName != null) &#123; for (; i &lt; parentPackageName.length; i++) &#123; if(i &gt; 0) result.append('.'); result.append(parentPackageName[i]); &#125; &#125; if (Character.isUpperCase(packageName[0])) &#123; if (!isPackage(result.toString())) &#123; return false; &#125; &#125; if(i &gt; 0) result.append('.'); result.append(packageName); return isPackage(result.toString()); &#125; @Override public void cleanup() &#123; &#125; &#125;; final IErrorHandlingPolicy policy = DefaultErrorHandlingPolicies.proceedWithAllProblems(); final Map&lt;String,String&gt; settings = new HashMap&lt;&gt;(); settings.put(CompilerOptions.OPTION_LineNumberAttribute, CompilerOptions.GENERATE); settings.put(CompilerOptions.OPTION_SourceFileAttribute, CompilerOptions.GENERATE); settings.put(CompilerOptions.OPTION_ReportDeprecation, CompilerOptions.IGNORE); if (ctxt.getOptions().getJavaEncoding() != null) &#123; settings.put(CompilerOptions.OPTION_Encoding, ctxt.getOptions().getJavaEncoding()); &#125; if (ctxt.getOptions().getClassDebugInfo()) &#123; settings.put(CompilerOptions.OPTION_LocalVariableAttribute, CompilerOptions.GENERATE); &#125; // Source JVM if(ctxt.getOptions().getCompilerSourceVM() != null) &#123; String opt = ctxt.getOptions().getCompilerSourceVM(); if(opt.equals("1.1")) &#123; settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_1); &#125; else if(opt.equals("1.2")) &#123; settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_2); &#125; else if(opt.equals("1.3")) &#123; settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_3); &#125; else if(opt.equals("1.4")) &#123; settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_4); &#125; else if(opt.equals("1.5")) &#123; settings.put(CompilerOptions.OPTION_Source, CompilerOptions.VERSION_1_5); &#125; else if(opt.equals("1.6")) &#123; settings.put(CompilerOptions.OPTION_Source, "1.6"); &#125; else if(opt.equals("1.7")) &#123; settings.put(CompilerOptions.OPTION_Source, "1.7"); &#125; else if(opt.equals("1.8")) &#123; settings.put(CompilerOptions.OPTION_Source, "1.8"); // Version format changed from Java 9 onwards. // Support old format that was used in EA implementation as well &#125; else if(opt.equals("9") || opt.equals("1.9")) &#123; settings.put(CompilerOptions.OPTION_Source, "1.9"); &#125; else if(opt.equals("10")) &#123; settings.put(CompilerOptions.OPTION_Source, "10"); &#125; else if(opt.equals("11")) &#123; settings.put(CompilerOptions.OPTION_Source, "11"); &#125; else if(opt.equals("12")) &#123; // Constant not available in latest ECJ version shipped with // Tomcat. May be supported in a snapshot build. // This is checked against the actual version below. settings.put(CompilerOptions.OPTION_Source, "12"); &#125; else if(opt.equals("13")) &#123; // Constant not available in latest ECJ version shipped with // Tomcat. May be supported in a snapshot build. // This is checked against the actual version below. settings.put(CompilerOptions.OPTION_Source, "13"); &#125; else &#123; log.warn(Localizer.getMessage("jsp.warning.unknown.sourceVM", opt)); settings.put(CompilerOptions.OPTION_Source, "1.8"); &#125; &#125; else &#123; // Default to 1.8 settings.put(CompilerOptions.OPTION_Source, "1.8"); &#125; // Target JVM if(ctxt.getOptions().getCompilerTargetVM() != null) &#123; String opt = ctxt.getOptions().getCompilerTargetVM(); if(opt.equals("1.1")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_1); &#125; else if(opt.equals("1.2")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_2); &#125; else if(opt.equals("1.3")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_3); &#125; else if(opt.equals("1.4")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_4); &#125; else if(opt.equals("1.5")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, CompilerOptions.VERSION_1_5); settings.put(CompilerOptions.OPTION_Compliance, CompilerOptions.VERSION_1_5); &#125; else if(opt.equals("1.6")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, "1.6"); settings.put(CompilerOptions.OPTION_Compliance, "1.6"); &#125; else if(opt.equals("1.7")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, "1.7"); settings.put(CompilerOptions.OPTION_Compliance, "1.7"); &#125; else if(opt.equals("1.8")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, "1.8"); settings.put(CompilerOptions.OPTION_Compliance, "1.8"); // Version format changed from Java 9 onwards. // Support old format that was used in EA implementation as well &#125; else if(opt.equals("9") || opt.equals("1.9")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, "1.9"); settings.put(CompilerOptions.OPTION_Compliance, "1.9"); &#125; else if(opt.equals("10")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, "10"); settings.put(CompilerOptions.OPTION_Compliance, "10"); &#125; else if(opt.equals("11")) &#123; settings.put(CompilerOptions.OPTION_TargetPlatform, "11"); settings.put(CompilerOptions.OPTION_Compliance, "11"); &#125; else if(opt.equals("12")) &#123; // Constant not available in latest ECJ version shipped with // Tomcat. May be supported in a snapshot build. // This is checked against the actual version below. settings.put(CompilerOptions.OPTION_TargetPlatform, "12"); settings.put(CompilerOptions.OPTION_Compliance, "12"); &#125; else if(opt.equals("13")) &#123; // Constant not available in latest ECJ version shipped with // Tomcat. May be supported in a snapshot build. // This is checked against the actual version below. settings.put(CompilerOptions.OPTION_TargetPlatform, "13"); settings.put(CompilerOptions.OPTION_Compliance, "13"); &#125; else &#123; log.warn(Localizer.getMessage("jsp.warning.unknown.targetVM", opt)); settings.put(CompilerOptions.OPTION_TargetPlatform, "1.8"); &#125; &#125; else &#123; // Default to 1.8 settings.put(CompilerOptions.OPTION_TargetPlatform, "1.8"); settings.put(CompilerOptions.OPTION_Compliance, "1.8"); &#125; final IProblemFactory problemFactory = new DefaultProblemFactory(Locale.getDefault()); final ICompilerRequestor requestor = new ICompilerRequestor() &#123; @Override public void acceptResult(CompilationResult result) &#123; try &#123; if (result.hasProblems()) &#123; IProblem[] problems = result.getProblems(); for (int i = 0; i &lt; problems.length; i++) &#123; IProblem problem = problems[i]; if (problem.isError()) &#123; String name = new String(problems[i].getOriginatingFileName()); try &#123; problemList.add(ErrorDispatcher.createJavacError (name, pageNodes, new StringBuilder(problem.getMessage()), problem.getSourceLineNumber(), ctxt)); &#125; catch (JasperException e) &#123; log.error(Localizer.getMessage("jsp.error.compilation.jdtProblemError"), e); &#125; &#125; &#125; &#125; if (problemList.isEmpty()) &#123; ClassFile[] classFiles = result.getClassFiles(); for (int i = 0; i &lt; classFiles.length; i++) &#123; ClassFile classFile = classFiles[i]; char[][] compoundName = classFile.getCompoundName(); StringBuilder classFileName = new StringBuilder(outputDir).append('/'); for (int j = 0; j &lt; compoundName.length; j++) &#123; if(j &gt; 0) classFileName.append('/'); classFileName.append(compoundName[j]); &#125; byte[] bytes = classFile.getBytes(); classFileName.append(".class"); try (FileOutputStream fout = new FileOutputStream( classFileName.toString()); BufferedOutputStream bos = new BufferedOutputStream(fout)) &#123; bos.write(bytes); &#125; &#125; &#125; &#125; catch (IOException exc) &#123; log.error(Localizer.getMessage("jsp.error.compilation.jdt"), exc); &#125; &#125; &#125;; ICompilationUnit[] compilationUnits = new ICompilationUnit[classNames.length]; for (int i = 0; i &lt; compilationUnits.length; i++) &#123; String className = classNames[i]; compilationUnits[i] = new CompilationUnit(fileNames[i], className); &#125; CompilerOptions cOptions = new CompilerOptions(settings); // Check source/target JDK versions as the newest versions are allowed // in Tomcat configuration but may not be supported by the ECJ version // being used. String requestedSource = ctxt.getOptions().getCompilerSourceVM(); if (requestedSource != null) &#123; String actualSource = CompilerOptions.versionFromJdkLevel(cOptions.sourceLevel); if (!requestedSource.equals(actualSource)) &#123; log.warn(Localizer.getMessage("jsp.warning.unsupported.sourceVM", requestedSource, actualSource)); &#125; &#125; String requestedTarget = ctxt.getOptions().getCompilerTargetVM(); if (requestedTarget != null) &#123; String actualTarget = CompilerOptions.versionFromJdkLevel(cOptions.targetJDK); if (!requestedTarget.equals(actualTarget)) &#123; log.warn(Localizer.getMessage("jsp.warning.unsupported.targetVM", requestedTarget, actualTarget)); &#125; &#125; cOptions.parseLiteralExpressionsAsConstants = true; Compiler compiler = new Compiler(env, policy, settings, requestor, problemFactory); compiler.compile(compilationUnits); if (!ctxt.keepGenerated()) &#123; File javaFile = new File(ctxt.getServletJavaFileName()); if (!javaFile.delete()) &#123; throw new JasperException(Localizer.getMessage( "jsp.warning.compiler.javafile.delete.fail", javaFile)); &#125; &#125; if (!problemList.isEmpty()) &#123; JavacErrorDetail[] jeds = problemList.toArray(new JavacErrorDetail[0]); errDispatcher.javacError(jeds); &#125; if( log.isDebugEnabled() ) &#123; long t2=System.currentTimeMillis(); log.debug("Compiled " + ctxt.getServletJavaFileName() + " " + (t2-t1) + "ms"); &#125; if (ctxt.isPrototypeMode()) &#123; return; &#125; // JSR45 Support if (! options.isSmapSuppressed()) &#123; SmapUtil.installSmap(smaps); &#125; &#125;&#125;]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IDEA修改java版本号]]></title>
    <url>%2F2019%2F09%2F15%2FIDEA%E4%BF%AE%E6%94%B9java%E7%89%88%E6%9C%AC%E5%8F%B7%2F</url>
    <content type="text"><![CDATA[总共有4处需要修改,直接上图(在后面),如果懒得每次改版本号,也可以利用maven插件 123456789&lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;自行找个版本&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt;&lt;/plugin&gt;]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[隧道连接redis集群报错]]></title>
    <url>%2F2019%2F09%2F15%2F%E9%9A%A7%E9%81%93%E8%BF%9E%E6%8E%A5redis%E9%9B%86%E7%BE%A4%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[####问题描述&emsp;java springboot程序访问redis,由于redis集群分布于多个目标服务器上,且均有防火墙阻拦,平时调试都是通过tunnel建立隧道来访问。单个redis通过隧道访问成功,但是redis集群通过隧道访问失败。 使用的jar包如下 12&lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; 单个redis连接时配置如下(已经提前建立好隧道) 12spring.redis.host: 单个ipspring.redis.port: 单个端口 redis集群连接时配置如下(已经提前建立好隧道) 1spring.redis.cluster.nodes: localhost:6379 按照单个redis连接配置时正常连接,按照集群配置时报错 1234567org.springframework.data.redis.ClusterStateFailureException: Could not retrieve cluster information. CLUSTER NODES returned with error. - ipA:端口A failed: Could not get a resource from the pool - ipB:端口B failed: Could not get a resource from the pool - ipC:端口C failed: Could not get a resource from the pool - ipD:端口D failed: Could not get a resource from the pool - ipE:端口E failed: Could not get a resource from the pool - ipF:端口F failed: Could not get a resource from the pool ####问题排查因为配置文件配置了生成环境开发环境测试环境等一系列的环境,分别对应不同的集群配置,因为当时只配置了一个ip端口,以为是读取配置文件出现错乱,所以在这方面排查了一段时间 后来通过分析源码发现了问题,我们在配置文件中配置的服务器ip和端口,在集群模式下仅仅相当于入口的作用。即,先与配置文件中的ip端口建立socket链接,然后发送cluster获取集群信息命令,然后断开该socket链接,转而直接跟各个集群服务器建立socket链接,从而导致后续请求不会走我们配置的隧道。也就出现了之前我们只配置了一个ip和端口缺出现了和6个redis均连接失败的情况,误以为时配置读取问题]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql设置默认值无效]]></title>
    <url>%2F2019%2F09%2F14%2Fmysql%E8%AE%BE%E7%BD%AE%E9%BB%98%E8%AE%A4%E5%80%BC%E6%97%A0%E6%95%88%2F</url>
    <content type="text"><![CDATA[场景:数据库mysql,框架hibernate 原因: 根据hibernate打印出的sql信息可以发现,如果实体类字段为null,则仍会insert这个字段为null,而mysql设置的默认值生效的前提是,当我们insert一条记录时,我们不指定某字段的值,他才会自动生成默认值,而我们用save的时候指定该字段的值为null,此时如果我们mysql设置的为not null,那么同时也会报错 解决: @DynamicInsert(默认为true) @DynamicUpdate(默认为true) 这两个注解是类注解,作用为:当插入/更新一条记录时,只insert/update改变的信息,而不是将所有字段都update为当前的 即,没有注解时update的sql为 12 Hibernate: select student0_.id as id1_0_0_, student0_.default_value as default_2_0_0_, student0_.password as password3_0_0_, student0_.username as username4_0_0_ from user_student student0_ where student0_.id=?Hibernate: update user_student set default_value=?, password=?, username=? where id=? 有注解时的sql为 12 Hibernate: select student0_.id as id1_0_0_, student0_.default_value as default_2_0_0_, student0_.password as password3_0_0_, student0_.username as username4_0_0_ from user_student student0_ where student0_.id=?Hibernate: update user_student set username=? where id=? 可以看到,当需要update时(如果没有做更改则无论有无注解均不会执行update命令),无注解的将所有字段全都update为当前值,有注解的则只update修改值。在每次update之前,均会执行select查询出数据库当前该字段的状态进行比较后在执行更新操作 网上有人说@DynamicInsert这个注解的作用是,如果值为null,则不set该值。 从片面的角度来看,这句话是对的,如果我们在save时指定id,因为insert对于一条记录只会出现一次,在执行insert之前,hibernate回去数据库执行select查询,如果查询不到数据,那么我们当前值的null和他当前缓存种的值null是相等的,就认为该值没有修改,在后面执行insert时mysql就会给该值赋予默认值。如果我们没指定id,那么他就不会select,同理,跟缓存中的null相等,在组建insert语句时就不会附带该值 那么有这么一种情况,假若我们save了一个新记录,然后又update该记录,但是在update时,有个字段我们没有赋值,其为null,那么跟从数据库select出的数据发生了变化,就会set null向数据库中,此时如果我们数据库时not null的,就会报错,反之,则会该字段的值被设为了null]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>hibernate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[分布式锁]]></title>
    <url>%2F2019%2F08%2F28%2F%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%2F</url>
    <content type="text"><![CDATA[####什么是锁?&emsp;锁是一个多方可以共同访问的元素,各个访问者通过对该元素的信息的判断,按照一定事先约定的行为进行协调的功能。这个元素可以是任何的东西,根据事先约定的行为的不同也会随之变化。 &emsp;例如,一个队列,如果来访者发现自己的id在该队列的头部,那么就认为自己拥有了锁,可以执行某些逻辑,这时候这个队列就相当于一个锁。锁也可以是一个boolean类型的对象,当他为true或者false时,其他线程可以来竞争使得boolean状态改变,从而认为自己获取了锁(当然需要考虑使用场景)。锁也可以是一个信号量,也可以是一个节点,例如zookeeper中,一个节点存在与否就意味着是否可以竞争锁(当然行为是我们自己来定的,zookeeper和redis仅仅是提供了一个放置锁的地方)。当然,最重要的一点就是原子性,我们在加锁和解锁的时候,要充分考虑使用场景来决定对锁的判断策略 ####redis锁的实现&emsp;对于redis分布式锁来说,常用的莫过于SETNX,SET,DEL这几个函数了tip:现在SET函数可以传递参数,例如过期时间,在已存在值时的反应,对于添加成功或者失败的返回值这几个元素,所以SET已经完全可以取代SETNX,甚至说比SETNX表现更好。因为SETNX在加锁时还要设置过期时间字段,需要由客户端根据这个字段来判断锁是否过期,这样一牵扯到非原子性的问题,就会十分复杂 &emsp;最简单的加锁解锁代码如下,由于在解锁时,伴随着锁过期的可能,我们需要先判断锁是否是本客户端加的,再去解锁,否则A加锁,A过期,B加锁,A完成任务解锁,就把B加的锁解掉了。解锁操作我们可以想象,他是先查询再操作,不是原子性,所以我们需要封装LUA脚本来使这两条语句具备原子性具体SET参数意义可以自行搜索 123456789101112131415161718192021222324252627282930313233343536/*** Non-blocking try to hold a lock* if true,the work must be finished within millisecond,else the distributed-lock is meaningless* @param key the key of lock* @param value a unique String,it will be used When release* @param expiration it will expirate after now+expiration* @return true if access,else false* */public boolean tryLock(String key,String value,long expiration)&#123; //try to create a record if not exist Object res = redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; JedisCommands connect = (JedisCommands) redisConnection.getNativeConnection(); //SETNX can be replace by SET from Redis 2.6.12 version return connect.set(key,value,"NX","PX",expiration); &#125;); return res!=null;&#125;/*** Non-blocking release a lock,if lock has expiration,nothing happen* @param key the key of lock* @param value the String you set When try to hold a lock* */public void relaseLock(String key,String value)&#123; redisTemplate.execute((RedisCallback) redisConnection -&gt; &#123; Object obj = redisConnection.getNativeConnection(); System.out.println(obj.getClass().getName()); if (obj instanceof JedisCluster) &#123; JedisCluster connection = (JedisCluster) obj; return connection.eval(LUA,Collections.singletonList(key),Collections.singletonList(value)); &#125;else if (obj instanceof Jedis)&#123; Jedis connection = (Jedis) obj; return connection.eval(LUA,Collections.singletonList(key),Collections.singletonList(value)); &#125; return null; &#125;) ;&#125; 虽然SET方法是瞬时的,无法阻塞,但是我们可以自己封装方法来达到阻塞加锁的效果 123456789101112131415161718192021222324252627/*** blocking try to hold a lock* if true,the work must be finished within millisecond,else the distributed-lock is meaningless* @param key the key of lock* @param value a unique String,it will be used When release* @param expiration it will expirate after now+expiration* @param overtime if getLock unfinish after overtime,return false* @param frequency the frequency try to get a Lock,more small it will have a large probability to get a Lock* and more pressure on the CPU,* @return true if access,else false* */public boolean getLock(String key,String value,long expiration,long overtime,long frequency)&#123; Future future = executor.submit(() -&gt; &#123; boolean flag = false; while (!flag)&#123; flag = tryLock(key,value,expiration); Thread.sleep(frequency); &#125; return flag; &#125;); try &#123; return (boolean) future.get(overtime,TimeUnit.MILLISECONDS); &#125; catch (InterruptedException | ExecutionException | TimeoutException e) &#123; future.cancel(true); return false; &#125;&#125; tip:假如我们要做这种近似无限循环直到符合条件的操作,建议根据业务场景适当的Thread.sleep();让出cpu时间片,减少cpu压力。具体体现为,如果没有sleep,那么cpu的使用率在8线程测试机上直接飙升30%,而加入sleep后cpu使用率低于3%,另外true也可以改为flag标记位,以为今后增加中断功能做拓展 123while&#123;true&#125;&#123; //业务代码&#125; &emsp;上面我们说了分布式锁的简单加锁和解锁,那么接下来就出现了问题了,假如redis崩溃,我们的锁就全部失效。当然我们一般会搭建redis集群,每个redis都会有主从配置,但是有一点要注意,主从redis在同步的时候是异步的,无法保证实时一致性,也就是说如果我们A加了锁,主redis崩溃,锁未同步到从redis,B认为没有加锁,所以他可以成功加锁,这就产生了冲突,对于这种情况,antirez提出的redlock算法或许可以解决这个问题(还未仔细研究redlock算法,无法断言)]]></content>
      <categories>
        <category>探索笔记</category>
      </categories>
      <tags>
        <tag>distributed-lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java中的锁]]></title>
    <url>%2F2019%2F08%2F28%2Fjava%E4%B8%AD%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[锁的几种用法####synchronizede.g:1用synchronized对一个代码块加锁,object可以是任意的对象,任何其他synchronized(该对象)的代码块均需要获取到锁以后才可以执行,如果object=this,那么就是锁住的整个对象 123synchronized(object) &#123; //代码块&#125; e.g:2下方代码锁住的是此方法所在的对象,也就是如果该对象中两个不同的方法前面均有synchronized时,在多个线程操作同一个对象时,同一时间只有一个方法可以被调用 123public synchronized void work()&#123; System.out.println(123);&#125; e.g:3如果是对一个class或者static类型的对象加锁,那么因为class和static类型的对象只会在jvm虚拟机保存一份,所以加锁要额外注意e.g:4特别强调的一点是,synchronized是针对对象加锁,Class和static也可以看作一个对象,假如说出现下面代码,此时你的锁是无效的,虽然引用没变,但是引用指向的对象已经改变 123456Object obj = new Object();synchronized(obj)&#123; obj = new Object(); //代码块&#125;` 待续 拓展:分布式锁]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
        <tag>lock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简记20190927]]></title>
    <url>%2F2019%2F08%2F27%2F%E7%AE%80%E8%AE%B020190927%2F</url>
    <content type="text"><![CDATA[今天用到了metricbeat组件diskio.iostat部分,突然看到一个比较在意的点,对于system.diskio.iostat.read.request.per_sec这个字段,有的描述是每秒读取的扇区数,有的被描述成每秒访问磁盘数。一开始以为是翻译问题,突然联想到磁盘访问原理,我们对磁盘访问的最小单位是扇区,也就是每秒访问扇区数在这个场景下是可以等同理解为每秒访问磁盘次数的]]></content>
      <categories>
        <category>简记</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Exception thrown when sending a message with key='null']]></title>
    <url>%2F2019%2F08%2F25%2FBUG_kafka_01%2F</url>
    <content type="text"><![CDATA[报错122019-08-20 18:45:09 [nioEventLoopGroup-3-15] ERROR o.s.k.s.LoggingProducerListener - Exception thrown when sending a message with key=&apos;null&apos; and payload=&apos;xxxxxxxxxxxxxx&apos; to topic abc-event:org.apache.kafka.common.errors.TimeoutException: Failed to update metadata after 60000 ms. 原因&emsp;连接的远程kafka,服务器防火墙没开]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[线程模型]]></title>
    <url>%2F2019%2F08%2F17%2F%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[首先我们来谈一谈java中常见的几种IO线程模型 我们知道一般io(socket)都是由accept,read,write,close几种状态组成 ####同步阻塞(bio)在read时需要无限等待直到消息到达,就是阻塞,同步则指的是每一步都需要等待上一步完成然后被调用 ####同步非阻塞()同步阻塞和同步非阻塞的区别就在于,在read时无论是否有数据,立刻返回。那么或许有人会问了,这样有什么意义,还需要自己写while循环包裹来促使其不断访问直到数据到达。其实针对这一点,如果一个程序在底层进入了阻塞状态,也就意味着我们失去了对其控制,对于socket来说,我们只能通过close来使其断开连接离开阻塞状态,而如果我们是非阻塞的情况下,我们发现read数据未到达,可以先允许该线程去做其他工作,过一会再来read一次检测下消息是否到达,同时我们也可以通过标记位来控制其后续行为 ####io多路复用(nio)其实nio也被算作同步非阻塞,但是在使用时也可以成为异步非阻塞,不过我们不必拘泥于这些分类,在发展中,是先有的模型,后来才被分类,所以很多情况下分类是模棱两可的。io多路复用跟之前说的同步非阻塞有点关系,io多路复用的read也是非阻塞的,跟之前的最大区别在于,他采用了Selector选择器负责监听每一个socket的各种行为,当该行为被激活的时候,通知后续线程去处理。我们可以想象,此时有巨量的socket链接进来,我们需要为每一个socket创建一个线程来read(即使是使用线程池减少了创建线程的消耗,那么大量的线程也依旧会在while(){//read}上浪费掉),此时我们就需要一个方案来解放这些线程无意义的循环read一个管理者,来管理所有的Socket,这也就诞生了Selector选择器,由Selector负责检测是否有accept,read,write行为,并且通知其他线程来处理,这样我们可以节约大量线程,配合线程池我们就可以用有限的资源处理大量的连接假设我们将流程分类为,io监听和io接收,业务处理三部分,那么nio的核心就是在于将io监听给提取出来单独管理 ####异步说到异步,阻塞与非阻塞的界限更为模糊。下面让我们来看一段代码,这段代码并不是异步,他只是一个回调雏形,后面我会谈到 123456789101112131415161718192021public interface CallBack &#123; void callback();&#125;public class Main &#123; public void work(CallBack callBack)&#123; //业务代码省略... callBack.callback(); &#125; public static void main(String[] args) &#123; Main main = new Main(); System.out.println(1); main.work(new CallBack() &#123; @Override public void callback() &#123; System.out.println(2); &#125; &#125;); System.out.println(3); &#125;&#125; 如果你对代理模式比较熟悉,那么这里你肯定会产生疑问:这不就是代理模式么?嗯,没错,这个东西在我眼里就是代理模式,只不过我们一般使用的代理模式的代码是写死在代理类中,而这里我们传入了自定义的代码,这就是回调的雏形 你肯定会问,这有什么用?还不如直接在一个方法里从头到尾写下来。这是因为我们还没有引入其他的模型,假设我们引入多线程,那么我们的代码就成了这样 1234567891011121314151617181920212223242526public interface CallBack &#123; void callback();&#125;public class Main &#123; public void work(CallBack callBack)&#123; //业务代码 callBack.callback(); &#125; public static void main(String[] args) &#123; Main main = new Main(); System.out.println(1); new Thread(new Runnable() &#123; @Override public void run() &#123; main.work(new CallBack() &#123; @Override public void callback() &#123; System.out.println(2); &#125; &#125;); &#125; &#125;).start(); System.out.println(3); &#125;&#125; 通过对比,我们发现,引入了线程的概念后,他的意义就完全改变,变成了一种近似异步(不必在乎这些概念,你重点关注的应该是是否对于性能有真正的提升)的实现。假设我们面对这样一个场景(此处我们先以非阻塞为例,否则引入自变量过的多不宜于理解),两个socket AB互相长期通信,且每次通信在业务上(我们先将流程简单的分为为io,业务两部分)所需要耗费的时间是不确定的,假若说我们采用同步的方式,每一次A发往B,因B只有一根线程,需要顺序的处理读io,业务操作,写io后才可继续处理A的后续请求。而现在,我们将双方模型改为异步,A只要有请求就向B发送,无需等待B响应,当B读取完消息后(你可能会问A一直在发送消息,B怎么知道A是发送到一个请求还是两个请求,这一点你可以去了解粘包拆包的问题),将消息封装为一个任务,递交给线程池执行(执行完毕后会将执行回调函数来决定接下来的操作,由于任务耗时的不确定性,如果返回消息的话,消息的先后顺序也是不确定的,所以A在请求时需要附带消息的序列号),并立刻返回A一条消息表示自己已经接收到了请求。 到这里你会觉得一切豁然开朗,你仿佛明白了同步异步,阻塞非阻塞,感觉自己成为了大佬。但是,我刚才做的将同步改为异步的操作,真的提高了性能么,假设我线程池只设置一根线程,那么性能跟io和业务在同一根线程有区别么,这真的是异步带来的福利,还是仅仅是多线程带来的福利?我只不过是让A提前知道了,B已经接收到了来自A的消息,但是实际如果线程池只有一根线程的话,业务处理时间是不会改变的。那么异步的意义何在?仅仅是为了利用起多线程并发处理业务这个效果么? ……… 答案:&emsp;异步确实起到了利用多线程的作用,这里的异步我们要明确,异步并非是一个确切的概念,而是一个抽象宏观的概念,是针对于观察点而不断变化的,例如在当前这个场景中,如果A只有当收到B的处理结果才会继续发送,那么B的异步还算是真正的异步吗?我们当然可以说B是异步的,但是对于整体来说,他又是同步的,B在此时的是无法体现其性能优势的。假如说在这个基础上,有许许多多的A连接同一个B向其发送消息,此时B针对每一个连接起一个io线程(这里当然可以用Selector选择器配合io线程池),接到消息后扔到线程池(即使线程池只有一根线程,但是由于io是并发的,省去了io时间)去处理,这时候B又能体现他的性能优势了 那么接下来我们抛开异步同步阻塞非阻塞这个问题,从性能方面总结一下,之前我们提到的线程模型,变化繁多,那么他们为了性能所做的改变都有什么共同点呢?将职责精细划分,对于每一部分职责分别进行深度优化,使得每一部分职责成为一个组件,各组件之间相互通信,以避免某一组件因为另一组件的原因而造成无意义的等待在并发量低的环境下,由于我们机器可以开足够的线程来处理消息,即使义务处理因为io产生了等待,其他的消息也可以选择其他线程去处理。而当并发量增高,此时如果我们线程随之增高的话,会产生大量的线程上下文切换开销,所以我们不得不把控线程的数目,转而通过技巧来充分利用起每一条线程(例如线程池,组件功能划分等方式),这也就是这些线程模型存在并逐渐演化的原因 拓展: Tomcat源码笔记最尾处的Tomcat线程模型 待续]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Tomcat源码笔记]]></title>
    <url>%2F2019%2F08%2F14%2FTomcat%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[ps:由于图片过大,所以限制了在博客中显示大小,大家可以右键查看图片看原图本系列均是基于9.0.21版本&emsp;本章我们不会涉及代码,而是笼统的分析Tomcat的实现原理,让大家对全局有一定的掌控,后面几章我会带大家分析代码 ####Tomcat是什么?&emsp;在我看来,Tomcat是利用各种模型和设计方式对socket的深度封装,做到适配各种协议同时达到一定性能的代码组,同时给我们写的各种业务代码(Servlet)提供了容器(也可以理解为tomcat可以将以对象的形式使用我们写的Servlet业务),这是Tomcat的核心。当然,Tomcat还实现了一些其他的比如生命周期管理,但是这些都是为了核心而服务的 &emsp;我们第一次接触Tomcat,相信大多数人都是Hello World。想想当时我们是怎么做的:首先我们建立了个项目,按照网上的教程建好了项目里面的文件夹,导入servlet包,然后开始编写xml配置文件,继承Servlet编写Get,Post代码,然后导出war包放到tomcat下的webapps文件夹,启动tomcat。so easy,然后我们就可以通过浏览器访问我们之前写好的接口了。 &emsp;但是,我们有没有想过是为什么,为什么我们GET中的代码会被调用,为什么我们访问一个网址会执行我们的代码,他又是怎么执行的。这一切,我们将从Servlet与Tomcat的源码解析中找到答案 ####消息接收&emsp;首先,消息是如何接收的。这里,我要阐述下自己的理解,在网络传输的世界里面,一切都是消息,消息是指什么?消息可以理解为一串二进制,一串byte或者字符串,当然,在网络模型的最底层,这些都会被转换为二进制来传输。 &emsp;协议又是什么?协议是一种事先约定的规范,规定了消息格式,消息处理方式等等各种机制,例如我们编写servlet最常用到的http协议,他的可视化表示就如同下面这些内容,其实,每一行后面都跟着\r\n,不过这是换行符,所以在屏幕上展现出来就是一行一行的数据 12345678GET / HTTP/1.1Host: localhost:8080User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:68.0) Gecko/20100101 Firefox/68.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateConnection: keep-aliveUpgrade-Insecure-Requests: 1 &emsp;了解了这些以后,我们就可以继续进行了,既然一切都是消息,那么当我们发送一个http请求的时候,Tomcat最开始接收到的也是一串像是上面这种的字符串,java中接收消息用的就是socket,Tomcat也不例外。所以我在文章最开始的时候说到,Tomcat实质就是对socket的深度封装。在获取到socket套接字以后,Tomcat开始解析,根据传入内容标明协议的不同,按照在代码中定义好的各种协议模板来解析这个字符串,解析完成后封装到Request和Response中交给Servlet执行用户自定义的业务代码,最后再由socket发送响应,这就是Tomcat最浅显的流程 生命周期Tomcat的各个组件也是有生命周期的,这个生命周期由一种设计模式(状态机)来控制,下面让我们了解一下 首先要介绍的是LifecycleMBeanBase类,下面是这个类的类图 我们从Lifecycle接口开始了解,Lifecycle定义了一个状态机,下面是Lifecycle的原注释 12345678910111213141516171819202122232425262728* start()* -----------------------------* | |* | init() |* NEW -»-- INITIALIZING |* | | | | ------------------«-----------------------* | | |auto | | |* | | \|/ start() \|/ \|/ auto auto stop() |* | | INITIALIZED --»-- STARTING_PREP --»- STARTING --»- STARTED --»--- |* | | | | |* | |destroy()| | |* | --»-----«-- ------------------------«-------------------------------- ^* | | | |* | | \|/ auto auto start() |* | | STOPPING_PREP ----»---- STOPPING ------»----- STOPPED -----»-----* | \|/ ^ | ^* | | stop() | | |* | | -------------------------- | |* | | | | |* | | | destroy() destroy() | |* | | FAILED ----»------ DESTROYING ---«----------------- |* | | ^ | |* | | destroy() | |auto |* | --------»----------------- \|/ |* | DESTROYED |* | |* | stop() |* ----»-----------------------------»------------------------------ 我们可以看到,这是一种状态机设计模式,规定了组件生命周期的状态转换,可以方便的进行组件生命周期的管理,从下图我们可以看到,从Server开始几乎每一个组件间接继承/实现了该状态机 接下来让我们看LifecycleBase,这是一个抽象类,实现了fireLifecycleEvent,init,start…等方法fireLifecycleEvent的设计其实是根据观察者模式init,start等方法仅仅是用来控制其生命周期的,每个方法例如init,在内部还会调用initInternal(),Tomcat的很多组件的业务代码全部都在xxxInternal()中,由子类负责实现 LifecycleMBeanBase则对LifecycleBase进行了进一步的实现,我们从他的图中可以看到 其中最关键的是initInternal()和destroyInternal(),主要实现了委托Register类来将子类(类如StandardServer等)注册到bean容器中。容器部分设计是符合JMX规范的,此处暂且不谈,如果在看源码过程中大家对ManagedBean或者MBeanServer抱有疑惑,可以先去学习一下JMX规范再回来看容器部分代码,不过即使跳过容器部分,也不影响接下来的部分 Tomcat初始化流程(仅需有个印象即可,想要学到东西的话还是要自己去研究代码)Tomcat工作主要有几个流程:init(负责new各级对象,组件依赖关系,加载配置文件),start(这一步完成时可以正常接收请求开始处理),处理消息,结束首先放一张tomcat init的流程图(简化版) Bootstrap:是入口,例如命令行输入service tomcat start等操作时,便是由这个类来解析,这个类均通过反射操作来调用Catalina Catalina:提供了操控Tomcat启停等行为的方法 LifecycleBase:状态机设计模式,我们后文会提及,StandardServer等大部分组件都会实现该状态机 StandardServer:顶级容器,一个Tomcat对应唯一一个Server,负责管理多个service的启停等行为 StandardService:可以完整执行功能的最小单元容器(如果不明白可以先继续看),下面是一个server.xml文件去掉注释后的内容,根据xml我们可以清楚的看到其构建逻辑,Server包含Service,Service包含Connector和Engine,Engine包含host。假如我们现在面临一个问题,有两个同名的项目需要发布或者希望不同项目部署在不同的端口,那么我们就可以在后面新增一个service 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Server port="8005" shutdown="SHUTDOWN"&gt; &lt;Listener className="org.apache.catalina.startup.VersionLoggerListener" /&gt; &lt;Listener className="org.apache.catalina.core.AprLifecycleListener" SSLEngine="on" /&gt; &lt;Listener className="org.apache.catalina.core.JreMemoryLeakPreventionListener" /&gt; &lt;Listener className="org.apache.catalina.mbeans.GlobalResourcesLifecycleListener" /&gt; &lt;Listener className="org.apache.catalina.core.ThreadLocalLeakPreventionListener" /&gt; &lt;GlobalNamingResources&gt; &lt;Resource name="UserDatabase" auth="Container" type="org.apache.catalina.UserDatabase" description="User database that can be updated and saved" factory="org.apache.catalina.users.MemoryUserDatabaseFactory" pathname="conf/tomcat-users.xml" /&gt; &lt;/GlobalNamingResources&gt; &lt;Service name="Catalina"&gt; &lt;Connector port="8080" protocol="HTTP/1.1" connectionTimeout="20000" redirectPort="8443" /&gt; &lt;Connector port="8009" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine name="Catalina" defaultHost="localhost"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase"/&gt; &lt;/Realm&gt; &lt;Host name="localhost" appBase="webapps" unpackWARs="true" autoDeploy="true"&gt; &lt;Valve className="org.apache.catalina.valves.AccessLogValve" directory="logs" prefix="localhost_access_log" suffix=".txt" pattern="%h %l %u %t &amp;quot;%r&amp;quot; %s %b" /&gt; &lt;/Host&gt; &lt;/Engine&gt; &lt;/Service&gt;&lt;/Server&gt; ScheduledThreadPoolExecutor:线程池,后面我在讲述线程模型的时候会讲到 Container容器模块,呈现包含关系,之间以责任链形式调用,这里注意一点,虽然方法名是invoke,但实际上并不是通过反射来调用,类似的在tomcat中也有很多继承了Runnable但是有些模块用不到start而是使用run的情况{ Engine{ Host{ Context{ Wrapper } } }} Endpoint:核心部分,后面讲线程模型我会提到 Tomcat的start流程其实跟init流程类似,在宏观上几乎没有改动,因此省略 ####Tomcat接收消息流程这里我认为一张图足以 ####一些关键的节点这里将提供一些消息在Tomcat中传递的关键节点,可以帮助大家通过全局搜索快速定位到源码 init时:&emsp;这里有人会疑惑类的初始化和注入依赖在哪里,答案是digester.parse。这种感觉就像是我们写springMVC时配置的xml一样,在这里xml就是server.xml,digester会根据这个xml来解析并注入依赖 NIO接收消息时:&emsp;关键类Acceptor,其run方法是核心,endpoint.setSocketOptions是转折点,随后一系列操作将accept到的封装为PollerEvent加入队列&emsp;关键类Poller,从队列取处PollerEvent注册到socketChannel的Selector选择器中,并且负责轮询读写事件,将其封装后扔到线程池中&emsp;关键类SocketProcessor,被上文封装的Runnable,负责接下来的读取解析处理返回操作&emsp;关键类Http11Processor,inputBuffer.parseRequestLine获取并解析请求,如果是文件传输类型,那么不会解析消息体,如果是表格那种文本的,就会一起读取出来&emsp;具体从socket读取消息的地方:Http11InputBuffer类的socketWrapper.read。NioSocketWrapper类的nRead = fillReadBuffer(block, to)&emsp;关键类Http11Processor。inputBuffer.parseHeaders将读取出的消息解析为消息头 ####这里我们讲Tomcat线程模型 基础知识:线程模型 TomcatNIO的线程模型其实非常简单,简单到什么程度?让我们看图 甚至于io操作和业务操作在同一根线程上进行,没有经过分离,poller的职责仅仅是检测事件,并不负责io操作, 注意这仅仅是NIO模式,不包括另外两种NIO2和APR模式 我们看server.xml配置文档的时候可以看到允许我们设置一些参数,这里之前tomcatNIO接收请求逻辑图已经描述过,不再赘述。 至于Poller,你在看旧文章时有人会说允许最大值不超过2个。没错,在之前的版本是这样,但是在9.0,我们看到注释文档中有句话,在NIO下Poller被改为仅有一个 1234&lt;update&gt; Remove &lt;code&gt;pollerThreadCount&lt;/code&gt; Connector attribute for NIO, one poller thread is sufficient. (remm)&lt;/update&gt; 通过这些,我们可以分析到,Tomcat NIO模式下,是通过粗暴的增加线程来处理请求,如果同时请求数过多,会被ServerSocketChannel阻拦掉,如果交给线程池的read达到线程池上限,那么就会加入队列中进行排队,这也就是Tomcat无法承受大量并发的原因所在]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
        <tag>源码</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于在上海生活六个月提前要做的准备]]></title>
    <url>%2F2019%2F07%2F23%2F%E5%85%B3%E4%BA%8E%E5%9C%A8%E4%B8%8A%E6%B5%B7%E7%94%9F%E6%B4%BB%E5%85%AD%E4%B8%AA%E6%9C%88%E6%8F%90%E5%89%8D%E8%A6%81%E5%81%9A%E7%9A%84%E5%87%86%E5%A4%87%2F</url>
    <content type="text"><![CDATA[&emsp;首先不得不提到的一点就是气候差异(夏天)。不下雨的情况下,北方空气湿度40%左右,上海长期80%偶尔60%,导致的就是,在北方糙汉子还可以2天洗一次澡,到了上海恨不得一天洗两次,而且晚上睡觉会感觉床单特别潮湿(这里楼主用了150多块左右吸湿垫和粗布床单,感觉比一开始带来的学生宿舍用床单好了不少)。晾衣服有风还好说,床单在高层楼的穿堂风下一天就干了,然而不开窗户即使3天也晾不干一条内裤 &emsp;接下来,我要说一下去上海租房我做了哪些准备。首先,我提前先浏览了各大租房app,发现价格和质量实在是无法承受,于是去了豆瓣小组蹲点,蹲了一个月终于蹲到了一个不错的合租房(建议先问下公司有没有配宿舍或者折扣房,还有尽量错过实习高峰找房)。非常重要的一点:一定要靠近地铁。对于没做过地铁的小伙伴来说,是体会不到的(当时租了离地铁两公里的房子,哭晕),地铁有点类似高铁的感觉,每一站都是卡着时间到站,而且速度非常的快,5公里的距离基本可以无视时间成本。对于资金的话,上海这边个人转租半年的话押一付二,押一付三的居多,各种app上一般是押一付一,租房子一定要提前蹲消息,一个处得来的室友和房东可以让你不用花精力在生活琐事上,一个好的室友往往比一个性价比高的房子更重要 &emsp;当我去上海的时候,我只带了钱包(现在都是支付宝了,不过上海有的地铁只能用他的app或者投币,没法直接支付宝,前排提醒),电脑,手机,各种证件,还有3套夏装1套秋装,一条宿舍用床单(因为没订酒店直接去的出租房,临时凑活一晚),还有一些小物件,轻装上阵。 &emsp;到了之后这是我的采购清单 123456789101112131415161718192021222324252627282930网购: 1 床单(大床,尽量防潮吧),最后买了防潮垫和粗布床单 1 椅子 1 瑜伽垫 1 枕头 1 墙纸,墙胶(墙皮有些开裂,还有地板是那种简装修的,有的地方还露着水泥,风一吹就飘灰) 1 烧水器,大水杯,小水杯,暖壶 1 指甲刀,镊子,螺丝刀(因为楼主的门锁坏了,自力更生) 1 垃圾桶(多个,垃圾分类) 1 洗手台 1 电脑支架 1 垃圾袋 1 除潮剂 1 洗衣液(大份) 1 卫生纸(批发) 1 衣架 1 枕巾 1 鞋(一定要有换洗的鞋,不然太难晾干了洗完了) 1 洗面奶(北方的油皮肤,一直是用的硫磺皂洗脸,到了上海发现洗脸太频繁了硫磺皂对皮肤伤害太大了,真的,到了上海,脸上出油量*n,原地爆炸)实体店: 1 洗衣液(临时) 1 卫生纸(临时) 1 拖把 1 多块抹布,毛巾 1 网线(临时应急) 1 拖鞋(凉拖两用的那种) 1 垃圾袋(临时) 1 脸盆(大中小各一个) 1 洗发膏 1 扫把,簸箕 &emsp;ps:垃圾分类小提示:瓜果之类可以用微生物腐化之后做能源的属于湿垃圾(坚果壳核太难分解的的除外)。报纸,快递盒子(胶带要撕下来),泡沫塑料属于可回收。各种电池杀虫剂等有毒的属于有害垃圾,其他模棱两可的扔干垃圾]]></content>
      <categories>
        <category>vlog</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[关于全面屏手机app点击无效问题]]></title>
    <url>%2F2019%2F07%2F14%2F%E5%85%B3%E4%BA%8E%E5%85%A8%E9%9D%A2%E5%B1%8F%E6%89%8B%E6%9C%BAapp%E7%82%B9%E5%87%BB%E6%97%A0%E6%95%88%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[概要&emsp;最近使用红手指(云手机)时触摸频繁失效,不被响应 现象&emsp;1.在使用云手机时,操作越频繁,失效概率越大&emsp;2.大约2-3分钟失效一段时间&emsp;3.点击左侧调整画质按钮后,可以恢复正常一段时 间(有时调整画质按钮也无法响应)&emsp;4.app的log日志中并没有接收到点击事件 原因&emsp;由于水滴屏等屏幕在运行此类app没有对流海屏做适应时,摄像头左右存在一个真空带,这个真空带在我们日常使用时是极容易被手掌内侧挤压(手越胖越容易,当然也与使用习惯有关),被挤压时因为其显示黑色使我们下意识认为这已经不属于屏幕范围,但是在挤压时会破坏一部分app的点击监听事件,导致app无法接收到操作请求,让用户以为是app未响应或者其他的问题]]></content>
      <categories>
        <category>BUG</category>
      </categories>
      <tags>
        <tag>other</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端添加数据后动态刷新时获取获取后端数据是旧的]]></title>
    <url>%2F2019%2F07%2F05%2F%E5%89%8D%E7%AB%AF%E6%B7%BB%E5%8A%A0%E6%95%B0%E6%8D%AE%E5%90%8E%E5%8A%A8%E6%80%81%E5%88%B7%E6%96%B0%E6%97%B6%E8%8E%B7%E5%8F%96%E8%8E%B7%E5%8F%96%E5%90%8E%E7%AB%AF%E6%95%B0%E6%8D%AE%E6%98%AF%E6%97%A7%E7%9A%84%2F</url>
    <content type="text"><![CDATA[情况一(后端缓存)第一种情况是由于后端使用了缓存,且添加数据后由于后端代码问题导致缓存刷新不及时产生的 情况二(前端异步请求)由于服务器响应请求总会有延迟,前端前后相差几毫秒发出了修改请求和查询请求。这种情况下由于网络问题,前端会出现有时可以刷新成功,有时旧数据的情况。解决方法就是前端同步下请求,收到第一个请求的返回后再发送下一个请求]]></content>
      <categories>
        <category>BUG</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[mysql大小写问题]]></title>
    <url>%2F2019%2F07%2F02%2Fmysql%E5%A4%A7%E5%B0%8F%E5%86%99%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[直接上报错,简单来讲就是报错说表没找到 123456782019-07-02 12:26:48.782 WARN 16022 --- [nio-8080-exec-2] o.h.engine.jdbc.spi.SqlExceptionHelper : SQL Error: 1146, SQLState: 42S022019-07-02 12:26:48.782 ERROR 16022 --- [nio-8080-exec-2] o.h.engine.jdbc.spi.SqlExceptionHelper : Table &apos;summertrain.Market_good&apos; doesn&apos;t existorg.springframework.dao.InvalidDataAccessResourceUsageException: could not execute statement; SQL [n/a]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute statement ...Caused by: org.hibernate.exception.SQLGrammarException: could not execute statement ... 74 moreCaused by: java.sql.SQLSyntaxErrorException: Table &apos;summertrain.Market_good&apos; doesn&apos;t exist ... 92 more 由于团队成员都会先从本地进行调试,本地调试成功就会推送到远程服务器让其自动部署本次情况发生时,成员本地调试通过,远程确报错如上内容 这是由于大小写问题引起的,写这个错误的成员,其本地数据库大小写不敏感,而我们远程服务器使用的mysql大小写敏感,从而summertrain.Market_good,M大写导致出现异常在更改其所有大写M为小写m后,推送到服务器,测试了可以正常使用 如果不想mysql对大小写敏感的话,可以在my.ini配置文件的字段mysqld下增加：lower_case_table_names=1(0表示大小写敏感,1表示不敏感,2表示存储时按大小写,比较时统一按小写比较)。如果我们设置表名大小写的话,需要操作系统支持,例如有的操作系统对于文件名是不区分大小写的,此时设置0会导致mysql启动异常]]></content>
      <categories>
        <category>BUG记录</category>
      </categories>
      <tags>
        <tag>base</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[i++不是原子性操作]]></title>
    <url>%2F2019%2F07%2F02%2Fi%2B%2B%E4%B8%8D%E6%98%AF%E5%8E%9F%E5%AD%90%E6%80%A7%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言这篇是从我以前csdn博客上搬运过来的,属于原创 正文 1234567891011121314151617public class CasStudy01 &#123; private static int count = 0; public static void main(String[] args) &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; count++; &#125; &#125;; for (int i = 0; i &lt; 10000; i++) &#123; new Thread(runnable).start(); &#125; Thread.sleep(1000);//为了等子线程全部运行结束 System.out.println(count); &#125;&#125; 输出:9945 Process finished with exit code 0 刚才的代码,照我们的设想,他应该是输出10000,然而每次我们run这段demo,输出结果各不相同这是因为count++这一行代码并不是原子操作,这一行代码实际在运行时,被分为取值,修改,存储三步操作,所以1,2两个线程同时取出值a,并且自增1修改为a+1,再存储的话,两次自增实际上只自增了1]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AtomicLong]]></title>
    <url>%2F2019%2F07%2F02%2FAtomicLong%2F</url>
    <content type="text"><![CDATA[前言这篇是从我以前csdn博客上搬运过来的,属于原创 正文一.AtomicLong是做什么用的首先我们可以先看一下我的另一篇文章i++不是原子性操作 此时,我们通常选择会是进行这样的操作 123456789101112131415161718192021public class CasStudy01 &#123; private static int count = 0; private synchronized static void add()&#123; count++; &#125; public static void main(String[] args) throws InterruptedException &#123; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; add(); &#125; &#125;; for (int i = 0; i &lt; 10000; i++) &#123; new Thread(runnable).start(); &#125; Thread.sleep(1000); System.out.println(count); &#125;&#125; 我们将count++操作放在了一个带锁的方法里面,来保证其线程安全性。然而,我们知道,加锁解锁操作会造成性能的消耗,在并发量不算太高的情况下,我们可以考虑采用AtomicLong(无锁的方式,采用/2019/07/02/CAS机制/)来保证线程安全性 二.AtomicLong的实现AtomicLong在源码中持有Unsafe类的实例,其大部分操作都是交付给Unsafe类来完成的(Unsafe中大多是本地方法,虽然我们可以通过反射来调用,但是官方强烈不建议我们这么做) AtomicLong里面持有一个long类型的valueOffset变量,这个变量表示的是其value值的内存偏移量(详见JVM内存模型),当我们调用incrementAndGet时,会交付Unsafe类来进行操作 123public final long incrementAndGet() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;&#125; 我们传入本类的实例,value的偏移量,以及增加量 12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 在Unsafe中就会进行CAS操作,使得value增加1,这是线程安全的 三.AtomicLong的缺点当并发量极大的时候,由于CAS机制本身的原因,导致CAS失败率极高,从而拖慢性能。此时,我们可以考虑使用LongAdder(待补充)]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CAS机制]]></title>
    <url>%2F2019%2F07%2F02%2FCAS%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[前言这篇是从我以前csdn博客上搬运过来的,属于原创 正文一.什么是CAS机制CAS机制的全名叫做compare and swap让我们来看一行代码 1public final native boolean compareAndSwapLong(Object var1, long var2, long var4, long var6); 这行代码源于Unsafe类(待补充),参数var1和var2我们先不考虑,var4表示旧值,var6表示新值,这行代码的作用是,如果var4的值等于内存中的现有值,那么将内存中的值替换为var6同时返回true,否则返回false。这就是CAS机制,同时也是其在Java中的体现 二.为什么要使用CAS/有哪些好处一般情况下,当我们并发访问同一个int变量时,我们往往需要加锁操作,但每次加锁会造成大量的开销,影响性能,所以就有了CAS机制,可以让我们在不加锁的情况下做到线程安全 三.CAS机制存在哪些问题1.ABA问题先看一段代码,代码源于Unsafe类①这一步的意义是得到内存中的现有值(参数可忽略) 12345678public final long getAndAddLong(Object var1, long var2, long var4) &#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2);① &#125; while(!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6; &#125; ABA问题简述:如代码所示,假设存在线程1,2。线程1运行了①之后等待,线程2开始运行,线程2将A改变为B,再将B改变为A,线程2结束,线程1继续运行,此时,线程1会认为A依旧是原来他读取到的A,期间并没有改变,并且将他按照正常流程改变为B。当然,在正常情况下,变量加减方面这并不会造成什么影响,但是若将CAS用在堆栈或者链表上(网上搜索一下有很多这种ABA问题的例子),或由于业务错误,同时发出了两次修改金钱100为50的操作,但是此时又加入了一个修改金钱50为100的操作(参考自漫画：什么是CAS机制？（进阶篇）),那么就会出现严重的问题解决方案:最常见的ABA问题的解决方案就是诸如java并发包中的AtomicStampedReference类,其内部实现类似于。不同点是,其内部维护了一个内部类Pair,采用记录版本号的方式来避免ABA问题,不过每次在更改时都会new一个新的Pair来进行CAS,如果对性能有极高的要求,那么需要谨慎选择 2.由于在使用CAS时,往往使用的是重试机制,即在while循环中一直重试CAS直到成功为止,所以在极高并发情况下,CAS的失败率将增大,会导致严重的性能问题,对于这个问题,很多时候解决方案是在一般程度并发时采取CAS,极高并发时进行排队]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>base</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[jpa查询部分字段获取实体类]]></title>
    <url>%2F2019%2F07%2F01%2Fjpa%E6%9F%A5%E8%AF%A2%E9%83%A8%E5%88%86%E5%AD%97%E6%AE%B5%E8%8E%B7%E5%8F%96%E5%AE%9E%E4%BD%93%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[代码已经放到github,test测试中的demo2对应的是sql方式,demo3对应的是hql方式,demo1是分页查询,我另一篇文章会讲到github地址 前言我们平时使用jpa查询时,有两种情况,一种是查询全部字段,另一种是查询部分字段,当我们按通常的sql语句写法查询部分字段时,会出现jpa无法自动解析类型的情况,例如这类报错 1org.springframework.dao.InvalidDataAccessResourceUsageException: could not execute query; SQL [ SELECT sa.name FROM student sa ]; nested exception is org.hibernate.exception.SQLGrammarException: could not execute query 解决方案针对hql和sql分别有两种解决方案 一. &emsp;hql情况下,我们可以用这种方式来解决,有必要注意的一点是,Student里面一定要有相应的构造类 123//TODO 查询部分字段的demo-hql@Query(value = " SELECT new Student(s.name) FROM Student s")List&lt;Student&gt; temp03(); 二. 在sql情况下,我们可以用这种方式解决,首先我们将查出来的数据领jpa解析为map,然后通过我们自己写的map转实体类方法来解决 1234//TODO 查询部分字段的demo-sql@Query(value = " SELECT sa.name FROM student sa ", nativeQuery = true)List&lt;Map&lt;String,Object&gt;&gt; temp02(); 下面是我自己写的一个map转实体类的工具方法 1234567891011121314151617181920212223242526272829303132333435363738/**将map转换为实体类,在jpa查询部分字段时会用到* 使用的时候注意,因为int类型会初始化的问题,无法被FASTJSON忽略掉,所以返回的json可能会带有额外的数字0* 由于是通过属性名来匹配,所以如果数据库字段名和参数名不一致,会导致部分字段映射不到实体,应该这么写* @Query(value = " select id,bar_code01 barCode01,bar_code02 barCode02,bar_code03 barCode03,name,comment from library_good ",nativeQuery=true)* 在查询时取别名,将其跟类的属性名一致 */public static &lt;T&gt;T mapToEntity(Map&lt;String,Object&gt; map,Class&lt;T&gt; targetClass) throws IllegalAccessException, InstantiationException &#123; Class superClass; Field[] fields; T target = targetClass.newInstance(); //接收targetClass的Field List&lt;Field&gt; targetfieldList = new LinkedList&lt;&gt;(); superClass = targetClass; while(superClass!=null&amp;&amp;superClass!=Object.class)&#123; //由于该方法只能获取superClass的参数(private,protect,public等任何声明),但无法获取父类的参数,这里我们迭代一波 fields = superClass.getDeclaredFields(); targetfieldList.addAll(Arrays.asList(fields)); superClass = superClass.getSuperclass(); &#125; //匹配并赋值 for (Field targetfield : targetfieldList) &#123; for (Map.Entry&lt;String, Object&gt; mapEntry : map.entrySet()) &#123; if (targetfield.getName().equals(mapEntry.getKey()))&#123; //暂时保存权限 boolean targetFlag = targetfield.isAccessible(); //赋予权限 targetfield.setAccessible(true); //赋值 targetfield.set(target,mapEntry.getValue()); //恢复原权限 targetfield.setAccessible(targetFlag); break; &#125; &#125; &#125; return target;&#125; 有一点需要注意,由于其底层用了反射,所以无论是通过该种方式取数据还是存数据,均需要setAccessible(true),否则会出现IllegalAccessException异常]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>jpa</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux安装jdk(非openjdk)]]></title>
    <url>%2F2019%2F07%2F01%2Flinux%E5%AE%89%E8%A3%85jdk(%E9%9D%9Eopenjdk)%2F</url>
    <content type="text"><![CDATA[1.官网下载压缩包,这里我下载的是解压版不是rpm版本,现在可能需要你登陆才可以下载,自己去注册个账户吧,或者用其他方式得到压缩包oracle下载jdk8的网址 2.解压压缩包tar -zxvf 你压缩包的名字.tar.gz 3.安装vim,这是个文本编辑器,你可以把它理解为记事本这种东西,至少我的ubuntu18.04是不自带vim的你可以使用sudo apt install vim这条命令安装,也可以在命令行输入vim按照他的提示安装 3.修改配置文件,原理跟window一样,只要将路径添加到配置文件中,操作系统就可以检测到我们想要安装的东西vim /etc/profile(这里需要注意了,要用root权限进行,前面加sudo) 4.打开配置文件后,我们在尾部追加如下内容,vim的操作方式请自行搜索 123export JAVA_HOME=你的jdk目录,注意是根目录,不是bin目录export CLASSPATH=$JAVA_HOME/lib/export PATH=$JAVA_HOME/bin:$PATH 5.使操作系统重新加载配置文件,注意需要root权限source /etc/profile 6.输入java -version出现java版本信息即我们配置成功了]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>base</tag>
        <tag>linux</tag>
        <tag>jdk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Servlet源码笔记]]></title>
    <url>%2F2019%2F06%2F28%2FServlet%E6%BA%90%E7%A0%81%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[主要简单介绍下servlet源码结构 介绍首先类的主要结构关系需要提及一下 1234567891011121314151617模块一interface ServletRequestinterface HttpServletRequest extends ServletRequestclass ServletRequestWrapper implements ServletRequestclass HttpServletRequestWrapper extends ServletRequestWrapper implements HttpServletRequest模块二interface ServletConfiginterface Servletabstract class GenericServlet implements Servlet, ServletConfig, java.io.Serializableabstract class HttpServlet extends GenericServlet 看到上面的类继承关系可能会有点陌生,接下来我给出一段demo 123456789public class HelloWord extends HttpServlet &#123; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response)&#123; &#125; @Override protected void doPost(HttpServletRequest request, HttpServletResponse response)&#123; &#125; 好了,这下应该不陌生了,我们用Servlet写代码一般都是继承HttpServlet来进行,这属于第二模块,而我们代码中操作的request属于第一模块 在具体分析代码之前,有必要先科普下Servlet的生命周期,平时我们在写Servlet服务端的时候,是没有main入口类的,仔细想想,没有入口类为何可以启动?答案来了,是因为tomcat,如果将Servlet看作对象的话,那么tomcat就是Servlet的容器,tomcat负责操控Servlet的生命周期,tomcat从他自己的入口类启动,运行时调用Servlet从而进行一切操作。我看了很多的博客教程,他们都是这么说的: 1&amp;emsp;tomcat作为servlet容器,当http请求进来时,发现没有servlet,那么则初始化一个servlet,将http请求封装为Request交给servlet处理,且servlet为单例重复使用,若长时间未调用才会销毁 但是在tomcat8.5.28+servlet4.0环境下,在不调整任何参数时(默认),我的测试跟上述操作有点出入,servlet并不是在接到http请求时才初始化,而是在随tomcat启动时便已经初始化,这一点可以根据我对servlet初始化init方法打断点,并且以debug方式启动可以看出,各位尽可以自行尝试,当然这不是重点,大体流程了解即可。 首先我们从第二模块开始 Servlet这个接口类定义了一系列与tomcat相互交互的一系列接口 ServletConfig看名字也知道是提供配置信息的一个接口 GenericServlet这个是对Servlet和ServletConfig接口的一些实现,另外增加了一些log方法来传递异常 HttpServlet这个类就定义了对GET,PUT,POST,HEAD,DELETE等各种HTTP方法的处理方式那么问题来了,我们知道之前定义的Servlet接口类提供给tomcat一些交互接口,那么唯一涉及到各种操作的只有service方法,他是如何跟各种HTTP方法的处理结合起来的呢?在源码面前的朋友可以追着service方法一路下来,最终在HttpServlet中可以看到service方法的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; String method = req.getMethod(); if (method.equals(METHOD_GET)) &#123; long lastModified = getLastModified(req); if (lastModified == -1) &#123; // servlet doesn't support if-modified-since, no reason // to go through further expensive logic doGet(req, resp); &#125; else &#123; long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE); if (ifModifiedSince &lt; lastModified) &#123; // If the servlet mod time is later, call doGet() // Round down to the nearest second for a proper compare // A ifModifiedSince of -1 will always be less maybeSetLastModified(resp, lastModified); doGet(req, resp); &#125; else &#123; resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED); &#125; &#125; &#125; else if (method.equals(METHOD_HEAD)) &#123; long lastModified = getLastModified(req); maybeSetLastModified(resp, lastModified); doHead(req, resp); &#125; else if (method.equals(METHOD_POST)) &#123; doPost(req, resp); &#125; else if (method.equals(METHOD_PUT)) &#123; doPut(req, resp); &#125; else if (method.equals(METHOD_DELETE)) &#123; doDelete(req, resp); &#125; else if (method.equals(METHOD_OPTIONS)) &#123; doOptions(req,resp); &#125; else if (method.equals(METHOD_TRACE)) &#123; doTrace(req,resp); &#125; else &#123; // // Note that this means NO servlet supports whatever // method was requested, anywhere on this server. // String errMsg = lStrings.getString("http.method_not_implemented"); Object[] errArgs = new Object[1]; errArgs[0] = method; errMsg = MessageFormat.format(errMsg, errArgs); resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg); &#125; &#125; 从代码中可以看到,他是负责匹配头部信息来进行分发操作,不清楚http报文的朋友可以看下面,这是用firefox浏览器发送的一组请求,第一行的GET即为method.equals(…)中的method内容 12345678910GET / HTTP/1.1Host: localhost:8080User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:67.0) Gecko/20100101 Firefox/67.0Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2Accept-Encoding: gzip, deflateConnection: keep-aliveUpgrade-Insecure-Requests: 1Pragma: no-cacheCache-Control: no-cache 到此为止第二模块基本结束 接下来分析第一模块 ServletRequest主要用来获取被储存信息,例如储存被tomcat封装后的http信息 HttpServletRequest特别针对http协议的各种参数在ServletRequest基础上进行了扩展 ServletRequestWrapper也是个扩展,不过有个特殊的地方要注意,这个类的构造方法public ServletRequestWrapper(ServletRequest request)接收了一个ServletRequest对象,以后的参数就从这个对象里面拿取 HttpServletRequestWrapper就是上面三个类的实现了,没什么意思 #####通过这些介绍,Servlet已经不再神秘,大家可以仔细去看源码,其实Servlet构造十分简单,真正起到关键作用的还是例如Tomcat等Servlet容器基础知识:Tomcat源码笔记]]></content>
      <categories>
        <category>源码</category>
      </categories>
      <tags>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[getParamter为何接收不到postman构造的信息]]></title>
    <url>%2F2019%2F06%2F28%2FgetParamter%E4%B8%BA%E4%BD%95%E6%8E%A5%E6%94%B6%E4%B8%8D%E5%88%B0postman%E6%9E%84%E9%80%A0%E7%9A%84%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[之前发生了这样一件事,由于是用的postman发送的消息,消息体有几种常用构造方式:none,form-data,x-www-form-urlencoded有一些构造方式通过getParameter方法是获取不到数据的,接下来让我们一起看一下这个问题 首先我对两种构造方式进行了抓包,看到他们发出去的请求首先时form-data格式下的Get,Post方式 1234567891011121314151617181920GET http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------130695699130126180335395User-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 255c0f6d-0296-4095-af08-3a0bc1e1f756Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 281Connection: keep-alive----------------------------130695699130126180335395Content-Disposition: form-data; name=&quot;username&quot;admin----------------------------130695699130126180335395Content-Disposition: form-data; name=&quot;password&quot;123456----------------------------130695699130126180335395-- 123456789101112131415161718192021POST http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: multipart/form-data; boundary=--------------------------666026373795318990654180User-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: f7e5f00a-65d9-4aba-961d-34762e8c410cHost: localhost:8080accept-encoding: gzip, deflatecontent-length: 281Connection: keep-alive----------------------------666026373795318990654180Content-Disposition: form-data; name=&quot;username&quot;admin----------------------------666026373795318990654180Content-Disposition: form-data; name=&quot;password&quot;123456----------------------------666026373795318990654180--` 接下来是x-www-form-urlencoded格式下的Get,Post方式 123456789101112GET http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: application/x-www-form-urlencodedUser-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 7e03a95e-5539-4a2a-b0e7-0fe399a4af28Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 30Connection: keep-aliveusername=admin&amp;password=123456 123456789101112POST http://localhost:8080/TestHttp/HelloWord HTTP/1.1Content-Type: application/x-www-form-urlencodedUser-Agent: PostmanRuntime/7.15.0Accept: */*Cache-Control: no-cachePostman-Token: 13ed95bb-803d-451c-b046-db4e5eb142b2Host: localhost:8080accept-encoding: gzip, deflatecontent-length: 30Connection: keep-aliveusername=admin&amp;password=123456 根据实验结果,在POST模式下x-www-form-urlencoded才可以通过getParameter获取数据,那么导致这一问题的原因是什么呢?通过代码,锁定了Tomcat Request类的parseParameters方法 12345678910111213141516//这里对消息格式进行判断if ("multipart/form-data".equals(contentType)) &#123; parseParts(false); success = true; return;&#125;//在这一行对method进行了判断,如果是POST,则进行接下来的解析,如果是其他的,那么直接返回if( !getConnector().isParseBodyMethod(getMethod()) ) &#123; success = true; return;&#125;//这里对消息格式进行判断if (!("application/x-www-form-urlencoded".equals(contentType))) &#123; success = true; return;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用git完成服务器自动化部署解决方案]]></title>
    <url>%2F2019%2F06%2F24%2F%E5%88%A9%E7%94%A8git%E5%AE%8C%E6%88%90%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[前言本篇主要讲述在团队合作时,如何利用脚本和git在前后端分离模式下,测试时的服务器自动化部署问题(只是个人想法和实践,仅作参考。下方代码已经经过测试,保证做好适配后可用) 适用情况:团队合作,前后端分离,后端需根据前端需求持续变更代码并提供给前端测试 需要的环境:linux服务器,git,maven,java 2019.6.25更新昨天忘记了说一个重要的问题,如果你是在window环境下写的shell脚本到linux环境下运行,由于两者系统换行符不一致,需要在linux中执行vim你的脚本名,进入脚本:set ff=unix,注意”:”这个符号需要带着,不明白的请去搜vim命令一定要赋予脚本可执行权限,赋权具体命令下文sh代码有提及刚才看了些博客,有提到用hook触发,而不是自己去循环访问,思路待定 原答案&emsp;首先讲成果,上代码,我会在其中伴随大量讲解1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#!/bin/sh###本代码中的该项目特有名称均会用其他文本代替,例如我的项目名就用demo代替###该项目的git文件夹我们暂且称呼为demofunction updateAndRestart()&#123; #切换到online分支,这个地方需要根据自己的git分支做适配 git checkout online #git rev-parse online命令用于查看本地的online分支最后一次提交id LOCALONLINE=$(git rev-parse online) #用于这句话就是打印到控制台,没什么意义 echo "本地ONLINE为$&#123;LOCALONLINE&#125;" #从远程仓库fetch,这里选择fetch而不是pull也是为了性能考虑,如有偏差,请根据自己想法修改 git fetch echo "从远程仓库拉取结束" #获取已经fetch下来的远程仓库的HEAD,这里要做郑重说明,如果git rev-parse orgin/online虽然是获取远程仓库online分支的最后一次提交,但是他不会真的去连接远程仓库拉取信息,而是读取本地的远程仓库的缓存信息,所以之前需要git fetch也是为了刷新本地缓存的作用。 #关于如何直接去远程查看远程仓库最后一次提交这个问题,我找了一半天没有找到这个方法 REMOTEONLINE=$(git rev-parse origin/online) echo "远程HEAD为$&#123;REMOTEONLINE&#125;" #检查远程仓库是否与本地ONLINE一致,若不一致,则证明了远程已更新 if [[ $LOCALONLINE != $REMOTEONLINE ]]; then echo "进入重启-------------------------------------------" #将远程分支的更新合并到本地,由于git pull命令可以理解为git fetch+git merge,这一步的意义这里不做赘述 git merge $REMOTEONLINE #杀死所有名为下列的进程 #这里只讲一点,由于awk命令下文介绍过,那么此时可以想象文本状态是kill -9 进程pid,sh命令是把之前的输出当作脚本来执行,那么就成果实现了批量kill进程 jps | grep demo.jar|awk '&#123;print "kill -9 " $1&#125;'|sh #重新打包jar mvn clean package #给jar授权 #这里有必要作下说明,此脚本我是运行在root用户下(这点很重要,如果是其他用户,则在权限方面需要注意做适配) #chomd是赋权命令,后面参数则是其权限,参数每部分的具体意义请自行查询 #这条命令是授予demo.jar的root用户可执行权限(原本被mvn打包后默认为读写权限,没有执行权限) chmod 744 /你的目录/demo.jar #这个文件我不知道是什么,在window环境下尝试情况,删除了也不会有什么影响。有人说.jar是不带依赖的,original是带依赖的,但是观察文件大小,发现original文件只有几十k,明显不是带着依赖一起打包的样子 chmod 744 /你的目录/demo.jar.original #后台运行jar,具体意义可见后半部分文章 nohup java -jar /你的目录t/demo.jar &gt; /你的目录/xxx-`date +%Y-%m-%d-%H-%M-%S`.log 2&gt;&amp;1 &amp; sleep 15 fi&#125;###上面的是函数,只有调用时才会运行,首先运行的是下面代码#首先cd到你的demo存放目录,这一步可有可无,根据你的项目路径做好适配就行cd /xxx/xxx/demo#下面这行代码是脚本启动时用来检测是否demo程序正在运行#这里顺便讲解下shell和java的知识# jps该命令可以理解为和ps命令类似,只不过是用来显示java进程# |这个管道命令我无法解释,自己去搜索引擎# grep用来抓取出包含demo.jar字段的行# awk一种文本处理命令,将文本按照我们定义的规则处理# 这里'&#123;print $1&#125;'代表的是输出每行的第一个参数(在我的linux系统中,每行的第一个参数正好是java进程的pid,其他人需要根据情况适配,注意'引号一定要有)# wc -l是统计命令,由于之前都是一行一行打印的,所以此命令可以很轻松统计有多少在运行# 综上所述,该条命令的意义在于:统计名为demo.jar的java进程的数目,awk这段命令后来想了想属于冗余命令了,可视情况去除SUMMERTRAINPID=$(jps | grep demo.jar |awk '&#123;print $1&#125;' |wc -l)if [[ SUMMERTRAINPID!=0 ]]; then echo "脚本开始,检测到程序未启动,先启动程序------------------------" #summertrain-`date +%Y-%m-%d-%H-%M-%S` #下面这条命令是在后台启动demo.jar并且将输出重定向到指定的log文件,如果文件不存在会新建 #其实nohup java -jar /你的路径/demo.jar &gt; /你log日志的路径/文件名.log &amp;这条命令就可以做到这一点 #下面这条命令多出来的几个字段表示的是将error日志也重定向到log文件 #小提示,在自己的脚本,log日志太长不易于观看,所以可以文件名可以在后缀加上`date +%Y-%m-%d-%H-%M-%S`,参数可以在生成文件时自动加上当前实际后缀,例如demolog-`date +%Y-%m-%d-%H-%M-%S`.log nohup java -jar /你的路径/demo.jar &gt; /你log日志的路径/文件名.log 2&gt;&amp;1 &amp; #这里我令他休眠15秒等待java程序启动 sleep 15fi#接下来开始循环检测是否git有更新while truedo echo "自动循环中" updateAndRestart sleep 10done 后记:写该脚本时参考了git命令,shell语法,linux命令shell脚本中的空格一定要注意,少一个空格往往意义就会不同如果团队人数更多,那么该方法不再试用,每次程序启动都需一定时间。届时改为分布式项目,每个模块独立部署。]]></content>
      <categories>
        <category>探索笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql启动(无需添加到服务)]]></title>
    <url>%2F2019%2F06%2F22%2Fmysql%E5%90%AF%E5%8A%A8(%E6%97%A0%E9%9C%80%E6%B7%BB%E5%8A%A0%E5%88%B0%E6%9C%8D%E5%8A%A1)%2F</url>
    <content type="text"><![CDATA[已经安装配置好mysql,无需将mysql添加到服务项中即可启动 1.打开cmd,通过cd到mysql安装/解压文件夹下 2.调用bin下的mysqld.exe文件(如果是linux则可能是.sh) 3.参数为my.ini/my.cnf 4.具体命令为&emsp;bin/mysqld –defaults-file=./my.ini 5.输入该命令后cmd应该会挂起,此时mysql已经启动成功。如果关闭cmd命令行那么mysql关闭]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git使用笔记]]></title>
    <url>%2F2019%2F06%2F21%2Fgit%E4%BD%BF%E7%94%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[详细介绍git使用和配置(不包括安装) 什么是git? 首先我用通俗语言解释下,git是一种版本控制工具,你既可以在本地进行版本控制,也可以与搭建好git服务器的远端进行同步 如何使用? windows的可以官方下载安装包,linux可以命令行下载(对于window来说可能需配置环境变量,可有可无) 配置全局信息 随便找个地方右键打开git bash ps:这里配置的昵称和邮箱可以随便写,作用体现在,假如你提交了git,那么在git记录中会显示提交者昵称和邮箱,即为下面输入的 输入git config –global user.name “你的昵称” 输入git config –global user.name “你的邮箱” 创建git仓库 随便找个地方新建文件夹进去打开git bash(此处建议选一个父文件夹作为git仓库目录) 输入git init 该命令的作用是在当前文件夹下生成git仓库所需文件(注意,这里git仓库通常指的是一个项目,而不是管理多个项目的仓库,而且生成的文件为.git是个隐藏文件夹) 使用git 当我们在文件夹下做了操作以后(添加修改删除文件),可以git add . .代表暂存全部文件,当然也可以是其他写法或部分文件 此时我们已经add成功,接下来git commit -m”此次提交的注释” 此时,本地的使用基本就到这里(此外还有分支,冲突等各种概念,不在本篇讲) 关联github/码云(也可以是其他的或者自己搭建的git服务器) 首先我们在git bash中生成一对密钥,命令为:ssh-keygen -t rsa -C “你之前填写的邮箱” 其实一般码云或者github都要官方绑定密钥教程,基本都一样 生成密钥后我们把密钥配置到git服务器上 如果是github之类的你从个人setting可以找到配置密钥的地方,如果是个人git服务器则可能需要手动添加 刚才生成的密钥分为公钥和私钥,一般公钥以.pub结尾,这部分涉及到密码学,你只需要知道这是非对称密钥用来代替用户密码做身份验证就好了,具体内容请自行搜索 在window中默认保存在C://user/{你的用户名}/.ssh文件夹中 当我们配置到服务器公钥后,就可以正常的git clone 远程私有仓库等操作 可视化界面SourceTree SourceTree需要注册啥的,可能被墙了,自己解决 这里要提到一点,它仅仅是个可视化界面,仍然需要你安装git 团队里有人出现了SourceTree没有权限的问题,打开密钥设置界面(不同版本打开位置有所不同,大概都是在工具-选项这一块),找到之前我们生成的密钥(上文提到过位置),将私钥添加进去即可 解决冲突 这里我不建议大家团队合作时在采用pull来拉代码,这样的话如果有冲突,文件会被标记为冲突,建议用fetch先检测一下 如果是在commit之前拉取,产生了冲突,那么可以针对冲突的文件,抛弃自己的修改(等fetch+merge之后在手动增加回来) 如果是在commit之后拉取产生了冲突,就会出现无法拉取也无法推送的情况,这时候我们可以撤销commit操作,使其返回到上一种情况 1234567git reset [--参数] 提交id参数有: mixed:不删除改动的代码,撤销commit和add soft:不删除改动代码,撤销commit hard:删除改动代码,撤销commit和add(这种是用指定的提交id强行覆盖掉现有代码)示例: git reset --soft xxxxxxxxx 这里我们说的是命令行的操作,如果是sourceTree,那么对应的就是”重置当前分支到此次提交” 如果想要抛弃对方的提交,使自己本次提交强行覆盖掉对方,那么可以见下方代码。如果是sourceTree的话,则需要取选项里面允许强制提交。此外,如果用的github之类的这种托管远程仓库,那么对方可能还会设置了权限,只有拥有者有权限强制推送,项目所属人去github里面设置一下就好(这一点笔者没有实践) 1git push --force origin 一些其他的诸如merge,rebase的用法 这些用法笔者的理解有限,这里附一个知乎的提问,大家可以参考下在开发过程中使用git rebase还是git merge，优缺点分别是什么？ 一些其他的bug如何解决 现象:原本中文编码变成了/xxx/xxx之类的八进制码解决:修改本地git仓库下的.git隐藏文件夹下config文件,在[core]部分新增quotepath = false字段保存即可 git忽略规则&emsp;当我们同步到远程仓库时,配置了.gitignore可以令git按照我们定义的规则,选择性的跟踪本地仓库的文件&emsp;具体的语法规范这里不做描述,搜索引擎搜教程即可&emsp;这里我将列出学生team一个springboot项目合作时使用的.gitignore。对官方生成的git做了少许改动 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263HELP.mdtarget/!.mvn/wrapper/maven-wrapper.jar!**/src/main/**!**/src/test/**###团队合作config######由于团队合作时每个成员数据库账户密码不一样,所以每个成员都有个个人配置信息,在通用配置里面引入###person.properties###springboot######此处表示忽略测试文件夹###/src/test/java### STS ###.apt_generated.classpath.factorypath.project.settings.springBeans.sts4-cache### IntelliJ IDEA ###.idea*.iws*.iml*.ipr### NetBeans ###/nbproject/private//nbbuild//dist//nbdist//.nb-gradle/build/### VS Code ###.vscode/# Log file*.log# Compiled class file*.class# BlueJ files*.ctxt# Mobile Tools for Java (J2ME).mtj.tmp/# Package Files #*.jar*.war*.nar*.ear*.zip*.tar.gz*.rarhs_err_pid* &emsp;常见问题:配置了.gitignore仍然无法忽略&emsp;解决方式:git rm –cached filename&emsp;删除该filename文件的本地缓存,然后再进行add和commit等操作,等push到远端后,以后再就不会被追踪&emsp;原因:这是由于在配置.gitignore之前该文件就已经被git追踪造成的,]]></content>
      <categories>
        <category>工具笔记</category>
      </categories>
      <tags>
        <tag>base</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[welcome]]></title>
    <url>%2F2019%2F06%2F20%2Fwelcome%2F</url>
    <content type="text"><![CDATA[####测试图片,图片无效 图片下标 下一行文本 ####测试图片,图片无效]]></content>
  </entry>
</search>
